{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#georeader","title":"georeader","text":"<p>georeader is a package to process raster data from different satellite missions. georeader makes easy to read specific areas of your image, to reproject images from different satellites to a common grid  (<code>georeader.read</code>), to go from vector to raster formats (<code>georeader.vectorize</code> and <code>georeader.rasterize</code>) or to do radiance to reflectance conversions (<code>georeader.reflectance</code>). </p> <p>georeader is mainly used to process satellite data for scientific usage, to create ML-ready datasets and to implement end-to-end operational inference pipelines (e.g. the Kherson Dam Break floodmap). </p>"},{"location":"#install","title":"Install","text":"<p>The core package dependencies are <code>numpy</code>, <code>rasterio</code>, <code>shapely</code> and <code>geopandas</code>.</p> <pre><code>pip install georeader-spaceml\n</code></pre>"},{"location":"#getting-started","title":"Getting started","text":"<p>Read from a Sentinel-2 image a fixed size subimage on an specific <code>lon,lat</code> location (directly from the S2 public Google Cloud bucket):</p> <p><pre><code># This snippet requires:\n# pip install fsspec gcsfs google-cloud-storage\nimport os\nos.environ[\"GS_NO_SIGN_REQUEST\"] = \"YES\"\n\nfrom georeader.readers import S2_SAFE_reader\nfrom georeader import read\n\ncords_read = (-104.394, 32.026) # long, lat\ncrs_cords = \"EPSG:4326\"\ns2_safe_path = S2_SAFE_reader.s2_public_bucket_path(\"S2B_MSIL1C_20191008T173219_N0208_R055_T13SER_20191008T204555.SAFE\")\ns2obj = S2_SAFE_reader.s2loader(s2_safe_path, \n                                out_res=10, bands=[\"B04\",\"B03\",\"B02\"])\n\n# copy to local avoids http errors specially when not using a Google Cloud project.\n# This will only copy the bands set up above B04, B03 and B02\ns2obj = s2obj.cache_product_to_local_dir(\".\")\n\n# See also read.read_from_bounds, read.read_from_polygon for different ways of croping an image\ndata = read.read_from_center_coords(s2obj,cords_read, shape=(2040, 4040),\n                                    crs_center_coords=crs_cords)\n\ndata_memory = data.load() # this loads the data to memory\n\ndata_memory # GeoTensor object\n</code></pre> <pre><code>&gt;&gt;  Transform: | 10.00, 0.00, 537020.00|\n| 0.00,-10.00, 3553680.00|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 2040, 4040)\n         Resolution: (10.0, 10.0)\n         Bounds: (537020.0, 3533280.0, 577420.0, 3553680.0)\n         CRS: EPSG:32613\n         fill_value_default: 0\n</code></pre></p> <p>In the <code>.values</code> attribute we have the plain numpy array that we can plot with <code>show</code>:</p> <p><pre><code>from rasterio.plot import show\nshow(data_memory.values/3500, transform=data_memory.transform)\n</code></pre> </p> <p>Saving the <code>GeoTensor</code> as a COG GeoTIFF: </p> <pre><code>from georeader.save import save_cog\n\n# Supports writing in bucket location (e.g. gs://bucket-name/s2_crop.tif)\nsave_cog(data_memory, \"s2_crop.tif\", descriptions=s2obj.bands)\n</code></pre>"},{"location":"#tutorials","title":"Tutorials","text":""},{"location":"#sentinel-2","title":"Sentinel-2","text":"<ul> <li>Reading Sentinel-2 images from the public Google bucket </li> <li>Explore metadata of Sentinel-2 object </li> <li>Query Sentinel-2 images over a location and time span, mosaic and plot them </li> <li>Sentinel-2 images from GEE and CloudSEN12 cloud detection </li> </ul>"},{"location":"#read-rasters-from-different-satellites","title":"Read rasters from different satellites","text":"<ul> <li>Tutorial to read overlapping tiles from a GeoTIFF and a Sentinel-2 image </li> <li>Example of reading a Proba-V image overlapping with Sentinel-2 forcing same resolution</li> <li>Work with EMIT images </li> <li>Read overlapping images of PRISMA and EMIT </li> <li>Read EnMAP images, integrate them to Sentinel-2 bands, convert radiance to TOA reflectance and run CloudSEN12 cloud detection model </li> </ul>"},{"location":"#used-in-other-projects","title":"Used in other projects","text":"<ul> <li>georeader with ml4floods to automatically download and produce flood extent maps: the Kherson Dam Break example</li> <li>georeader with STARCOP to simulate Sentinel-2 from AVIRIS images</li> <li>georeader with STARCOP to run plume detection in EMIT images</li> <li>georeader with CloudSEN12 to run cloud detection in Sentinel-2 images</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you find this code useful please cite: <pre><code>@article{portales-julia_global_2023,\n    title = {Global flood extent segmentation in optical satellite images},\n    volume = {13},\n    issn = {2045-2322},\n    doi = {10.1038/s41598-023-47595-7},\n    number = {1},\n    urldate = {2023-11-30},\n    journal = {Scientific Reports},\n    author = {Portal\u00e9s-Juli\u00e0, Enrique and Mateo-Garc\u00eda, Gonzalo and Purcell, Cormac and G\u00f3mez-Chova, Luis},\n    month = nov,\n    year = {2023},\n    pages = {20316},\n}\n@article{ruzicka_starcop_2023,\n    title = {Semantic segmentation of methane plumes with hyperspectral machine learning models},\n    volume = {13},\n    issn = {2045-2322},\n    url = {https://www.nature.com/articles/s41598-023-44918-6},\n    doi = {10.1038/s41598-023-44918-6},\n    number = {1},\n    journal = {Scientific Reports},\n    author = {R\u016f\u017ei\u010dka, V\u00edt and Mateo-Garcia, Gonzalo and G\u00f3mez-Chova, Luis and Vaughan, Anna, and Guanter, Luis and Markham, Andrew},\n    month = nov,\n    year = {2023},\n    pages = {19999},\n}\n</code></pre></p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>This research has been supported by the DEEPCLOUD project (PID2019-109026RB-I00) funded by the Spanish Ministry of Science and Innovation (MCIN/AEI/10.13039/501100011033) and the European Union (NextGenerationEU).</p> <p></p> <ul> <li>Documentation https://spaceml-org.github.io/georeader/</li> </ul>"},{"location":"emit_explore/","title":"EMIT","text":"<pre><code>from georeader.readers import emit\nfrom georeader.readers import download_utils\nimport os\n\ndir_emit_files = \"emit_database/raw\"\nos.makedirs(dir_emit_files, exist_ok=True)\n# link = 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL1BRAD.001/EMIT_L1B_RAD_001_20220828T051941_2224004_006/EMIT_L1B_RAD_001_20220828T051941_2224004_006.nc'\nlink = 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL1BRAD.001/EMIT_L1B_RAD_001_20220827T060753_2223904_013/EMIT_L1B_RAD_001_20220827T060753_2223904_013.nc'\nfile_save = os.path.join(dir_emit_files, os.path.basename(link))\n\nemit.download_product(link, file_save)\n</code></pre> <pre>\n<code>File emit_database/raw/EMIT_L1B_RAD_001_20220827T060753_2223904_013.nc exists. It won't be downloaded again\n</code>\n</pre> <pre>\n<code>'emit_database/raw/EMIT_L1B_RAD_001_20220827T060753_2223904_013.nc'</code>\n</pre> <pre><code># file_save = \"emit_database/EMIT_L1B_RAD_001_20220827T060753_2223904_013.nc\"\nei = emit.EMITImage(file_save)\nei\n</code></pre> <pre>\n<code> \n         File: emit_database/raw/EMIT_L1B_RAD_001_20220827T060753_2223904_013.nc\n         Transform: | 0.00,-0.00, 61.16|\n|-0.00,-0.00, 36.83|\n| 0.00, 0.00, 1.00|\n         Shape: (285, 2007, 2239)\n         Resolution: (0.0005422325202530942, 0.0005422325202530942)\n         Bounds: (61.1592142222353, 35.74201728362127, 62.3732728350893, 36.8302779517758)\n         CRS: EPSG:4326\n         units: uW/cm^2/SR/nm\n        </code>\n</pre> <pre><code>ei.nc_ds\n</code></pre> <pre>\n<code>&lt;class 'netCDF4._netCDF4.Dataset'&gt;\nroot group (NETCDF4 data model, file format HDF5):\n    ncei_template_version: NCEI_NetCDF_Swath_Template_v2.0\n    summary: The Earth Surface Mineral Dust Source Investigation (EMIT) is an Earth Ventures-Instrument (EVI-4) Mission that maps the surface mineralogy of arid dust source regions via imaging spectroscopy in the visible and short-wave infrared (VSWIR). Installed on the International Space Station (ISS), the EMIT instrument is a Dyson imaging spectrometer that uses contiguous spectroscopic measurements from 410 to 2450 nm to resolve absoprtion features of iron oxides, clays, sulfates, carbonates, and other dust-forming minerals. During its one-year mission, EMIT will observe the sunlit Earth's dust source regions that occur within +/-52\u00b0 latitude and produce maps of the source regions that can be used to improve forecasts of the role of mineral dust in the radiative forcing (warming or cooling) of the atmosphere.\\n\\nThis file contains L1B at-sensor calibrated radiances. The radiance calibration occurs in two basic stages: 1) transforming raw digital numbers into radiance units using a calibrated radiometric response and correcting for electronic artifacts, and 2) a correction for instrument optical effects which results in an absolute spectral wavelength calibration. The radiance file contains radiance for each of 285 channels in units of microwatts per centimeter per centimeter squared per steradian. Geolocation data (latitude, longitude, height) and a lookup table to project the data are also included.\n    keywords: Imaging Spectroscopy, minerals, EMIT, dust, radiative forcing\n    Conventions: CF-1.63\n    sensor: EMIT (Earth Surface Mineral Dust Source Investigation)\n    instrument: EMIT\n    platform: ISS\n    institution: NASA Jet Propulsion Laboratory/California Institute of Technology\n    license: https://science.nasa.gov/earth-science/earth-science-data/data-information-policy/\n    naming_authority: LPDAAC\n    date_created: 2023-01-21T12:24:18Z\n    keywords_vocabulary: NASA Global Change Master Directory (GCMD) Science Keywords\n    stdname_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention\n    creator_name: Jet Propulsion Laboratory/California Institute of Technology\n    creator_url: https://earth.jpl.nasa.gov/emit/\n    project: Earth Surface Mineral Dust Source Investigation\n    project_url: https://emit.jpl.nasa.gov/\n    publisher_name: NASA LPDAAC\n    publisher_url: https://lpdaac.usgs.gov\n    publisher_email: lpdaac@usgs.gov\n    identifier_product_doi_authority: https://doi.org\n    flight_line: emit20220827t060753_o23904_s001\n    time_coverage_start: 2022-08-27T06:07:53+0000\n    time_coverage_end: 2022-08-27T06:08:05+0000\n    software_build_version: 010603\n    product_version: V001\n    history: PGE Run Command: {python /beegfs/store/emit/ops/repos/emit-sds-l1b/emitrdn.py --mode default --level INFO --log_file /tmp/emit/ops/emit20220827t060753_emit.L1BCalibrate_20221112t080244/output/emit20220827t060753_o23904_s001_l1b_rdn_b0106_v01_pge.log /beegfs/store/emit/ops/data/acquisitions/20220827/emit20220827t060753/l1a/emit20220827t060753_o23904_s001_l1a_raw_b0106_v01.img /beegfs/store/emit/ops/data/acquisitions/20220827/emit20220827t054803/l1a/emit20220827t054803_o23904_s000_l1a_raw_b0106_v01.img /tmp/emit/ops/emit20220827t060753_emit.L1BCalibrate_20221112t080244/l1b_config.json /tmp/emit/ops/emit20220827t060753_emit.L1BCalibrate_20221112t080244/output/emit20220827t060753_o23904_s001_l1b_rdn_b0106_v01.img /tmp/emit/ops/emit20220827t060753_emit.L1BCalibrate_20221112t080244/output/emit20220827t060753_o23904_s001_l1b_bandmask_b0106_v01.img;python /beegfs/store/emit/ops/repos/emit-sds-l1b/utils/fitflatfield.py /tmp/emit/ops/emit20220827t060753_emit.L1BCalibrate_20221112t080244/output/emit20220827t060753_o23904_s001_l1b_rdn_b0106_v01.img /tmp/emit/ops/emit20220827t060753_emit.L1BCalibrate_20221112t080244/output/emit20220827t060753_o23904_s001_l1b_rdn_destripe_b0106_v01.img /tmp/emit/ops/emit20220827t060753_emit.L1BCalibrate_20221112t080244/output/emit20220827t060753_o23904_s001_l1b_destripeff_b0106_v01.img /tmp/emit/ops/emit20220827t060753_emit.L1BCalibrate_20221112t080244/output/emit20220827t060753_o23904_s001_l1b_destripedark_b0106_v01.img}, PGE Input Files: {srf_correction_file=/beegfs/store/emit/ops/repos/emit-sds-l1b/data/emit/EMIT_SpectralScatter_20220406, crf_correction_file=/beegfs/store/emit/ops/repos/emit-sds-l1b/data/emit/EMIT_SpatialScatter_20220406, bad_element_file=/beegfs/store/emit/ops/repos/emit-sds-l1b/data/emit/EMIT_BadElements_20220307, spectral_calibration_file=/beegfs/store/emit/ops/repos/emit-sds-l1b/data/emit/EMIT_Wavelengths_20220817.txt, ghost_map_file=/beegfs/store/emit/ops/repos/emit-sds-l1b/data/emit/EMIT_GhostMap_20220424.json, linearity_file=/beegfs/store/emit/ops/repos/emit-sds-l1b/data/emit/EMIT_LinearityBasis_20220504, linearity_map_file=/beegfs/store/emit/ops/repos/emit-sds-l1b/data/emit/EMIT_LinearityMap_20220504, flat_field_file=/beegfs/store/emit/ops/repos/emit-sds-l1b/data/emit/EMIT_FlatField_20220825, radiometric_coefficient_file=/beegfs/store/emit/ops/repos/emit-sds-l1b/data/emit/EMIT_RadiometricCoeffs_20220901.txt, dark_file=/beegfs/store/emit/ops/data/acquisitions/20220827/emit20220827t054803/l1a/emit20220827t054803_o23904_s000_l1a_raw_b0106_v01.img}\n    crosstrack_orientation: as seen on ground\n    easternmost_longitude: 61.1592142222353\n    northernmost_latitude: 36.8302779517758\n    westernmost_longitude: 62.3732728350893\n    southernmost_latitude: 35.74201728362127\n    spatialResolution: 0.000542232520256367\n    spatial_ref: GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]\n    geotransform: [ 6.11592142e+01  5.42232520e-04 -0.00000000e+00  3.68302780e+01\n -0.00000000e+00 -5.42232520e-04]\n    day_night_flag: Day\n    title: EMIT L1B At-Sensor Calibrated Radiance Data 60 m V001\n    dimensions(sizes): downtrack(1280), crosstrack(1242), bands(285), ortho_y(2007), ortho_x(2239)\n    variables(dimensions): float32 radiance(downtrack, crosstrack, bands)\n    groups: sensor_band_parameters, location</code>\n</pre> <pre><code>ei.wavelengths\n</code></pre> <pre>\n<code>array([ 381.00558,  388.4092 ,  395.81583,  403.2254 ,  410.638  ,\n        418.0536 ,  425.47214,  432.8927 ,  440.31726,  447.7428 ,\n        455.17035,  462.59888,  470.0304 ,  477.46292,  484.89743,\n        492.33292,  499.77142,  507.2099 ,  514.6504 ,  522.0909 ,\n        529.5333 ,  536.9768 ,  544.42126,  551.8667 ,  559.3142 ,\n        566.7616 ,  574.20905,  581.6585 ,  589.108  ,  596.55835,\n        604.0098 ,  611.4622 ,  618.9146 ,  626.36804,  633.8215 ,\n        641.2759 ,  648.7303 ,  656.1857 ,  663.6411 ,  671.09753,\n        678.5539 ,  686.0103 ,  693.4677 ,  700.9251 ,  708.38354,\n        715.84094,  723.2993 ,  730.7587 ,  738.2171 ,  745.6765 ,\n        753.1359 ,  760.5963 ,  768.0557 ,  775.5161 ,  782.97754,\n        790.4379 ,  797.89935,  805.36176,  812.8232 ,  820.2846 ,\n        827.746  ,  835.2074 ,  842.66986,  850.1313 ,  857.5937 ,\n        865.0551 ,  872.5176 ,  879.98004,  887.44147,  894.90393,\n        902.3664 ,  909.82886,  917.2913 ,  924.7538 ,  932.21625,\n        939.6788 ,  947.14026,  954.6027 ,  962.0643 ,  969.5268 ,\n        976.9883 ,  984.4498 ,  991.9114 ,  999.37286, 1006.8344 ,\n       1014.295  , 1021.7566 , 1029.2172 , 1036.6777 , 1044.1383 ,\n       1051.5989 , 1059.0596 , 1066.5201 , 1073.9797 , 1081.4404 ,\n       1088.9    , 1096.3597 , 1103.8184 , 1111.2781 , 1118.7368 ,\n       1126.1964 , 1133.6552 , 1141.1129 , 1148.5717 , 1156.0304 ,\n       1163.4882 , 1170.9459 , 1178.4037 , 1185.8616 , 1193.3184 ,\n       1200.7761 , 1208.233  , 1215.6898 , 1223.1467 , 1230.6036 ,\n       1238.0596 , 1245.5154 , 1252.9724 , 1260.4283 , 1267.8833 ,\n       1275.3392 , 1282.7942 , 1290.2502 , 1297.7052 , 1305.1603 ,\n       1312.6144 , 1320.0685 , 1327.5225 , 1334.9756 , 1342.4287 ,\n       1349.8818 , 1357.3351 , 1364.7872 , 1372.2384 , 1379.6907 ,\n       1387.1418 , 1394.5931 , 1402.0433 , 1409.4937 , 1416.944  ,\n       1424.3933 , 1431.8427 , 1439.292  , 1446.7404 , 1454.1888 ,\n       1461.6372 , 1469.0847 , 1476.5321 , 1483.9796 , 1491.4261 ,\n       1498.8727 , 1506.3192 , 1513.7649 , 1521.2104 , 1528.655  ,\n       1536.1007 , 1543.5454 , 1550.9891 , 1558.4329 , 1565.8766 ,\n       1573.3193 , 1580.7621 , 1588.205  , 1595.6467 , 1603.0886 ,\n       1610.5295 , 1617.9705 , 1625.4104 , 1632.8513 , 1640.2903 ,\n       1647.7303 , 1655.1694 , 1662.6074 , 1670.0455 , 1677.4836 ,\n       1684.9209 , 1692.358  , 1699.7952 , 1707.2314 , 1714.6667 ,\n       1722.103  , 1729.5383 , 1736.9727 , 1744.4071 , 1751.8414 ,\n       1759.2749 , 1766.7084 , 1774.1418 , 1781.5743 , 1789.007  ,\n       1796.4385 , 1803.8701 , 1811.3008 , 1818.7314 , 1826.1611 ,\n       1833.591  , 1841.0206 , 1848.4495 , 1855.8773 , 1863.3052 ,\n       1870.733  , 1878.16   , 1885.5869 , 1893.013  , 1900.439  ,\n       1907.864  , 1915.2892 , 1922.7133 , 1930.1375 , 1937.5607 ,\n       1944.9839 , 1952.4071 , 1959.8295 , 1967.2518 , 1974.6732 ,\n       1982.0946 , 1989.515  , 1996.9355 , 2004.355  , 2011.7745 ,\n       2019.1931 , 2026.6118 , 2034.0304 , 2041.4471 , 2048.865  ,\n       2056.2808 , 2063.6965 , 2071.1123 , 2078.5273 , 2085.9421 ,\n       2093.3562 , 2100.769  , 2108.1821 , 2115.5942 , 2123.0063 ,\n       2130.4175 , 2137.8289 , 2145.239  , 2152.6482 , 2160.0576 ,\n       2167.467  , 2174.8755 , 2182.283  , 2189.6904 , 2197.097  ,\n       2204.5034 , 2211.9092 , 2219.3147 , 2226.7195 , 2234.1233 ,\n       2241.5269 , 2248.9297 , 2256.3328 , 2263.7346 , 2271.1365 ,\n       2278.5376 , 2285.9387 , 2293.3386 , 2300.7378 , 2308.136  ,\n       2315.5342 , 2322.9326 , 2330.3298 , 2337.7263 , 2345.1216 ,\n       2352.517  , 2359.9126 , 2367.3071 , 2374.7007 , 2382.0935 ,\n       2389.486  , 2396.878  , 2404.2695 , 2411.6604 , 2419.0513 ,\n       2426.4402 , 2433.8303 , 2441.2183 , 2448.6064 , 2455.9944 ,\n       2463.3816 , 2470.7678 , 2478.153  , 2485.5386 , 2492.9238 ],\n      dtype=float32)</code>\n</pre> <pre><code>ei.time_coverage_start, ei.time_coverage_end\n</code></pre> <pre>\n<code>(datetime.datetime(2022, 8, 27, 6, 7, 53, tzinfo=datetime.timezone.utc),\n datetime.datetime(2022, 8, 27, 6, 8, 5, tzinfo=datetime.timezone.utc))</code>\n</pre> <pre><code>import geopandas as gpd\n\ngpd.GeoDataFrame(geometry=[ei.footprint()],\n                 crs=ei.crs).explore()\n</code></pre> Make this Notebook Trusted to load map: File -&gt; Trust Notebook <pre><code>import numpy as np\nwavelengths_read = np.array([640, 550, 460])\n\nbands_read = np.argmin(np.abs(wavelengths_read[:, np.newaxis] - ei.wavelengths), axis=1).tolist()\nei_rgb = ei.read_from_bands(bands_read)\nei_rgb\n</code></pre> <pre>\n<code> \n         File: emit_database/raw/EMIT_L1B_RAD_001_20220827T060753_2223904_013.nc\n         Transform: | 0.00,-0.00, 61.16|\n|-0.00,-0.00, 36.83|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 2007, 2239)\n         Resolution: (0.0005422325202530942, 0.0005422325202530942)\n         Bounds: (61.1592142222353, 35.74201728362127, 62.3732728350893, 36.8302779517758)\n         CRS: EPSG:4326\n         units: uW/cm^2/SR/nm\n        </code>\n</pre> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom georeader import reflectance\n\nthuiller = reflectance.load_thuillier_irradiance() # (dataframe with 8191 rows, 2 colums -&amp;gt; Nanometer, Radiance(mW/m2/nm)\n\nei_rgb.wavelengths, ei_rgb.fwhm # (K,) vectors with the center wavelength and the FWHM\n\nresponse = reflectance.srf(ei_rgb.wavelengths, ei_rgb.fwhm, thuiller[\"Nanometer\"].values) # (8191, K)\n\ncolors = [\"red\",\"green\", \"blue\"]\nfig, ax = plt.subplots(1,1,figsize=(12,4))\n\nax.plot(thuiller[\"Nanometer\"].values,\n        thuiller[\"Radiance(mW/m2/nm)\"].values,\n        label=\"Thuiller irradiance\")\nax.set_ylabel(\"Solar irradiance (mW/m$^2$/nm)\")\nax = ax.twinx()\nfor k in range(3):\n    ax.plot(thuiller[\"Nanometer\"].values, response[:, k], \n            label=f\"{wavelengths_read[k]}nm\",c=colors[k])\nax.set_xlabel(\"Wavelength nm\")\nax.set_ylabel(\"SRF\")\nax.set_xlim(410,700)\nax.legend(loc=\"upper left\")\n</code></pre> <pre>\n<code>&lt;matplotlib.legend.Legend at 0x7f03eb294220&gt;</code>\n</pre> <pre><code># solar_irradiance_norm = thuiller[\"Radiance(mW/m2/nm)\"].values.dot(response) # mW/m$^2$/nm\n# solar_irradiance_norm/=1_000  # W/m$^2$/nm\n# solar_irradiance_norm\n# ei_rgb_local = ei_rgb.load(as_reflectance=False)\n# ei_rgb_local = reflectance.radiance_to_reflectance(ei_rgb_local, solar_irradiance_norm,\n#                                                    ei.time_coverage_start,units=units)\n</code></pre> <pre><code>ei_rgb_local = ei_rgb.load(as_reflectance=True)\n</code></pre> <pre><code>from georeader.plot import show\n\nshow((ei_rgb_local).clip(0,1), \n     mask=ei_rgb_local.values == ei_rgb_local.fill_value_default)\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>import georeader\n\ncrs_utm = georeader.get_utm_epsg(ei.footprint(\"EPSG:4326\"))\nemit_image_utm = ei.to_crs(crs_utm)\nemit_image_utm_rgb = emit_image_utm.read_from_bands(bands_read)\nemit_image_utm_rgb_local = emit_image_utm_rgb.load(as_reflectance=True)\nemit_image_utm_rgb_local\n</code></pre> <pre>\n<code> \n         Transform: | 60.00, 0.00, 333546.51|\n| 0.00,-60.00, 4077625.88|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 2036, 1844)\n         Resolution: (60.0, 60.0)\n         Bounds: (333546.5136802632, 3955465.8769401284, 444186.5136802632, 4077625.8769401284)\n         CRS: EPSG:32641\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>emit_image_utm_rgb.observation_date_correction_factor\n</code></pre> <pre>\n<code>3.9465190869822364</code>\n</pre> <pre><code>show((emit_image_utm_rgb_local).clip(0,1), \n     mask=emit_image_utm_rgb_local.values == emit_image_utm_rgb_local.fill_value_default,\n     add_scalebar=True)\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>show(emit_image_utm.elevation(), add_colorbar_next_to=True, add_scalebar=True,\n     mask=True,title=\"Elevation\")\n</code></pre> <pre>\n<code>&lt;Axes: title={'center': 'Elevation'}&gt;</code>\n</pre> <pre><code>from georeader import read\n\npoint_tup = (61.28, 36.21)\nei_subset = read.read_from_center_coords(emit_image_utm_rgb, point_tup, \n                                         shape=(200,200),crs_center_coords=\"EPSG:4326\")\n\nei_subset_local = ei_subset.load(as_reflectance=True)\nei_subset_local\n</code></pre> <pre>\n<code> \n         Transform: | 60.00, 0.00, 339366.51|\n| 0.00,-60.00, 4014625.88|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 200, 200)\n         Resolution: (60.0, 60.0)\n         Bounds: (339366.5136802632, 4002625.8769401284, 351366.5136802632, 4014625.8769401284)\n         CRS: EPSG:32641\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>from georeader.plot import add_shape_to_plot\nfrom shapely.geometry import Point\n\nax = show((ei_subset_local).clip(0,1),\n          mask=ei_subset_local.values == ei_rgb_local.fill_value_default,\n         add_scalebar=True)\nadd_shape_to_plot(Point(*point_tup),crs_shape=\"EPSG:4326\",\n                  crs_plot=ei_subset_local.crs, ax=ax)\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>import matplotlib.pyplot as plt\n\nei_rgb_raw = ei_rgb.load_raw(transpose=False)\nplt.imshow((ei_rgb_raw/12).clip(0,1))\n</code></pre> <pre>\n<code>&lt;matplotlib.image.AxesImage at 0x7f03db62f370&gt;</code>\n</pre> <pre><code>ei_rgb_subset = ei_subset.load_raw(transpose=False)\nplt.imshow((ei_rgb_subset/12).clip(0,1))\n</code></pre> <pre>\n<code>&lt;matplotlib.image.AxesImage at 0x7f03db6b0df0&gt;</code>\n</pre> <pre><code>emit_image_utm.mask_bands\n</code></pre> <pre>\n<code>array(['Cloud flag', 'Cirrus flag', 'Water flag', 'Spacecraft Flag',\n       'Dilated Cloud Flag', 'AOD550', 'H2O (g cm-2)', 'Aggregate Flag'],\n      dtype=object)</code>\n</pre> <pre><code># mask filtering cloudy pixels\nshow(emit_image_utm.validmask(), add_scalebar=True,vmin=0, vmax=1,\n     mask=True,title=\"Valid Mask\")\n</code></pre> <pre>\n<code>&lt;Axes: title={'center': 'Valid Mask'}&gt;</code>\n</pre> <pre><code>emit_image_utm.observation_bands\n</code></pre> <pre>\n<code>array(['Path length (sensor-to-ground in meters)',\n       'To-sensor azimuth (0 to 360 degrees CW from N)',\n       'To-sensor zenith (0 to 90 degrees from zenith)',\n       'To-sun azimuth (0 to 360 degrees CW from N)',\n       'To-sun zenith (0 to 90 degrees from zenith)',\n       'Solar phase (degrees between to-sensor and to-sun vectors in principal plane)',\n       'Slope (local surface slope as derived from DEM in degrees)',\n       'Aspect (local surface aspect 0 to 360 degrees clockwise from N)',\n       'Cosine(i) (apparent local illumination factor based on DEM slope and aspect and to sun vector)',\n       'UTC Time (decimal hours for mid-line pixels)',\n       'Earth-sun distance (AU)'], dtype=object)</code>\n</pre> <pre><code>show(emit_image_utm.sza(), add_colorbar_next_to=True, add_scalebar=True,\n     mask=True,title=\"Solar Zenith Angle\")\n</code></pre> <pre>\n<code>&lt;Axes: title={'center': 'Solar Zenith Angle'}&gt;</code>\n</pre> <pre><code>show(emit_image_utm.vza(), add_colorbar_next_to=True, add_scalebar=True,\n     mask=True,title=\"Viewing Zenith Angle\")\n</code></pre> <pre>\n<code>&lt;Axes: title={'center': 'Viewing Zenith Angle'}&gt;</code>\n</pre> <pre><code>show(emit_image_utm.observation('Path length (sensor-to-ground in meters)'), \n     add_colorbar_next_to=True, add_scalebar=True,\n     mask=True,title='Path length (sensor-to-ground in meters)')\n</code></pre> <pre>\n<code>&lt;Axes: title={'center': 'Path length (sensor-to-ground in meters)'}&gt;</code>\n</pre> <pre><code>show(emit_image_utm.observation('Slope (local surface slope as derived from DEM in degrees)'), \n     add_colorbar_next_to=True, add_scalebar=True,\n     mask=True,title='Slope (local surface slope as derived from DEM in degrees)')\n</code></pre> <pre>\n<code>&lt;Axes: title={'center': 'Slope (local surface slope as derived from DEM in degrees)'}&gt;</code>\n</pre>"},{"location":"emit_explore/#emit","title":"EMIT","text":""},{"location":"emit_explore/#install-package-with-emit-dependecies","title":"Install package with EMIT dependecies","text":"<p>EMIT requires the <code>netcdf4</code> package to read the products. We will also use the <code>pysolar</code> package to convert the EMIT L1B radiances to reflectances.</p> <pre><code>pip install georeader-spaceml netcdf4 pysolar\n</code></pre>"},{"location":"emit_explore/#download-an-emit-image","title":"Download an EMIT image","text":""},{"location":"emit_explore/#create-and-inspec-emit-object","title":"Create and inspec emit object","text":"<p>EMIT objects let you open an EMIT nc file without loading the content of the file in memory. The object in the cell below has 285 spectral bands. For the API description of the EMIT class see the emit module. Since the object follows the API of georeader, you can read from the rasters using the functions from the read module.</p>"},{"location":"emit_explore/#load-rgb","title":"Load RGB","text":"<p>Select the RGB bands, we see that the raster has only 3 channels now (see Shape in the output of the cell below). The <code>ei</code> object has an attribute called <code>wavelengths</code> with the central wavelength of the hyperspectral band.</p>"},{"location":"emit_explore/#normalize-radiance-to-reflectance","title":"Normalize radiance to reflectance","text":""},{"location":"emit_explore/#reproject-to-utm","title":"Reproject to UTM","text":""},{"location":"emit_explore/#subset-emit-image","title":"Subset EMIT image","text":""},{"location":"emit_explore/#load-image-non-orthorectified","title":"Load image non-orthorectified","text":""},{"location":"emit_explore/#full-image","title":"Full image","text":""},{"location":"emit_explore/#subset","title":"Subset","text":""},{"location":"emit_explore/#load-l2amask","title":"Load L2AMask","text":"<p>The L2AMask is stored in a separated file. The <code>mask</code> array has the following variables:</p>"},{"location":"emit_explore/#load-metadata","title":"Load metadata","text":"<p>Metadata is stored in a separated file (with suffix <code>_OBS_</code> instead of <code>_RAD_</code>). In metadata we have the following variables:</p>"},{"location":"emit_explore/#licence","title":"Licence","text":"<p>The georeader package is published under a GNU Lesser GPL v3 licence</p> <p>If you find this work useful please cite:</p> <pre><code>@article{ruzicka_starcop_2023,\n    title = {Semantic segmentation of methane plumes with hyperspectral machine learning models},\n    volume = {13},\n    issn = {2045-2322},\n    url = {https://www.nature.com/articles/s41598-023-44918-6},\n    doi = {10.1038/s41598-023-44918-6},\n    number = {1},\n    journal = {Scientific Reports},\n    author = {R\u016f\u017ei\u010dka, V\u00edt and Mateo-Garcia, Gonzalo and G\u00f3mez-Chova, Luis and Vaughan, Anna, and Guanter, Luis and Markham, Andrew},\n    month = nov,\n    year = {2023},\n    pages = {19999},\n}\n</code></pre>"},{"location":"enmap_with_cloudsen12/","title":"EnMAP","text":"<p>This notebook requires the <code>cloudsen12_models</code> package <pre><code>pip install georeader-spaceml cloudsen12_models fsspec\n</code></pre></p> <pre><code>from georeader.readers import enmap\nfrom cloudsen12_models import cloudsen12\nfrom georeader import plot\n\nxml_file = \"tempEnMAP/ENMAP01-____L1B-DT0000074101_20240511T080843Z_001_V010402_20240514T093550Z/ENMAP01-____L1B-DT0000074101_20240511T080843Z_001_V010402_20240514T093550Z-METADATA.XML\"\nenmap_reader = enmap.EnMAP(xml_file,by_folder=False)\nenmap_reader\n</code></pre> <pre>\n<code>/home/gonzalo/mambaforge/envs/georeader3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</code>\n</pre> <pre>\n<code>\n        File: tempEnMAP/ENMAP01-____L1B-DT0000074101_20240511T080843Z_001_V010402_20240514T093550Z/ENMAP01-____L1B-DT0000074101_20240511T080843Z_001_V010402_20240514T093550Z-METADATA.XML\n        Bounds: (47.42948365009492, 29.213144376313977, 47.8031320641908, 29.53032430940031)\n        Time: 2024-05-11 08:08:43.855554+00:00\n        Spatial shape (height, width): (1024, 1000)\n        VNIR Range: (411.42039, 1003.9755) nbands: 91 \n        SWIR Range: (892.78475, 2452.4581000000003) nbands: 133\n        </code>\n</pre> <pre><code>%%time\n\nrgb = enmap_reader.load_rgb(apply_rpcs=False)\nplot.show(rgb)\n</code></pre> <pre>\n<code>CPU times: user 588 ms, sys: 940 ms, total: 1.53 s\nWall time: 406 ms\n</code>\n</pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>from georeader.readers import S2_SAFE_reader\n\nsrf = S2_SAFE_reader.read_srf(\"S2A\")\nsrf\n</code></pre> <pre>\n<code>/home/gonzalo/mambaforge/envs/georeader3/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n  warn(msg)\n</code>\n</pre> B01 B02 B03 B04 B05 B06 B07 B08 B8A B09 B10 B11 B12 SR_WL 412 0.001776 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 413 0.004073 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 414 0.003626 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 415 0.003515 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 416 0.005729 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2316 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.010984 2317 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.007360 2318 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.006491 2319 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.004697 2320 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.002059 <p>877 rows \u00d7 13 columns</p> <pre><code>%%time\n\n# Load swir in enmap_reader.units (i.e. radiance units)\nswir = enmap_reader.load_product(\"SPECTRAL_IMAGE_SWIR\")\n</code></pre> <pre>\n<code>CPU times: user 12.4 s, sys: 1.11 s, total: 13.5 s\nWall time: 13.5 s\n</code>\n</pre> <pre><code>from georeader import reflectance\n\nbands_s2_swir = [\"B09\",\"B10\",\"B11\",\"B12\"]\ns2bandsswir = reflectance.transform_to_srf(swir, \n                                           srf[bands_s2_swir],\n                                           wavelengths_hyperspectral=enmap_reader.wl_center[\"swir\"],\n                                           as_reflectance=True,\n                                           observation_date_corr_factor=enmap_reader.observation_date_correction_factor,\n                                           verbose=True,\n                                           units=enmap_reader.units)\n\ns2bandsswir\n</code></pre> <pre>\n<code>2024-10-30 10:31:40(0/4) Processing band B09\n2024-10-30 10:31:40  Loading 4 bands\n2024-10-30 10:31:40  bands loaded, computing tensor\n2024-10-30 10:31:40(1/4) Processing band B10\n2024-10-30 10:31:40  Loading 5 bands\n2024-10-30 10:31:40  bands loaded, computing tensor\n2024-10-30 10:31:41(2/4) Processing band B11\n2024-10-30 10:31:41  Loading 13 bands\n2024-10-30 10:31:41  bands loaded, computing tensor\n2024-10-30 10:31:41(3/4) Processing band B12\n2024-10-30 10:31:41  Loading 30 bands\n2024-10-30 10:31:41  bands loaded, computing tensor\n</code>\n</pre> <pre>\n<code> \n         Transform: | 0.00,-0.00, 47.50|\n|-0.00,-0.00, 29.53|\n| 0.00, 0.00, 1.00|\n         Shape: (4, 1024, 1000)\n         Resolution: (0.0003069912745516993, 0.0002759618727434178)\n         Bounds: (47.42948365009492, 29.213144376313977, 47.8031320641908, 29.53032430940031)\n         CRS: EPSG:4326\n         fill_value_default: 0.0\n        </code>\n</pre> <pre><code>import matplotlib.pyplot as plt\n\nfig, ax =plt.subplots(2,2,figsize=(12,5), tight_layout=True)\nax =ax.flatten()\n\nfor i,b in enumerate(bands_s2_swir):\n    ax[i].hist(s2bandsswir.values[i].ravel())\n    ax[i].set_title(b)\n</code></pre> <pre><code>vnir = enmap_reader.load_product(\"SPECTRAL_IMAGE_VNIR\")\nbands_s2_vnir = [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\"]\ns2bandsvnir = reflectance.transform_to_srf(vnir, \n                                           srf[bands_s2_vnir],\n                                           wavelengths_hyperspectral=enmap_reader.wl_center[\"vnir\"],\n                                           as_reflectance=True,\n                                           observation_date_corr_factor=enmap_reader.observation_date_correction_factor,\n                                           verbose=True,\n                                           extrapolate=True,\n                                           units=enmap_reader.units)\ns2bandsvnir\n</code></pre> <pre>\n<code>2024-10-30 10:31:52(0/9) Processing band B01\n2024-10-30 10:31:52  Loading 8 bands\n2024-10-30 10:31:52  bands loaded, computing tensor\n2024-10-30 10:31:52(1/9) Processing band B02\n2024-10-30 10:31:52  Loading 18 bands\n2024-10-30 10:31:52  bands loaded, computing tensor\n2024-10-30 10:31:53(2/9) Processing band B03\n2024-10-30 10:31:53  Loading 9 bands\n2024-10-30 10:31:53  bands loaded, computing tensor\n2024-10-30 10:31:53(3/9) Processing band B04\n2024-10-30 10:31:53  Loading 7 bands\n2024-10-30 10:31:53  bands loaded, computing tensor\n2024-10-30 10:31:53(4/9) Processing band B05\n2024-10-30 10:31:53  Loading 4 bands\n2024-10-30 10:31:53  bands loaded, computing tensor\n2024-10-30 10:31:53(5/9) Processing band B06\n2024-10-30 10:31:53  Loading 4 bands\n2024-10-30 10:31:53  bands loaded, computing tensor\n2024-10-30 10:31:53(6/9) Processing band B07\n2024-10-30 10:31:53  Loading 4 bands\n2024-10-30 10:31:53  bands loaded, computing tensor\n2024-10-30 10:31:53(7/9) Processing band B08\n2024-10-30 10:31:53  Loading 20 bands\n2024-10-30 10:31:53  bands loaded, computing tensor\n2024-10-30 10:31:53(8/9) Processing band B8A\n2024-10-30 10:31:53  Loading 6 bands\n2024-10-30 10:31:53  bands loaded, computing tensor\n</code>\n</pre> <pre>\n<code> \n         Transform: | 0.00,-0.00, 47.50|\n|-0.00,-0.00, 29.53|\n| 0.00, 0.00, 1.00|\n         Shape: (9, 1024, 1000)\n         Resolution: (0.0003069912745516993, 0.0002759618727434178)\n         Bounds: (47.42948365009492, 29.213144376313977, 47.8031320641908, 29.53032430940031)\n         CRS: EPSG:4326\n         fill_value_default: 0.0\n        </code>\n</pre> <pre><code>fig, ax =plt.subplots(4,2,figsize=(12,10), tight_layout=True)\nax =ax.flatten()\n\nfor i,b in enumerate(bands_s2_vnir[:-1]):\n    ax[i].hist(s2bandsvnir.values[i].ravel())\n    ax[i].set_title(b)\n</code></pre> <pre><code>rgb_s2 = s2bandsvnir.isel({\"band\": [3,2,1]})\nplot.show(rgb_s2)\n</code></pre> <pre>\n<code>/home/gonzalo/git/georeader/georeader/plot.py:119: UserWarning: The transform is not rectilinear. The x and y ticks and the scale bar are not going to be correct. To discard this warning use: warnings.filterwarnings('ignore', message='The transform is not rectilinear.')\n  warnings.warn(\"The transform is not rectilinear. The x and y ticks and the scale bar are not going to be correct.\"\n</code>\n</pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>from georeader.geotensor import GeoTensor\nimport numpy as np\ns2_image = GeoTensor(np.concatenate([s2bandsvnir.values, s2bandsswir.values],axis=0),\n                     transform=s2bandsswir.transform, crs=s2bandsswir.crs, \n                     fill_value_default=s2bandsswir.fill_value_default)\ns2_image\n</code></pre> <pre>\n<code> \n         Transform: | 0.00,-0.00, 47.50|\n|-0.00,-0.00, 29.53|\n| 0.00, 0.00, 1.00|\n         Shape: (13, 1024, 1000)\n         Resolution: (0.0003069912745516993, 0.0002759618727434178)\n         Bounds: (47.42948365009492, 29.213144376313977, 47.8031320641908, 29.53032430940031)\n         CRS: EPSG:4326\n         fill_value_default: 0.0\n        </code>\n</pre> <pre><code>swir_nir_red = (s2_image.isel({\"band\": [S2_SAFE_reader.BANDS_S2_L1C.index(b) for b in [\"B11\", \"B08\", \"B04\"]]}) / .45).clip(0,1)\n\nplot.show(swir_nir_red)\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>model_4bands = cloudsen12.load_model_by_name(name=\"dtacs4bands\", weights_folder=\"cloudsen12_models\")\ncloudmask = model_4bands.predict(s2_image.isel({\"band\": [S2_SAFE_reader.BANDS_S2_L1C.index(b) for b in model_4bands.bands]}))\n\nfig, ax = plt.subplots(1,2,figsize=(14,5),sharey=True, tight_layout=True)\n\nplot.show(swir_nir_red,ax=ax[0])\ncloudsen12.plot_cloudSEN12mask(cloudmask, ax=ax[1])\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>model = cloudsen12.load_model_by_name(name=\"UNetMobV2_V2\", weights_folder=\"cloudsen12_models\")\ncloudmask = model.predict(s2_image)\n\nfig, ax = plt.subplots(1,2,figsize=(14,5),sharey=True, tight_layout=True)\n\nplot.show(swir_nir_red,ax=ax[0])\ncloudsen12.plot_cloudSEN12mask(cloudmask, ax=ax[1])\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre>"},{"location":"enmap_with_cloudsen12/#enmap","title":"EnMAP","text":""},{"location":"prisma_with_cloudsen12/","title":"PRISMA cloud detection","text":"<pre><code>from georeader.readers import prisma\nfrom cloudsen12_models import cloudsen12\nfrom georeader import plot\n</code></pre> <pre>\n<code>/home/gonzalo/mambaforge/envs/marsmlpy312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</code>\n</pre> <pre><code>file = \"rasters/PRS_L1_STD_OFFL_20241109073054_20241109073059_0001.he5\"\nprisma_reader = prisma.PRISMA(file)\nprisma_reader\n</code></pre> <pre>\n<code>\n        File: rasters/PRS_L1_STD_OFFL_20241109073054_20241109073059_0001.he5\n        Bounds: (47.82221221923828, 29.50290870666504, 48.19811248779297, 29.824541091918945)\n        Time: 2024-11-09 07:30:54.783000+00:00\n        VNIR Range: (406.9934, 977.3654) 63 bands\n        SWIR Range: (943.3579, 2497.1155) 171 bands\n        </code>\n</pre> <pre><code>from georeader.readers import S2_SAFE_reader\n\nsrf = S2_SAFE_reader.read_srf(\"S2A\")\nsrf\n</code></pre> <pre>\n<code>/home/gonzalo/mambaforge/envs/marsmlpy312/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n  warn(msg)\n</code>\n</pre> B01 B02 B03 B04 B05 B06 B07 B08 B8A B09 B10 B11 B12 SR_WL 412 0.001776 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 413 0.004073 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 414 0.003626 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 415 0.003515 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 416 0.005729 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2316 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.010984 2317 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.007360 2318 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.006491 2319 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.004697 2320 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.002059 <p>877 rows \u00d7 13 columns</p> <pre><code>%%time\nimport numpy as np\n# Load VNIR-SWIR in prisma units (i.e. radiance units)\nvnir = prisma_reader.load_raw(swir_flag=False); print(vnir.shape)\nswir = prisma_reader.load_raw(swir_flag=True); print(swir.shape)\nvnir_swir = np.moveaxis(np.concatenate((vnir, swir), axis = 2), 2, 0)\n# Load VNIR-SWIR central wavelengths\nvnir_wvl = prisma_reader.wavelength_vnir[0]\nswir_wvl = prisma_reader.wavelength_swir[0]\nvnir_swir_wvl = np.concatenate((vnir_wvl, swir_wvl))\n</code></pre> <pre>\n<code>(1000, 1000, 63)\n(1000, 1000, 171)\nCPU times: user 7.46 s, sys: 1.39 s, total: 8.86 s\nWall time: 8.85 s\n</code>\n</pre> <pre><code>from georeader import reflectance\ns2bands = reflectance.transform_to_srf(vnir_swir, \n                                           srf,\n                                           wavelengths_hyperspectral=vnir_swir_wvl,\n                                           as_reflectance=True,\n                                           observation_date_corr_factor=prisma_reader.observation_date_correction_factor,\n                                           verbose=True,\n                                           units=prisma_reader.units)\ntype(s2bands)\n</code></pre> <pre>\n<code>2025-01-31 09:25:09(0/13) Processing band B01\n2025-01-31 09:25:09  Loading 7 bands\n2025-01-31 09:25:09  bands loaded, computing tensor\n2025-01-31 09:25:09(1/13) Processing band B02\n2025-01-31 09:25:09  Loading 12 bands\n2025-01-31 09:25:09  bands loaded, computing tensor\n</code>\n</pre> <pre>\n<code>/home/gonzalo/mambaforge/envs/marsmlpy312/lib/python3.12/site-packages/pysolar/solartime.py:113: UserWarning: I don't know about leap seconds after 2023\n  warnings.warn \\\n</code>\n</pre> <pre>\n<code>2025-01-31 09:25:10(2/13) Processing band B03\n2025-01-31 09:25:10  Loading 7 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(3/13) Processing band B04\n2025-01-31 09:25:10  Loading 5 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(4/13) Processing band B05\n2025-01-31 09:25:10  Loading 3 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(5/13) Processing band B06\n2025-01-31 09:25:10  Loading 3 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(6/13) Processing band B07\n2025-01-31 09:25:10  Loading 4 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(7/13) Processing band B08\n2025-01-31 09:25:10  Loading 14 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(8/13) Processing band B8A\n2025-01-31 09:25:10  Loading 5 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(9/13) Processing band B09\n2025-01-31 09:25:10  Loading 5 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(10/13) Processing band B10\n2025-01-31 09:25:10  Loading 8 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(11/13) Processing band B11\n2025-01-31 09:25:10  Loading 14 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n2025-01-31 09:25:10(12/13) Processing band B12\n2025-01-31 09:25:10  Loading 32 bands\n2025-01-31 09:25:10  bands loaded, computing tensor\n</code>\n</pre> <pre>\n<code>numpy.ndarray</code>\n</pre> <pre><code>import matplotlib.pyplot as plt\n\nbands_s2 = [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\", \"B09\",\"B10\",\"B11\",\"B12\"]\n\nfig, ax =plt.subplots(7,2,figsize=(10,10), tight_layout=True)\nax =ax.flatten()\n\nfor i,b in enumerate(bands_s2):\n    ax[i].hist(s2bands[i].ravel())\n    ax[i].set_title(b)\n</code></pre> <pre><code>s2bands.shape\nnp.moveaxis(s2bands, 0, 2).astype(np.float32).shape\n</code></pre> <pre>\n<code>(1000, 1000, 13)</code>\n</pre> <pre><code>from georeader import griddata\nfrom georeader.geotensor import GeoTensor\ns2_image = griddata.read_to_crs(np.moveaxis(s2bands, 0, 2).astype(np.float32), \n                                lons=prisma_reader.lons, lats=prisma_reader.lats, \n                                resolution_dst=30)\ns2_image\n</code></pre> <pre>\n<code> \n         Transform: | 30.00, 0.00, 192085.06|\n| 0.00,-30.00, 3303421.30|\n| 0.00, 0.00, 1.00|\n         Shape: (13, 1211, 1235)\n         Resolution: (30.0, 30.0)\n         Bounds: (192085.06318415108, 3267091.300334674, 229135.06318415108, 3303421.300334674)\n         CRS: EPSG:32639\n         fill_value_default: -1\n        </code>\n</pre> <pre><code>swir_nir_red = (s2_image.isel({\"band\": [S2_SAFE_reader.BANDS_S2_L1C.index(b) for b in [\"B11\", \"B08\", \"B04\"]]}) / .45).clip(0,1)\n\nplot.show(swir_nir_red)\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>model_4bands = cloudsen12.load_model_by_name(name=\"dtacs4bands\", weights_folder=\"cloudsen12_models\")\ncloudmask = model_4bands.predict(s2bands[[S2_SAFE_reader.BANDS_S2_L1C.index(b) for b in model_4bands.bands]])\n\ncloudmask_geotensor = griddata.read_to_crs(cloudmask,\n                                           lons=prisma_reader.lons, lats=prisma_reader.lats, \n                                           resolution_dst=30, method=\"nearest\")\n</code></pre> <pre><code>invalids = np.all(swir_nir_red.values == 0,axis=0)\ncloudmask_geotensor.values[invalids] = np.nan\n# swir_nir_red.values[:, invalids] = np.nan\n</code></pre> <pre><code>cloudsen12.plot_cloudSEN12mask(cloudmask_geotensor, ax=ax[1])\n\nfig, ax = plt.subplots(1,2,figsize=(14,5),sharey=True, tight_layout=True)\n\nplot.show(swir_nir_red,ax=ax[0])\ncloudsen12.plot_cloudSEN12mask(cloudmask_geotensor, ax=ax[1])\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre>"},{"location":"prisma_with_cloudsen12/#run-cloudsen12-models-in-prisma","title":"Run CloudSEN12 models in PRISMA","text":"<ul> <li>Authors: Gonzalo Mateo-Garc\u00eda, Manuel Montesino Martin</li> </ul> <p>This tutorial shows how to run <code>CloudSEN12</code>cloud detection models in a PRISMA image. It requires the <code>cloudsen12_models</code> package.</p> <pre><code>pip install cloudsen12_models georeader-spaceml\n</code></pre>"},{"location":"prisma_with_cloudsen12/#licence","title":"Licence","text":"<p>The <code>cloudsen12_models</code> package is published under a GNU Lesser GPL v3 licence</p> <p>The CloudSEN12 database and all pre-trained models are released under a Creative Commons non-commercial licence. For using the models in comercial pipelines written consent by the authors must be provided.</p> <p>This notebook is released under a Creative Commons non-commercial licence.</p> <p>If you find this work useful please cite: <pre><code>@article{aybar_cloudsen12_2024,\n    title = {{CloudSEN12}+: {The} largest dataset of expert-labeled pixels for cloud and cloud shadow detection in {Sentinel}-2},\n    issn = {2352-3409},\n    url = {https://www.sciencedirect.com/science/article/pii/S2352340924008163},\n    doi = {10.1016/j.dib.2024.110852},\n    journal = {Data in Brief},\n    author = {Aybar, Cesar and Bautista, Lesly and Montero, David and Contreras, Julio and Ayala, Daryl and Prudencio, Fernando and Loja, Jhomira and Ysuhuaylas, Luis and Herrera, Fernando and Gonzales, Karen and Valladares, Jeanett and Flores, Lucy A. and Mamani, Evelin and Qui\u00f1onez, Maria and Fajardo, Rai and Espinoza, Wendy and Limas, Antonio and Yali, Roy and Alc\u00e1ntara, Alejandro and Leyva, Martin and Loayza-Muro, Rau\u00b4l and Willems, Bram and Mateo-Garc\u00eda, Gonzalo and G\u00f3mez-Chova, Luis},\n    month = aug,\n    year = {2024},\n    pages = {110852},\n}\n</code></pre></p>"},{"location":"read_S2_SAFE_from_bucket/","title":"From the public bucket","text":"<pre><code>!pip install georeader-spaceml fsspec gcsfs\n</code></pre> <pre><code>import os\nfrom georeader.readers import S2_SAFE_reader\n\nos.environ[\"GS_NO_SIGN_REQUEST\"] = \"YES\"\n\n# Donwload key from next line link to access the buckets and requester pays requests to public bucket (this is needed to query Sentinel-2 data)\n# This is required to do advaced operations in the GCP bucket\n# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"path/to/file.json\"\n# os.environ[\"GS_USER_PROJECT\"] = \"project-name\"\n# S2_SAFE_reader.DEFAULT_REQUESTER_PAYS=True\n</code></pre> <pre><code>%%time\n\nsafe_file = \"S2B_MSIL1C_20220527T030539_N0400_R075_T49SGV_20220527T051042.SAFE\"\ns2_safe_folder = S2_SAFE_reader.s2_public_bucket_path(safe_file, check_exists=False)\n\nprint(f\"File is located at: {s2_safe_folder}\")\n\ns2obj = S2_SAFE_reader.s2loader(s2_safe_folder, out_res=10)\n\nos.makedirs(\"deleteme\",exist_ok=True)\ns2obj = s2obj.cache_product_to_local_dir(\"deleteme\")\n\ns2obj\n</code></pre> <pre>\n<code>File is located at: gs://gcp-public-data-sentinel-2/tiles/49/S/GV/S2B_MSIL1C_20220527T030539_N0400_R075_T49SGV_20220527T051042.SAFE\n</code>\n</pre> <pre>\n<code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:00&lt;00:00, 26341.04it/s]</code>\n</pre> <pre>\n<code>CPU times: user 410 ms, sys: 40.2 ms, total: 450 ms\nWall time: 529 ms\n</code>\n</pre> <pre>\n<code>\n</code>\n</pre> <pre>\n<code> \n         deleteme/S2B_MSIL1C_20220527T030539_N0400_R075_T49SGV_20220527T051042.SAFE\n         Transform: | 10.00, 0.00, 699960.00|\n| 0.00,-10.00, 4000020.00|\n| 0.00, 0.00, 1.00|\n         Shape: (13, 10980, 10980)\n         Resolution: (10.0, 10.0)\n         Bounds: (699960.0, 3890220.0, 809760.0, 4000020.0)\n         CRS: EPSG:32649\n         bands: ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B11', 'B12']\n         fill_value_default: 0\n        </code>\n</pre> <p>Select the bands and bounds to read and trigger <code>load</code> (to read the data in memory)</p> <pre><code>%%time\nfrom georeader import read\nbounds_read = (759760.0, 3940220.0, 799760.0, 3960220.0)\n\ns2obj_3bands = s2obj.read_from_band_names([\"B04\", \"B03\", \"B02\"])\ndata = read.read_from_bounds(s2obj_3bands, bounds_read) # This does not trigger the download of the data\ndata_memory = data.load() # this triggers download only for the selected bands and within the bounds\ndata_memory\n</code></pre> <pre>\n<code>CPU times: user 24.2 s, sys: 410 ms, total: 24.7 s\nWall time: 2.44 s\n</code>\n</pre> <pre>\n<code> \n         Transform: | 10.00, 0.00, 759760.00|\n| 0.00,-10.00, 3960220.00|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 2000, 4000)\n         Resolution: (10.0, 10.0)\n         Bounds: (759760.0, 3940220.0, 799760.0, 3960220.0)\n         CRS: EPSG:32649\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>s2obj.radio_add_offsets()\n</code></pre> <pre>\n<code>{'B01': -1000,\n 'B02': -1000,\n 'B03': -1000,\n 'B04': -1000,\n 'B05': -1000,\n 'B06': -1000,\n 'B07': -1000,\n 'B08': -1000,\n 'B8A': -1000,\n 'B09': -1000,\n 'B10': -1000,\n 'B11': -1000,\n 'B12': -1000}</code>\n</pre> <pre><code>import numpy as np\ncosa = np.array([1001,10002,1000], dtype=np.uint16)\ncosa - 1006\n</code></pre> <pre>\n<code>array([65531,  8996, 65530], dtype=uint16)</code>\n</pre> <p>The <code>numpy.array</code> is stored in the <code>values</code> property.</p> <pre><code>%%time\ndata_memory.values\n</code></pre> <pre>\n<code>CPU times: user 10 \u00b5s, sys: 0 ns, total: 10 \u00b5s\nWall time: 18.6 \u00b5s\n</code>\n</pre> <pre>\n<code>array([[[1314, 1139, 1156, ..., 1517, 1730, 1561],\n        [1309, 1142, 1274, ..., 1581, 1730, 1508],\n        [1335, 1288, 1526, ..., 1659, 1688, 1395],\n        ...,\n        [1510, 1539, 1567, ..., 1012, 1016, 1028],\n        [1479, 1514, 1545, ...,  974,  952,  954],\n        [1517, 1515, 1555, ...,  951,  952,  946]],\n\n       [[1395, 1271, 1275, ..., 1460, 1567, 1423],\n        [1355, 1260, 1347, ..., 1450, 1584, 1385],\n        [1396, 1360, 1502, ..., 1483, 1569, 1326],\n        ...,\n        [1570, 1585, 1595, ..., 1159, 1160, 1147],\n        [1563, 1572, 1578, ..., 1151, 1133, 1105],\n        [1555, 1576, 1562, ..., 1147, 1135, 1112]],\n\n       [[1398, 1301, 1320, ..., 1560, 1629, 1459],\n        [1386, 1319, 1403, ..., 1608, 1605, 1418],\n        [1417, 1401, 1544, ..., 1633, 1561, 1377],\n        ...,\n        [1690, 1699, 1687, ..., 1216, 1218, 1215],\n        [1665, 1670, 1666, ..., 1213, 1208, 1195],\n        [1653, 1647, 1652, ..., 1204, 1208, 1191]]], dtype=uint16)</code>\n</pre> <p>Plot the data that we have read</p> <pre><code>%%time\n\nimport rasterio.plot as rstplt\nimport numpy as np\n\n# From processing baseline PB04.00  values have an offset of 1_000. \n# This is handled automatically by the load function\nrstplt.show(np.clip(data_memory.values/3_000,0,1), transform=data_memory.transform)\n</code></pre> <pre>\n<code>CPU times: user 3.99 s, sys: 498 ms, total: 4.49 s\nWall time: 4.6 s\n</code>\n</pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code># import shutil\n\n# if os.path.exists(\"deleteme\"):\n#     shutil.rmtree(\"deleteme\")\n</code></pre>"},{"location":"read_S2_SAFE_from_bucket/#read-sentinel-2-files-from-public-bucket","title":"Read Sentinel-2 files from public bucket","text":"<p>Set the env variables to be able to read from the Google bucket. This is needed to cover reading costs</p>"},{"location":"read_S2_SAFE_from_bucket/#licence","title":"Licence","text":"<p>The georeader package is published under a GNU Lesser GPL v3 licence</p> <p>If you find this work useful please cite:</p> <pre><code>@article{portales-julia_global_2023,\n    title = {Global flood extent segmentation in optical satellite images},\n    volume = {13},\n    issn = {2045-2322},\n    doi = {10.1038/s41598-023-47595-7},\n    number = {1},\n    urldate = {2023-11-30},\n    journal = {Scientific Reports},\n    author = {Portal\u00e9s-Juli\u00e0, Enrique and Mateo-Garc\u00eda, Gonzalo and Purcell, Cormac and G\u00f3mez-Chova, Luis},\n    month = nov,\n    year = {2023},\n    pages = {20316},\n}\n</code></pre>"},{"location":"read_overlapping_probav_and_sentinel2/","title":"Overlapping S2 and Proba-V","text":"<p>Download the Proba-V image</p> <pre><code>from georeader.readers import download_pv_product\n\nlink_pv_product = \"https://www.vito-eodata.be/PDF/datapool/Free_Data/PROBA-V_100m/S1_TOA_100_m_C1/2019/2/9/PV_S1_TOA-20190209_100M_V101/PROBAV_S1_TOA_X07Y05_20190209_100M_V101.HDF5\"\nfilename_down = download_pv_product.download_product(link_pv_product)\nfilename_down\n</code></pre> <pre>\n<code>File PROBAV_S1_TOA_X07Y05_20190209_100M_V101.HDF5 exists. It won't be downloaded again\n</code>\n</pre> <pre><code>%%time\n\nfrom georeader.readers import probav_image_operational\n\ntoa_reader = probav_image_operational.ProbaVRadiometry(filename_down, level_name=\"LEVEL3\")\ntoa_reader\n</code></pre> <pre>\n<code>CPU times: user 807 ms, sys: 164 ms, total: 972 ms\nWall time: 1.88 s\n</code>\n</pre> <pre>\n<code>/home/gonzalo/miniconda3/envs/starcop/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</code>\n</pre> <pre>\n<code> \n         File: PROBAV_S1_TOA_X07Y05_20190209_100M_V101.HDF5\n         Transform: | 0.00, 0.00,-110.00|\n| 0.00,-0.00, 25.00|\n| 0.00, 0.00, 1.00|\n         Shape: 10080, 10080\n         Resolution: (0.000992063492063, 0.000992063492063)\n         Bounds: (-110.0, 15.00000000000496, -100.00000000000496, 25.0)\n         CRS: {'init': 'epsg:4326'}\n         Level: LEVEL3\n         TOA/TOC: TOA\n         Resolution name : 100M\n        </code>\n</pre> <pre><code>toa_reader.assert_can_be_read()\n# If this raises an error reinstall h5py with pip and reset the notebook:\n# pip install h5py --no-deps --ignore-installed\n</code></pre> <pre><code>from georeader.rasterio_reader import RasterioReader\n\ns2reader = RasterioReader(\"S2L1C.tif\")\ns2reader\n</code></pre> <pre>\n<code> \n         Paths: ['S2L1C.tif']\n         Transform: | 10.00, 0.00, 770950.00|\n| 0.00,-10.00, 2696720.00|\n| 0.00, 0.00, 1.00|\n         Shape: (13, 509, 509)\n         Resolution: (10.0, 10.0)\n         Bounds: (770950.0, 2691630.0, 776040.0, 2696720.0)\n         CRS: EPSG:32613\n         nodata: None\n         fill_value_default: 0\n        </code>\n</pre> <p>Band names are stored in the <code>descriptions</code> attribute</p> <pre><code>s2reader.descriptions\n</code></pre> <pre>\n<code>['B1',\n 'B2',\n 'B3',\n 'B4',\n 'B5',\n 'B6',\n 'B7',\n 'B8',\n 'B8A',\n 'B9',\n 'B10',\n 'B11',\n 'B12']</code>\n</pre> <p>Set the reader to read the BLUE, RED NIR and SWIR bands of Sentinel-2 that are equivalent to the bands of Proba-V.</p> <pre><code>s2reader.set_indexes_by_name([\"B2\",\"B4\", \"B8\",\"B11\"])\ns2reader\n</code></pre> <pre>\n<code> \n         Paths: ['S2L1C.tif']\n         Transform: | 10.00, 0.00, 770950.00|\n| 0.00,-10.00, 2696720.00|\n| 0.00, 0.00, 1.00|\n         Shape: (4, 509, 509)\n         Resolution: (10.0, 10.0)\n         Bounds: (770950.0, 2691630.0, 776040.0, 2696720.0)\n         CRS: EPSG:32613\n         nodata: None\n         fill_value_default: 0\n        </code>\n</pre> <pre><code># Read image in memory\ns2reader_memory = s2reader.load()\ns2reader_memory.values\n</code></pre> <pre>\n<code>array([[[ 998.,  976.,  954., ...,  948.,  879.,  995.],\n        [1013.,  956.,  942., ..., 1181., 1133., 1080.],\n        [1028.,  957.,  989., ..., 1125., 1173., 1257.],\n        ...,\n        [1596., 1579., 1472., ..., 1203., 1256., 1191.],\n        [1548., 1433., 1360., ..., 1296., 1325., 1225.],\n        [1550., 1539., 1377., ..., 1406., 1371., 1298.]],\n\n       [[1032., 1015.,  899., ...,  930.,  848.,  988.],\n        [1045.,  948.,  891., ..., 1296., 1209., 1164.],\n        [1119.,  918.,  988., ..., 1233., 1334., 1502.],\n        ...,\n        [2360., 2318., 2084., ..., 1491., 1541., 1490.],\n        [2305., 2049., 1953., ..., 1650., 1685., 1476.],\n        [2366., 2126., 2023., ..., 1815., 1730., 1642.]],\n\n       [[1387., 1377., 1191., ..., 1262., 1103., 1283.],\n        [1374., 1262., 1195., ..., 1635., 1580., 1559.],\n        [1432., 1319., 1351., ..., 1501., 1747., 1885.],\n        ...,\n        [2563., 2576., 2363., ..., 1943., 1975., 1939.],\n        [2527., 2290., 2204., ..., 2173., 2085., 1940.],\n        [2630., 2472., 2259., ..., 2355., 2178., 2146.]],\n\n       [[2583., 2502., 2502., ..., 2716., 2732., 2732.],\n        [2583., 2502., 2502., ..., 2716., 2732., 2732.],\n        [2691., 2545., 2545., ..., 2653., 2852., 2852.],\n        ...,\n        [3995., 3813., 3813., ..., 3097., 3066., 3066.],\n        [3995., 3813., 3813., ..., 3097., 3066., 3066.],\n        [4063., 3725., 3725., ..., 3314., 3262., 3262.]]], dtype=float32)</code>\n</pre> <pre><code>%%time\nfrom georeader import read\n\ntile_read = read.read_from_bounds(toa_reader, bounds=s2reader.bounds, crs_bounds=s2reader.crs,\n                                  pad_add=(50, 50))\ntile_read\n</code></pre> <pre>\n<code>CPU times: user 18.8 ms, sys: 0 ns, total: 18.8 ms\nWall time: 34 ms\n</code>\n</pre> <pre>\n<code> \n         File: PROBAV_S1_TOA_X07Y05_20190209_100M_V101.HDF5\n         Transform: | 0.00, 0.00,-102.38|\n| 0.00,-0.00, 24.41|\n| 0.00, 0.00, 1.00|\n         Shape: 148, 152\n         Resolution: (0.000992063492063, 0.000992063492063)\n         Bounds: (-102.3799603174641, 24.263888888889255, -102.22916666667052, 24.41071428571458)\n         CRS: {'init': 'epsg:4326'}\n         Level: LEVEL3\n         TOA/TOC: TOA\n         Resolution name : 100M\n        </code>\n</pre> <pre><code>tile_read_memory = tile_read.load()\ntile_read_memory.values\n</code></pre> <pre>\n<code>array([[[0.1295, 0.1285, 0.1255, ..., 0.151 , 0.152 , 0.149 ],\n        [0.1315, 0.1305, 0.129 , ..., 0.15  , 0.15  , 0.1515],\n        [0.131 , 0.135 , 0.137 , ..., 0.1495, 0.1475, 0.143 ],\n        ...,\n        [0.2445, 0.2405, 0.238 , ..., 0.1335, 0.1365, 0.136 ],\n        [0.2415, 0.238 , 0.233 , ..., 0.138 , 0.131 , 0.1355],\n        [0.237 , 0.2385, 0.234 , ..., 0.135 , 0.1275, 0.1365]],\n\n       [[0.1205, 0.1185, 0.119 , ..., 0.1725, 0.1745, 0.176 ],\n        [0.1185, 0.1205, 0.1275, ..., 0.1705, 0.1715, 0.172 ],\n        [0.1265, 0.1465, 0.155 , ..., 0.167 , 0.164 , 0.163 ],\n        ...,\n        [0.249 , 0.2455, 0.243 , ..., 0.116 , 0.1255, 0.122 ],\n        [0.245 , 0.2395, 0.236 , ..., 0.1325, 0.124 , 0.1225],\n        [0.2385, 0.2325, 0.2255, ..., 0.123 , 0.1115, 0.125 ]],\n\n       [[0.156 , 0.154 , 0.153 , ..., 0.227 , 0.2335, 0.229 ],\n        [0.153 , 0.1575, 0.165 , ..., 0.2245, 0.2245, 0.2305],\n        [0.1625, 0.18  , 0.196 , ..., 0.2225, 0.22  , 0.218 ],\n        ...,\n        [0.286 , 0.286 , 0.2855, ..., 0.173 , 0.182 , 0.174 ],\n        [0.2845, 0.2785, 0.277 , ..., 0.1825, 0.1735, 0.1725],\n        [0.2795, 0.2755, 0.2695, ..., 0.171 , 0.154 , 0.1695]],\n\n       [[0.228 , 0.2295, 0.2325, ..., 0.36  , 0.3575, 0.3555],\n        [0.237 , 0.2425, 0.2485, ..., 0.363 , 0.3575, 0.3565],\n        [0.248 , 0.2555, 0.261 , ..., 0.3625, 0.352 , 0.349 ],\n        ...,\n        [0.302 , 0.3015, 0.3005, ..., 0.2235, 0.228 , 0.2365],\n        [0.3005, 0.2995, 0.298 , ..., 0.2265, 0.229 , 0.2405],\n        [0.3015, 0.299 , 0.297 , ..., 0.2275, 0.232 , 0.2465]]],\n      dtype=float32)</code>\n</pre> <pre><code>%%time\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# SWIR, NIR, RED composite\nrgb_show = np.transpose(tile_read.values[:0:-1],(1,2,0))\nplt.imshow(rgb_show)\n</code></pre> <pre>\n<code>CPU times: user 627 ms, sys: 19.1 ms, total: 646 ms\nWall time: 712 ms\n</code>\n</pre> <pre>\n<code>&lt;matplotlib.image.AxesImage at 0x7fa66f827c70&gt;</code>\n</pre> <pre><code>plt.imshow(np.clip(s2reader_memory.values[:0:-1]/10_000,0,1).transpose((1,2,0)))\n</code></pre> <pre>\n<code>&lt;matplotlib.image.AxesImage at 0x7fa665f3e3d0&gt;</code>\n</pre> <pre><code>probav_100m_utm = read.read_reproject(toa_reader, bounds=s2reader.bounds, dst_crs=s2reader.crs,\n                                      resolution_dst_crs=100)\nprobav_100m_utm\n</code></pre> <pre>\n<code> \n         Transform: | 100.00, 0.00, 770950.00|\n| 0.00,-100.00, 2696720.00|\n| 0.00, 0.00, 1.00|\n         Shape: (4, 51, 51)\n         Resolution: (100.0, 100.0)\n         Bounds: (770950.0, 2691620.0, 776050.0, 2696720.0)\n         CRS: EPSG:32613\n         fill_value_default: -0.0005\n        </code>\n</pre> <p>Secondly we will reproject Sentinel-2 to 100m using an anti-aliasing filter to avoid artifacts.</p> <pre><code>s2reader_memory.set_dtype(np.float32) # Convert to float to avoid resampling errors!\n\ns2_100m = read.resize(s2reader_memory, resolution_dst=100, anti_aliasing=True)\ns2_100m\n</code></pre> <pre>\n<code> \n         Transform: | 100.00, 0.00, 770950.00|\n| 0.00,-100.00, 2696720.00|\n| 0.00, 0.00, 1.00|\n         Shape: (4, 51, 51)\n         Resolution: (100.0, 100.0)\n         Bounds: (770950.0, 2691620.0, 776050.0, 2696720.0)\n         CRS: EPSG:32613\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>fig, ax = plt.subplots(2,3,figsize=(18,12))\nax[0,0].imshow(probav_100m_utm.values[:0:-1].transpose((1,2,0)))\nax[0,0].set_title(\"Proba-V 100m (UTM grid) SWIR/NIR/RED\")\nax[0,1].imshow(np.clip(s2_100m.values[:0:-1].transpose((1,2,0))/10_000,0,1))\nax[0,1].set_title(\"Sentinel-2 100m SWIR/NIR/RED\")\nax[0,2].imshow(np.clip(s2reader_memory.values[:0:-1].transpose((1,2,0))/10_000,0,1))\nax[0,2].set_title(\"Sentinel-2 10m SWIR/NIR/RED\")\n\nax[1,0].imshow(probav_100m_utm.values[-2::-1].transpose((1,2,0)))\nax[1,0].set_title(\"Proba-V 100m (UTM grid) NIR/RED/BLUE\")\nax[1,1].imshow(np.clip(s2_100m.values[-2::-1].transpose((1,2,0))/10_000,0,1))\nax[1,1].set_title(\"Sentinel-2 100m NIR/RED/BLUE\")\nax[1,2].imshow(np.clip(s2reader_memory.values[-2::-1].transpose((1,2,0))/10_000,0,1))\nax[1,2].set_title(\"Sentinel-2 10m NIR/RED/BLUE\")\n</code></pre> <pre>\n<code>Text(0.5, 1.0, 'Sentinel-2 10m NIR/RED/BLUE')</code>\n</pre>"},{"location":"read_overlapping_probav_and_sentinel2/#read-overlapping-images-from-proba-v-and-sentinel-2","title":"Read overlapping images from Proba-V and Sentinel-2","text":"<p>Given a Sentinel-2 GeoTIFF file from the CloudSEN12 dataset and a Proba-V image we will show how to read the overlapping regions of those two using the georeader package.</p> <p>The Sentinel-2 image from CloudSEN12 that we will use in this tutorial is: <code>cloudsen12/high/point_0317/20190207T172509_20190207T173213_T13QGG/S2L1C.tif</code>. In order to proceed you need to download the image and store it in the same directory as this tutorial.</p>"},{"location":"read_overlapping_probav_and_sentinel2/#install-package-with-proba-v-dependecies","title":"Install package with Proba-V dependecies","text":"<pre><code>pip install git+https://github.com/spaceml-org/georeader#egg=georeader[probav]\n</code></pre>"},{"location":"read_overlapping_probav_and_sentinel2/#inspect-proba-v-products","title":"Inspect Proba-V products","text":"<p>Prova-V images are very large (10,080x10,080 pixels). Therefore we should avoid read them all in memory if possible.</p>"},{"location":"read_overlapping_probav_and_sentinel2/#warning","title":"Warning!!","text":"<p>To read the Proba-V image content the <code>h5py</code> package requires an special compression. If installed from conda this compressor is not available. Therefore, re-install h5py from pip if the following cell fails!</p> <p><code>pip install h5py --no-deps --ignore-installed</code></p>"},{"location":"read_overlapping_probav_and_sentinel2/#read-sentinel-2-file-of-the-cloudsen12-dataset","title":"Read Sentinel-2 file of the cloudSEN12 dataset","text":""},{"location":"read_overlapping_probav_and_sentinel2/#read-proba-v-image-within-the-bounds-of-the-sentinel-2","title":"Read Proba-V image within the bounds of the Sentinel-2","text":""},{"location":"read_overlapping_probav_and_sentinel2/#reproject-proba-v-and-sentinel-2","title":"Reproject Proba-V and Sentinel-2","text":"<p>First we will reproject the Proba-V image to the UTM crs of Sentinel-2 at a 100m resolution</p>"},{"location":"read_overlapping_probav_and_sentinel2/#licence","title":"Licence","text":"<p>The georeader package is published under a GNU Lesser GPL v3 licence</p> <p>If you find this work useful please cite:</p> <pre><code>@article{portales-julia_global_2023,\n    title = {Global flood extent segmentation in optical satellite images},\n    volume = {13},\n    issn = {2045-2322},\n    doi = {10.1038/s41598-023-47595-7},\n    number = {1},\n    urldate = {2023-11-30},\n    journal = {Scientific Reports},\n    author = {Portal\u00e9s-Juli\u00e0, Enrique and Mateo-Garc\u00eda, Gonzalo and Purcell, Cormac and G\u00f3mez-Chova, Luis},\n    month = nov,\n    year = {2023},\n    pages = {20316},\n}\n</code></pre>"},{"location":"reading_overlapping_sentinel2_aviris/","title":"Overlapping S2 and AVIRIS","text":"<p>Step 1: Create the reader object for the AVIRIS image</p> <pre><code>%%time\n\nfrom georeader.rasterio_reader import RasterioReader\n\naviris_reader = RasterioReader(\"/home/gonzalo/Downloads/permian_2019/permian_2019/ang20190928t185111-4_r6871_c424_rgb.tif\")\naviris_reader\n</code></pre> <pre>\n<code>CPU times: user 519 ms, sys: 1.84 s, total: 2.36 s\nWall time: 163 ms\n</code>\n</pre> <pre>\n<code> \n         Paths: ['/home/gonzalo/Downloads/permian_2019/permian_2019/ang20190928t185111-4_r6871_c424_rgb.tif']\n         Transform: | 5.99, 4.35, 592577.80|\n| 4.35,-5.99, 3519916.50|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 151, 151)\n         Resolution: (7.400000000000001, 7.400000000000001)\n         Bounds: (592577.7996484624, 3519012.5018222863, 594138.5864788886, 3520573.2886527125)\n         CRS: EPSG:32613\n         nodata: None\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>%%time\n\naviris_reader_in_memory = aviris_reader.load()\naviris_reader_in_memory.values\n</code></pre> <pre>\n<code>CPU times: user 0 ns, sys: 2.35 ms, total: 2.35 ms\nWall time: 2.35 ms\n</code>\n</pre> <pre>\n<code>array([[[253, 254, 237, ..., 187, 181, 134],\n        [231, 221, 199, ..., 203, 197, 164],\n        [193, 194, 194, ..., 212, 202, 193],\n        ...,\n        [ 90,  88,  88, ..., 183, 160, 170],\n        [ 92,  95,  95, ..., 192, 172, 181],\n        [ 88,  93,  89, ..., 194, 187, 210]],\n\n       [[235, 230, 213, ..., 172, 165, 131],\n        [216, 203, 181, ..., 185, 180, 153],\n        [184, 178, 177, ..., 189, 182, 178],\n        ...,\n        [ 96,  96,  96, ..., 183, 162, 171],\n        [ 99, 100, 100, ..., 191, 173, 181],\n        [ 97,  98,  96, ..., 193, 185, 205]],\n\n       [[190, 183, 163, ..., 148, 141, 116],\n        [174, 165, 142, ..., 151, 152, 129],\n        [151, 145, 143, ..., 148, 147, 148],\n        ...,\n        [102, 101, 100, ..., 166, 149, 155],\n        [103, 104, 103, ..., 173, 158, 163],\n        [102, 102, 100, ..., 175, 167, 180]]], dtype=uint8)</code>\n</pre> <p>Step 2: Create the reader object for the Sentinel-2 image</p> <pre><code>%%time\n\nimport os\nfrom georeader.readers import S2_SAFE_reader\n# This is required to do advaced operations in the GCP bucket\n# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"path/to/file.json\"\n# os.environ[\"GS_USER_PROJECT\"] = \"project-name\"\n# S2_SAFE_reader.DEFAULT_REQUESTER_PAYS=True\n\nos.environ[\"GS_NO_SIGN_REQUEST\"] = \"YES\"\n\n# Read only RGB bands\n\ns2path = \"gs://gcp-public-data-sentinel-2/tiles/13/S/ER/S2B_MSIL1C_20190928T173109_N0208_R055_T13SER_20190928T205958.SAFE\"\ns2_reader = S2_SAFE_reader.s2loader(s2path, out_res=10, bands=[\"B04\", \"B03\", \"B02\"])\ns2_reader\n</code></pre> <pre>\n<code>CPU times: user 229 ms, sys: 27.4 ms, total: 257 ms\nWall time: 344 ms\n</code>\n</pre> <pre>\n<code> \n         gs://gcp-public-data-sentinel-2/tiles/13/S/ER/S2B_MSIL1C_20190928T173109_N0208_R055_T13SER_20190928T205958.SAFE\n         Transform: | 10.00, 0.00, 499980.00|\n| 0.00,-10.00, 3600000.00|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 10980, 10980)\n         Resolution: (10.0, 10.0)\n         Bounds: (499980.0, 3490200.0, 609780.0, 3600000.0)\n         CRS: EPSG:32613\n         bands: ['B04', 'B03', 'B02']\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>%%time\n\nfrom georeader import read\n\ns2_at_aviris_loc = read.read_from_bounds(s2_reader, aviris_reader_in_memory.bounds, crs_bounds=aviris_reader_in_memory.crs)\ns2_at_aviris_loc\n</code></pre> <pre>\n<code>CPU times: user 4.13 ms, sys: 180 \u00b5s, total: 4.31 ms\nWall time: 3.28 ms\n</code>\n</pre> <pre>\n<code> \n         gs://gcp-public-data-sentinel-2/tiles/13/S/ER/S2B_MSIL1C_20190928T173109_N0208_R055_T13SER_20190928T205958.SAFE\n         Transform: | 10.00, 0.00, 592570.00|\n| 0.00,-10.00, 3520580.00|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 157, 157)\n         Resolution: (10.0, 10.0)\n         Bounds: (592570.0, 3519010.0, 594140.0, 3520580.0)\n         CRS: EPSG:32613\n         bands: ['B04', 'B03', 'B02']\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>%%time\ns2_at_aviris_loc_in_memory = s2_at_aviris_loc.load()\ns2_at_aviris_loc_in_memory.values\n</code></pre> <pre>\n<code>CPU times: user 772 ms, sys: 203 ms, total: 976 ms\nWall time: 24.5 s\n</code>\n</pre> <pre>\n<code>array([[[2387, 2649, 2654, ..., 2302, 2292, 2241],\n        [2244, 2454, 2630, ..., 2412, 2376, 2339],\n        [2540, 2432, 2373, ..., 2473, 2442, 2403],\n        ...,\n        [1347, 1312, 1325, ..., 1851, 2073, 2010],\n        [1268, 1265, 1368, ..., 2194, 2193, 2098],\n        [1261, 1293, 1392, ..., 2235, 2018, 1881]],\n\n       [[1803, 1946, 1970, ..., 1802, 1801, 1754],\n        [1739, 1879, 1971, ..., 1873, 1876, 1810],\n        [1914, 1862, 1796, ..., 1920, 1888, 1867],\n        ...,\n        [1265, 1239, 1268, ..., 1611, 1750, 1705],\n        [1194, 1210, 1283, ..., 1815, 1851, 1770],\n        [1181, 1214, 1271, ..., 1886, 1671, 1626]],\n\n       [[1622, 1689, 1683, ..., 1621, 1653, 1576],\n        [1517, 1632, 1690, ..., 1677, 1696, 1624],\n        [1665, 1637, 1614, ..., 1718, 1703, 1637],\n        ...,\n        [1294, 1302, 1299, ..., 1459, 1566, 1569],\n        [1288, 1256, 1333, ..., 1617, 1599, 1591],\n        [1273, 1266, 1350, ..., 1662, 1561, 1474]]], dtype=uint16)</code>\n</pre> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\nfig, ax = plt.subplots(1,2,figsize=(12,6))\nax[0].imshow(aviris_reader_in_memory.values.transpose((1,2,0)))\nax[1].imshow(np.clip(s2_at_aviris_loc_in_memory.values/3_500,0,1).transpose((1,2,0)))\n</code></pre> <pre>\n<code>&lt;matplotlib.image.AxesImage at 0x7f90b4eba080&gt;</code>\n</pre> <pre><code>from georeader import dataarray\ndr = dataarray.toDataArray(s2_at_aviris_loc_in_memory)\ndr\n</code></pre> <pre>&lt;xarray.DataArray (band: 3, y: 157, x: 157)&gt; Size: 148kB\narray([[[2387, 2649, 2654, ..., 2302, 2292, 2241],\n        [2244, 2454, 2630, ..., 2412, 2376, 2339],\n        [2540, 2432, 2373, ..., 2473, 2442, 2403],\n        ...,\n        [1347, 1312, 1325, ..., 1851, 2073, 2010],\n        [1268, 1265, 1368, ..., 2194, 2193, 2098],\n        [1261, 1293, 1392, ..., 2235, 2018, 1881]],\n\n       [[1803, 1946, 1970, ..., 1802, 1801, 1754],\n        [1739, 1879, 1971, ..., 1873, 1876, 1810],\n        [1914, 1862, 1796, ..., 1920, 1888, 1867],\n        ...,\n        [1265, 1239, 1268, ..., 1611, 1750, 1705],\n        [1194, 1210, 1283, ..., 1815, 1851, 1770],\n        [1181, 1214, 1271, ..., 1886, 1671, 1626]],\n\n       [[1622, 1689, 1683, ..., 1621, 1653, 1576],\n        [1517, 1632, 1690, ..., 1677, 1696, 1624],\n        [1665, 1637, 1614, ..., 1718, 1703, 1637],\n        ...,\n        [1294, 1302, 1299, ..., 1459, 1566, 1569],\n        [1288, 1256, 1333, ..., 1617, 1599, 1591],\n        [1273, 1266, 1350, ..., 1662, 1561, 1474]]], dtype=uint16)\nCoordinates:\n  * x        (x) float64 1kB 5.926e+05 5.926e+05 ... 5.941e+05 5.941e+05\n  * y        (y) float64 1kB 3.521e+06 3.521e+06 ... 3.519e+06 3.519e+06\nDimensions without coordinates: band\nAttributes:\n    crs:      EPSG:32613</pre>xarray.DataArray <p><ul><li>band: 3</li><li>y: 157</li><li>x: 157</li></ul></p> <p><ul><li>2387 2649 2654 2512 2296 2217 2333 ... 1510 1484 1662 1662 1561 1474 <p><pre>array([[[2387, 2649, 2654, ..., 2302, 2292, 2241],\n        [2244, 2454, 2630, ..., 2412, 2376, 2339],\n        [2540, 2432, 2373, ..., 2473, 2442, 2403],\n        ...,\n        [1347, 1312, 1325, ..., 1851, 2073, 2010],\n        [1268, 1265, 1368, ..., 2194, 2193, 2098],\n        [1261, 1293, 1392, ..., 2235, 2018, 1881]],\n<pre><code>   [[1803, 1946, 1970, ..., 1802, 1801, 1754],\n    [1739, 1879, 1971, ..., 1873, 1876, 1810],\n    [1914, 1862, 1796, ..., 1920, 1888, 1867],\n    ...,\n    [1265, 1239, 1268, ..., 1611, 1750, 1705],\n    [1194, 1210, 1283, ..., 1815, 1851, 1770],\n    [1181, 1214, 1271, ..., 1886, 1671, 1626]],\n\n   [[1622, 1689, 1683, ..., 1621, 1653, 1576],\n    [1517, 1632, 1690, ..., 1677, 1696, 1624],\n    [1665, 1637, 1614, ..., 1718, 1703, 1637],\n    ...,\n    [1294, 1302, 1299, ..., 1459, 1566, 1569],\n    [1288, 1256, 1333, ..., 1617, 1599, 1591],\n    [1273, 1266, 1350, ..., 1662, 1561, 1474]]], dtype=uint16)&lt;/pre&gt;\n</code></pre>\n\n\n\n<li>Coordinates: (2)<ul><li>x(x)float645.926e+05 5.926e+05 ... 5.941e+05<pre>array([592575., 592585., 592595., 592605., 592615., 592625., 592635., 592645.,\n       592655., 592665., 592675., 592685., 592695., 592705., 592715., 592725.,\n       592735., 592745., 592755., 592765., 592775., 592785., 592795., 592805.,\n       592815., 592825., 592835., 592845., 592855., 592865., 592875., 592885.,\n       592895., 592905., 592915., 592925., 592935., 592945., 592955., 592965.,\n       592975., 592985., 592995., 593005., 593015., 593025., 593035., 593045.,\n       593055., 593065., 593075., 593085., 593095., 593105., 593115., 593125.,\n       593135., 593145., 593155., 593165., 593175., 593185., 593195., 593205.,\n       593215., 593225., 593235., 593245., 593255., 593265., 593275., 593285.,\n       593295., 593305., 593315., 593325., 593335., 593345., 593355., 593365.,\n       593375., 593385., 593395., 593405., 593415., 593425., 593435., 593445.,\n       593455., 593465., 593475., 593485., 593495., 593505., 593515., 593525.,\n       593535., 593545., 593555., 593565., 593575., 593585., 593595., 593605.,\n       593615., 593625., 593635., 593645., 593655., 593665., 593675., 593685.,\n       593695., 593705., 593715., 593725., 593735., 593745., 593755., 593765.,\n       593775., 593785., 593795., 593805., 593815., 593825., 593835., 593845.,\n       593855., 593865., 593875., 593885., 593895., 593905., 593915., 593925.,\n       593935., 593945., 593955., 593965., 593975., 593985., 593995., 594005.,\n       594015., 594025., 594035., 594045., 594055., 594065., 594075., 594085.,\n       594095., 594105., 594115., 594125., 594135.])</pre></li><li>y(y)float643.521e+06 3.521e+06 ... 3.519e+06<pre>array([3520575., 3520565., 3520555., 3520545., 3520535., 3520525., 3520515.,\n       3520505., 3520495., 3520485., 3520475., 3520465., 3520455., 3520445.,\n       3520435., 3520425., 3520415., 3520405., 3520395., 3520385., 3520375.,\n       3520365., 3520355., 3520345., 3520335., 3520325., 3520315., 3520305.,\n       3520295., 3520285., 3520275., 3520265., 3520255., 3520245., 3520235.,\n       3520225., 3520215., 3520205., 3520195., 3520185., 3520175., 3520165.,\n       3520155., 3520145., 3520135., 3520125., 3520115., 3520105., 3520095.,\n       3520085., 3520075., 3520065., 3520055., 3520045., 3520035., 3520025.,\n       3520015., 3520005., 3519995., 3519985., 3519975., 3519965., 3519955.,\n       3519945., 3519935., 3519925., 3519915., 3519905., 3519895., 3519885.,\n       3519875., 3519865., 3519855., 3519845., 3519835., 3519825., 3519815.,\n       3519805., 3519795., 3519785., 3519775., 3519765., 3519755., 3519745.,\n       3519735., 3519725., 3519715., 3519705., 3519695., 3519685., 3519675.,\n       3519665., 3519655., 3519645., 3519635., 3519625., 3519615., 3519605.,\n       3519595., 3519585., 3519575., 3519565., 3519555., 3519545., 3519535.,\n       3519525., 3519515., 3519505., 3519495., 3519485., 3519475., 3519465.,\n       3519455., 3519445., 3519435., 3519425., 3519415., 3519405., 3519395.,\n       3519385., 3519375., 3519365., 3519355., 3519345., 3519335., 3519325.,\n       3519315., 3519305., 3519295., 3519285., 3519275., 3519265., 3519255.,\n       3519245., 3519235., 3519225., 3519215., 3519205., 3519195., 3519185.,\n       3519175., 3519165., 3519155., 3519145., 3519135., 3519125., 3519115.,\n       3519105., 3519095., 3519085., 3519075., 3519065., 3519055., 3519045.,\n       3519035., 3519025., 3519015.])</pre></li></ul></li>\n<li>Indexes: (2)<ul><li>xPandasIndex<pre>PandasIndex(Index([592575.0, 592585.0, 592595.0, 592605.0, 592615.0, 592625.0, 592635.0,\n       592645.0, 592655.0, 592665.0,\n       ...\n       594045.0, 594055.0, 594065.0, 594075.0, 594085.0, 594095.0, 594105.0,\n       594115.0, 594125.0, 594135.0],\n      dtype='float64', name='x', length=157))</pre></li><li>yPandasIndex<pre>PandasIndex(Index([3520575.0, 3520565.0, 3520555.0, 3520545.0, 3520535.0, 3520525.0,\n       3520515.0, 3520505.0, 3520495.0, 3520485.0,\n       ...\n       3519105.0, 3519095.0, 3519085.0, 3519075.0, 3519065.0, 3519055.0,\n       3519045.0, 3519035.0, 3519025.0, 3519015.0],\n      dtype='float64', name='y', length=157))</pre></li></ul></li>\n<li>Attributes: (1)crs :EPSG:32613</li>\n<p>\n\n\n\n\n</p>\n\n\n\n<pre><code>geotensorback = dataarray.fromDataArray(dr)\ngeotensorback\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code> \n         Transform: | 10.00, 0.00, 592570.00|\n| 0.00,-10.00, 3520580.00|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 157, 157)\n         Resolution: (10.0, 10.0)\n         Bounds: (592570.0, 3519010.0, 594140.0, 3520580.0)\n         CRS: EPSG:32613\n         fill_value_default: 0\n        </code>\n</pre>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<pre><code>center_coords_aviris = aviris_reader_in_memory.transform * (aviris_reader_in_memory.shape[1] / 2, aviris_reader_in_memory.shape[0] / 2)\ncenter_coords_aviris\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code>(593036.3218595202, 3520235.9129436193)</code>\n</pre>\n\n\n\n\n\n\n\n\n<pre><code>%%time\n\n\ns2_at_aviris_loc = read.read_from_center_coords(s2_reader, shape=(150,150),\n                                                center_coords=center_coords_aviris, crs_center_coords=aviris_reader_in_memory.crs)\ns2_at_aviris_loc\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code>CPU times: user 5.6 ms, sys: 560 \u00b5s, total: 6.16 ms\nWall time: 4.71 ms\n</code>\n</pre>\n\n\n\n\n<pre>\n<code> \n         gs://gcp-public-data-sentinel-2/tiles/13/S/ER/S2B_MSIL1C_20190928T173109_N0208_R055_T13SER_20190928T205958.SAFE\n         Transform: | 10.00, 0.00, 592290.00|\n| 0.00,-10.00, 3520990.00|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 150, 150)\n         Resolution: (10.0, 10.0)\n         Bounds: (592290.0, 3519490.0, 593790.0, 3520990.0)\n         CRS: EPSG:32613\n         bands: ['B04', 'B03', 'B02']\n         fill_value_default: 0\n        </code>\n</pre>\n\n\n\n\n\n\n\n\n<pre><code>%%time\ns2_at_aviris_loc_in_memory = s2_at_aviris_loc.load()\ns2_at_aviris_loc_in_memory.values\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code>CPU times: user 857 ms, sys: 9.61 ms, total: 867 ms\nWall time: 117 ms\n</code>\n</pre>\n\n\n\n\n<pre>\n<code>array([[[2403, 2577, 2603, ..., 1957, 2000, 1975],\n        [2360, 2327, 2266, ..., 2012, 1952, 1887],\n        [2298, 2156, 2188, ..., 2026, 2011, 1925],\n        ...,\n        [2368, 2257, 2093, ..., 2197, 2050, 2044],\n        [2316, 2276, 2117, ..., 2418, 2195, 1936],\n        [2370, 2346, 2337, ..., 2401, 2182, 1805]],\n\n       [[1962, 2124, 2189, ..., 1695, 1664, 1711],\n        [1895, 1891, 1861, ..., 1690, 1675, 1602],\n        [1864, 1769, 1811, ..., 1715, 1789, 1610],\n        ...,\n        [1842, 1765, 1661, ..., 1756, 1714, 1698],\n        [1817, 1764, 1653, ..., 1955, 1785, 1633],\n        [1880, 1804, 1762, ..., 1932, 1752, 1546]],\n\n       [[1777, 1899, 1964, ..., 1584, 1567, 1603],\n        [1688, 1676, 1719, ..., 1580, 1540, 1509],\n        [1640, 1561, 1644, ..., 1649, 1626, 1526],\n        ...,\n        [1589, 1559, 1443, ..., 1647, 1579, 1553],\n        [1613, 1565, 1441, ..., 1705, 1601, 1534],\n        [1627, 1575, 1521, ..., 1764, 1610, 1461]]], dtype=uint16)</code>\n</pre>\n\n\n\n\n\n\n\n\n<pre><code>fig, ax = plt.subplots(1,2,figsize=(12,6))\nax[0].imshow(aviris_reader_in_memory.values.transpose((1,2,0)))\nax[1].imshow(np.clip(s2_at_aviris_loc_in_memory.values/3_500,0,1).transpose((1,2,0)))\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code>&lt;matplotlib.image.AxesImage at 0x7f90b44a6200&gt;</code>\n</pre>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<pre><code>%%time\n\ns2_at_aviris_loc = read.read_reproject_like(s2_reader, aviris_reader_in_memory)\ns2_at_aviris_loc\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code>CPU times: user 773 ms, sys: 5.81 ms, total: 779 ms\nWall time: 127 ms\n</code>\n</pre>\n\n\n\n\n<pre>\n<code> \n         Transform: | 5.99, 4.35, 592577.80|\n| 4.35,-5.99, 3519916.50|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 151, 151)\n         Resolution: (7.400000000038687, 7.399999999944504)\n         Bounds: (592577.7996484624, 3519012.5018222863, 594138.5864788886, 3520573.2886527125)\n         CRS: EPSG:32613\n         fill_value_default: 0\n        </code>\n</pre>\n\n\n\n\n\n\n\n\n<pre><code>fig, ax = plt.subplots(1,2,figsize=(12,6))\nax[0].imshow(aviris_reader_in_memory.values.transpose((1,2,0)))\nax[1].imshow(np.clip(s2_at_aviris_loc.values/3_500,0,1).transpose((1,2,0)))\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code>&lt;matplotlib.image.AxesImage at 0x7f90a47f0790&gt;</code>\n</pre>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<pre><code>%%time\nimport rasterio.windows\nfrom math import ceil\n\nshape_out = ceil(aviris_reader_in_memory.shape[1] * aviris_reader_in_memory.res[0] / s2_reader.res[0]), ceil(aviris_reader_in_memory.shape[2] * aviris_reader_in_memory.res[1] / s2_reader.res[1])\n\ns2_at_aviris_loc = read.read_reproject(s2_reader, dst_crs=aviris_reader_in_memory.crs, \n                                       dst_transform=aviris_reader_in_memory.transform,\n                                       resolution_dst_crs=s2_reader.res,\n                                       window_out=rasterio.windows.Window(0,0, width=shape_out[-1], height=shape_out[-2]))\ns2_at_aviris_loc\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code>CPU times: user 766 ms, sys: 15.9 ms, total: 782 ms\nWall time: 111 ms\n</code>\n</pre>\n\n\n\n\n<pre>\n<code> \n         Transform: | 8.09, 5.88, 592577.80|\n| 5.88,-8.09, 3519916.50|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 112, 112)\n         Resolution: (9.999999999910532, 10.000000000141569)\n         Bounds: (592577.7996484624, 3519010.398378094, 594142.2181647301, 3520574.816894365)\n         CRS: EPSG:32613\n         fill_value_default: 0\n        </code>\n</pre>\n\n\n\n\n\n\n\n\n<pre><code>fig, ax = plt.subplots(1,2,figsize=(12,6))\nax[0].imshow(aviris_reader_in_memory.values.transpose((1,2,0)))\nax[1].imshow(np.clip(s2_at_aviris_loc.values/3_500,0,1).transpose((1,2,0)))\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code>&lt;matplotlib.image.AxesImage at 0x7f90b4e29c00&gt;</code>\n</pre>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<pre><code>avirs_at_10m = read.resize(aviris_reader_in_memory,resolution_dst=s2_reader.res,anti_aliasing=True)\navirs_at_10m\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code> \n         Transform: | 8.09, 5.88, 592577.80|\n| 5.88,-8.09, 3519916.50|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 112, 112)\n         Resolution: (9.999999999910532, 10.000000000141569)\n         Bounds: (592577.7996484624, 3519010.398378094, 594142.2181647301, 3520574.816894365)\n         CRS: EPSG:32613\n         fill_value_default: 0\n        </code>\n</pre>\n\n\n\n\n\n\n\n\n<pre><code>fig, ax = plt.subplots(1,3,figsize=(18,6))\nax[0].imshow(aviris_reader_in_memory.values.transpose((1,2,0)))\nax[1].imshow(avirs_at_10m.values.transpose((1,2,0)))\nax[2].imshow(np.clip(s2_at_aviris_loc.values/3_500,0,1).transpose((1,2,0)))\n</code></pre>\n\n\n\n\n\n\n<pre>\n<code>&lt;matplotlib.image.AxesImage at 0x7f9083f5c6d0&gt;</code>\n</pre>"},{"location":"reading_overlapping_sentinel2_aviris/#reading-overlapping-tiles-with-georeader","title":"Reading overlapping tiles with <code>georeader</code>","text":"<p>This tutorial shows how to read overlapping parts of two raster objects of different spatial resolution and with different transforms.</p> <p>For this tutorial we will use a GeoTIFF file derived from an AVIRIS-NG image that we downloaded from here and a Sentinel-2 file SAFE file that can be read directly from the public GCP bucket (or downloaded from Copernicus SciHub).</p>"},{"location":"reading_overlapping_sentinel2_aviris/#install-package-with-google-dependecies","title":"Install package with Google dependecies","text":"<p>This is needed to read image from S2 bucket</p> <pre><code>pip install georeader-spaceml fsspec gcsfs\n</code></pre>"},{"location":"reading_overlapping_sentinel2_aviris/#read-the-s2-image-at-the-aviris-location-using-read_from_bounds","title":"Read the S2 image at the AVIRIS location using <code>read_from_bounds</code>","text":""},{"location":"reading_overlapping_sentinel2_aviris/#convert-to-and-from-xarraydataarray","title":"Convert to and from <code>xarray.DataArray</code>","text":""},{"location":"reading_overlapping_sentinel2_aviris/#read-the-s2-image-at-the-aviris-location-using-read_from_center_coords","title":"Read the S2 image at the AVIRIS location using <code>read_from_center_coords</code>","text":""},{"location":"reading_overlapping_sentinel2_aviris/#read-the-s2-image-at-the-aviris-location-using-read_reproject_like","title":"Read the S2 image at the AVIRIS location using <code>read_reproject_like</code>","text":"<p>This will read the S2 image with the same resolution and transform as the AVIRIS image.</p>"},{"location":"reading_overlapping_sentinel2_aviris/#read-the-s2-image-at-the-aviris-location-using-read_reproject","title":"Read the S2 image at the AVIRIS location using <code>read_reproject</code>","text":"<p>With this we will show how to reproject the S2 image to the AVIRIS grid but keeping the original spatial resolution of Sentinel-2 (10m).</p>"},{"location":"reading_overlapping_sentinel2_aviris/#downscale-aviris-ng-to-the-sentinel-2-resolution-10m","title":"Downscale AVIRIS-NG to the Sentinel-2 resolution (10m)","text":"<p>This AVIRIS-NG image is at 7.40m resolution and we'd like to convert it to 10m resolution. We will set the option anti_aliasing to True to avoid aliasing efects of reducing the sampling size.</p>"},{"location":"reading_overlapping_sentinel2_aviris/#licence","title":"Licence","text":"<p>The georeader package is published under a GNU Lesser GPL v3 licence</p>\n<p>If you find this work useful please cite:</p>\n<pre><code>@article{ruzicka_starcop_2023,\n    title = {Semantic segmentation of methane plumes with hyperspectral machine learning models},\n    volume = {13},\n    issn = {2045-2322},\n    url = {https://www.nature.com/articles/s41598-023-44918-6},\n    doi = {10.1038/s41598-023-44918-6},\n    number = {1},\n    journal = {Scientific Reports},\n    author = {R\u016f\u017ei\u010dka, V\u00edt and Mateo-Garcia, Gonzalo and G\u00f3mez-Chova, Luis and Vaughan, Anna, and Guanter, Luis and Markham, Andrew},\n    month = nov,\n    year = {2023},\n    pages = {19999},\n}\n</code></pre>"},{"location":"simultaneous_prisma_emit/","title":"PRISMA","text":"<pre><code>import os\nprisma_path = \"prisma_database/PRS_L1_STD_OFFL_20230929102749_20230929102753_0001.he5\"\nemit_path = \"emit_database/raw/EMIT_L1B_RAD_001_20230929T122534_2327208_039.nc\"\nos.path.exists(prisma_path),os.path.exists(emit_path)\n</code></pre> <pre>\n<code>(True, True)</code>\n</pre> <pre><code>from georeader.readers import emit\nfrom georeader.readers import prisma\nimport matplotlib.pyplot as plt\nfrom georeader import plot\nfrom georeader import read\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Point\nfrom georeader.window_utils import polygon_to_crs\n\nei = emit.EMITImage(emit_path).to_crs()\nei\n</code></pre> <pre>\n<code> \n         File: emit_database/raw/EMIT_L1B_RAD_001_20230929T122534_2327208_039.nc\n         Transform: | 60.00, 0.00, 184463.99|\n| 0.00,-60.00, 3571041.85|\n| 0.00, 0.00, 1.00|\n         Shape: (285, 1935, 2004)\n         Resolution: (60.0, 60.0)\n         Bounds: (184463.98930973688, 3454941.8506227555, 304703.9893097369, 3571041.8506227555)\n         CRS: EPSG:32632\n         units: uW/cm^2/SR/nm\n        </code>\n</pre> <pre><code>pi = prisma.PRISMA(prisma_path)\npi\n</code></pre> <pre>\n<code>\n        File: prisma_database/PRS_L1_STD_OFFL_20230929102749_20230929102753_0001.he5\n        Bounds: (5.843493461608887, 31.288787841796875, 6.223865509033203, 31.612695693969727)\n        Time: 2023-09-29 10:27:49.047000+00:00\n        VNIR Range: (406.9934, 977.3654) 63 bands\n        SWIR Range: (943.3579, 2497.1155) 171 bands\n        </code>\n</pre> <pre><code># Load SWIR and NIR PRISMA images\npi.load_raw(swir_flag=True)\n_ = pi.load_raw(swir_flag=False)\n</code></pre> <pre><code>pixel_prisma = (45, 65)\n\n# The raw values of prisma are col major\npoint_prisma = pi.lons[pixel_prisma[-1::-1]],pi.lats[pixel_prisma[-1::-1]]\n\nei_on_point = read.read_from_center_coords(ei, point_prisma, \n                                           shape=(50,50), \n                                           crs_center_coords=\"EPSG:4326\").load()\nei_on_point\n</code></pre> <pre>\n<code> \n         Transform: | 60.00, 0.00, 207203.99|\n| 0.00,-60.00, 3501321.85|\n| 0.00, 0.00, 1.00|\n         Shape: (285, 50, 50)\n         Resolution: (60.0, 60.0)\n         Bounds: (207203.98930973688, 3498321.8506227555, 210203.98930973688, 3501321.8506227555)\n         CRS: EPSG:32632\n         fill_value_default: 0\n        </code>\n</pre> <pre><code># Center pixel\npixel_value_emit = ei_on_point.values[:, 25, 25]\n\npixel_value_prisma = pi.ltoa_swir[pixel_prisma + (slice(None),)]\npixel_value_prisma_vnir = pi.ltoa_vnir[pixel_prisma + (slice(None),)]\n\nplt.plot(ei.wavelengths, pixel_value_emit, label=\"EMIT\")\nplt.plot(pi.wavelength_swir[pixel_prisma[1],:], pixel_value_prisma/10, label=\"PRISMA SWIR\")\nplt.plot(pi.wavelength_vnir[pixel_prisma[1],:], pixel_value_prisma_vnir/10, label=\"PRISMA VNIR\")\n\nplt.ylabel(ei.units)\nplt.xlabel(\"$\\lambda$ (nm)\")\nplt.grid()\nplt.legend()\n</code></pre> <pre>\n<code>&lt;matplotlib.legend.Legend at 0x7f4ff610a6e0&gt;</code>\n</pre> <pre><code>rgb_prisma = pi.load_rgb(raw=False)\nrgb_prisma\n</code></pre> <pre>\n<code> \n         Transform: | 30.00, 0.00, 199694.39|\n| 0.00,-30.00, 3501644.59|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 1219, 1227)\n         Resolution: (30.0, 30.0)\n         Bounds: (199694.3906206509, 3465074.5888539106, 236504.3906206509, 3501644.5888539106)\n         CRS: EPSG:32632\n         fill_value_default: -1\n        </code>\n</pre> <pre><code>plot.show(rgb_prisma)\n</code></pre> <pre>\n<code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</code>\n</pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>rgb_emit = ei.load_rgb(as_reflectance=True)\nrgb_emit\n</code></pre> <pre>\n<code> \n         Transform: | 60.00, 0.00, 184463.99|\n| 0.00,-60.00, 3571041.85|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 1935, 2004)\n         Resolution: (60.0, 60.0)\n         Bounds: (184463.98930973688, 3454941.8506227555, 304703.9893097369, 3571041.8506227555)\n         CRS: EPSG:32632\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>fig, ax = plt.subplots(1,1)\nplot.show(rgb_emit, ax=ax)\nplot.add_shape_to_plot(ei.footprint(crs=\"EPSG:4326\"), crs_plot=ei.crs, crs_shape=\"EPSG:4326\", polygon_no_fill=True, ax=ax)\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>import geopandas as gpd\nmetadata = gpd.GeoDataFrame({\"geometry\": [ei.footprint(crs=\"EPSG:4326\"), pi.footprint(crs=\"EPSG:4326\")],\n                             # \"geometry\": [rgb_emit.valid_footprint(crs=\"EPSG:4326\"), rgb_prisma.valid_footprint(crs=\"EPSG:4326\")],\n                             \"satellite\": [\"EMIT\", \"PRISMA\"],\n                             \"tile_date\": [ei.time_coverage_start.isoformat(), pi.time_coverage_start.isoformat()]},\n                            geometry=\"geometry\",\n                            crs=\"EPSG:4326\")\nmetadata\n</code></pre> geometry satellite tile_date 0 POLYGON ((6.29588 32.23147, 6.29591 32.23039, ... EMIT 2023-09-29T12:25:34+00:00 1 POLYGON ((5.84349 31.34925, 6.15325 31.28879, ... PRISMA 2023-09-29T10:27:49.047000+00:00 <pre><code>metadata.explore()\n</code></pre> Make this Notebook Trusted to load map: File -&gt; Trust Notebook <pre><code>pol_intersection = rgb_emit.valid_footprint(crs=\"EPSG:4326\").intersection(rgb_prisma.valid_footprint(crs=\"EPSG:4326\"))\n\nrgb_emit_intersect = read.read_from_polygon(rgb_emit, pol_intersection, \"EPSG:4326\")\nrgb_prisma_intersect = read.read_from_polygon(rgb_prisma, pol_intersection, \"EPSG:4326\")\n\n# Show point where we extracted the profile in the plot\npoint_prisma_epsg = Point(*point_prisma)\npoint_emit_crs = polygon_to_crs(point_prisma_epsg, crs_polygon=\"EPSG:4326\", dst_crs=rgb_emit_intersect.crs)\npoint_prisma_crs = polygon_to_crs(point_prisma_epsg, crs_polygon=\"EPSG:4326\", dst_crs=rgb_prisma_intersect.crs)\n\nfig, ax = plt.subplots(1,2,figsize=(16,10))\nplot.show(rgb_emit_intersect, ax=ax[0], title=\"EMIT\")\nax[0].scatter([point_emit_crs.coords[0][0]], [point_emit_crs.coords[0][1]], marker=\"x\", color=\"red\")\nplot.add_shape_to_plot(pol_intersection, crs_plot=rgb_emit_intersect.crs, crs_shape=\"EPSG:4326\", polygon_no_fill=True, ax=ax[0])\nplot.show(rgb_prisma_intersect, ax=ax[1], title=\"PRISMA\")\nax[1].scatter([point_prisma_crs.coords[0][0]], [point_prisma_crs.coords[0][1]], marker=\"x\", color=\"red\")\nplot.add_shape_to_plot(pol_intersection, crs_plot=rgb_prisma_intersect.crs, crs_shape=\"EPSG:4326\", polygon_no_fill=True, ax=ax[1])\n</code></pre> <pre>\n<code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</code>\n</pre> <pre>\n<code>&lt;Axes: title={'center': 'PRISMA'}&gt;</code>\n</pre> <pre><code>rgb_emit_point = read.read_from_center_coords(rgb_emit, point_prisma, shape=(50,50),\n                                                  crs_center_coords=\"EPSG:4326\")\nrgb_prisma_point = read.read_from_center_coords(rgb_prisma, point_prisma, \n                                                shape=(100,100),\n                                                crs_center_coords=\"EPSG:4326\")\n\n# # Show point where we extracted the profile in the plot\n# point_prisma_epsg = Point(*point_prisma)\n# point_emit_crs = polygon_to_crs(point_prisma_epsg, crs_polygon=\"EPSG:4326\", dst_crs=rgb_emit_intersect.crs)\n# point_prisma_crs = polygon_to_crs(point_prisma_epsg, crs_polygon=\"EPSG:4326\", dst_crs=rgb_prisma_intersect.crs)\n\nfig, ax = plt.subplots(1,2,figsize=(16,10))\nplot.show(rgb_emit_point, ax=ax[0], title=\"EMIT\")\nax[0].scatter([point_emit_crs.coords[0][0]], [point_emit_crs.coords[0][1]], marker=\"x\", color=\"red\")\nplot.show(rgb_prisma_point, ax=ax[1], title=\"PRISMA\")\nax[1].scatter([point_prisma_crs.coords[0][0]], [point_prisma_crs.coords[0][1]], marker=\"x\", color=\"red\")\n</code></pre> <pre>\n<code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</code>\n</pre> <pre>\n<code>&lt;matplotlib.collections.PathCollection at 0x7f4fef997d90&gt;</code>\n</pre>"},{"location":"simultaneous_prisma_emit/#prisma-and-emit-readers","title":"PRISMA and EMIT readers","text":""},{"location":"simultaneous_prisma_emit/#install-package-dependecies","title":"Install package  dependecies","text":"<p>EMIT requires the <code>netcdf4</code> package to read the products. We will also use the <code>pysolar</code> package to convert the EMIT L1B radiances to reflectances. PRISMA requires the <code>h5py</code> package and we need <code>scipy</code> for the <code>georeader.reflectance</code> module.</p> <pre><code>pip install georeader-spaceml netcdf4 pysolar h5py scipy\n</code></pre>"},{"location":"simultaneous_prisma_emit/#read-images","title":"Read images","text":""},{"location":"simultaneous_prisma_emit/#read-same-pixel-value","title":"Read same pixel value","text":""},{"location":"simultaneous_prisma_emit/#load-rgb-reflectance","title":"Load RGB reflectance","text":""},{"location":"simultaneous_prisma_emit/#plot-rgb-over-the-exact-same-area","title":"Plot RGB over the exact same area","text":""},{"location":"simultaneous_prisma_emit/#zoom-in-in-the-point","title":"Zoom in in the point","text":""},{"location":"simultaneous_prisma_emit/#licence","title":"Licence","text":"<p>The georeader package is published under a GNU Lesser GPL v3 licence</p> <p>If you find this work useful please cite:</p> <pre><code>@article{ruzicka_starcop_2023,\n    title = {Semantic segmentation of methane plumes with hyperspectral machine learning models},\n    volume = {13},\n    issn = {2045-2322},\n    url = {https://www.nature.com/articles/s41598-023-44918-6},\n    doi = {10.1038/s41598-023-44918-6},\n    number = {1},\n    journal = {Scientific Reports},\n    author = {R\u016f\u017ei\u010dka, V\u00edt and Mateo-Garcia, Gonzalo and G\u00f3mez-Chova, Luis and Vaughan, Anna, and Guanter, Luis and Markham, Andrew},\n    month = nov,\n    year = {2023},\n    pages = {19999},\n}\n</code></pre>"},{"location":"Sentinel-2/explore_metadata_s2/","title":"Metadata","text":"<pre><code>!pip install georeader-spaceml fsspec gcsfs\n</code></pre> <pre><code>import os\n# Donwload key from next line link to access the buckets and requester pays requests to public bucket (this is needed to query Sentinel-2 data)\nos.environ[\"GS_NO_SIGN_REQUEST\"] = \"YES\"\n</code></pre> <pre><code>%%time\nfrom georeader.readers import S2_SAFE_reader\n\nsafe_file = \"S2B_MSIL1C_20220527T030539_N0400_R075_T49SGV_20220527T051042.SAFE\"\ns2_safe_folder = S2_SAFE_reader.s2_public_bucket_path(safe_file)\n\nprint(f\"File is located at: {s2_safe_folder}\")\n\ns2obj = S2_SAFE_reader.s2loader(s2_safe_folder, out_res=10)\ns2obj\n</code></pre> <pre>\n<code>/home/gonzalo/mambaforge/envs/marss2_vm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</code>\n</pre> <pre>\n<code>File is located at: gs://gcp-public-data-sentinel-2/tiles/49/S/GV/S2B_MSIL1C_20220527T030539_N0400_R075_T49SGV_20220527T051042.SAFE\nCPU times: user 1.82 s, sys: 1.56 s, total: 3.38 s\nWall time: 8.29 s\n</code>\n</pre> <pre>\n<code> \n         gs://gcp-public-data-sentinel-2/tiles/49/S/GV/S2B_MSIL1C_20220527T030539_N0400_R075_T49SGV_20220527T051042.SAFE\n         Transform: | 10.00, 0.00, 699960.00|\n| 0.00,-10.00, 4000020.00|\n| 0.00, 0.00, 1.00|\n         Shape: (13, 10980, 10980)\n         Resolution: (10.0, 10.0)\n         Bounds: (699960.0, 3890220.0, 809760.0, 4000020.0)\n         CRS: EPSG:32649\n         bands: ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B11', 'B12']\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>footprint = s2obj.footprint(crs=\"epsg:4326\")\nfootprint\n</code></pre> <pre><code>s2obj.metadata_msi\n</code></pre> <pre>\n<code>'gs://gcp-public-data-sentinel-2/tiles/49/S/GV/S2B_MSIL1C_20220527T030539_N0400_R075_T49SGV_20220527T051042.SAFE/MTD_MSIL1C.xml'</code>\n</pre> <pre><code>s2obj.solar_irradiance()\n</code></pre> <pre>\n<code>{'B01': 1.8742999999999999,\n 'B02': 1.95975,\n 'B03': 1.8249300000000002,\n 'B04': 1.5127899999999999,\n 'B05': 1.42578,\n 'B06': 1.29113,\n 'B07': 1.17557,\n 'B08': 1.04128,\n 'B8A': 0.95393,\n 'B09': 0.8175800000000001,\n 'B10': 0.36541,\n 'B11': 0.24708000000000002,\n 'B12': 0.08775}</code>\n</pre> <pre><code>s2obj.scale_factor_U()\n</code></pre> <pre>\n<code>0.975631110815927</code>\n</pre> <pre><code>s2obj.quantification_value()\n</code></pre> <pre>\n<code>10000</code>\n</pre> <p>When reading the data we automatically apply the radio offsets</p> <pre><code>s2obj.radio_add_offsets()\n</code></pre> <pre>\n<code>{'B01': -1000,\n 'B02': -1000,\n 'B03': -1000,\n 'B04': -1000,\n 'B05': -1000,\n 'B06': -1000,\n 'B07': -1000,\n 'B08': -1000,\n 'B8A': -1000,\n 'B09': -1000,\n 'B10': -1000,\n 'B11': -1000,\n 'B12': -1000}</code>\n</pre> <pre><code>s2obj.metadata_tl\n</code></pre> <pre>\n<code>'gs://gcp-public-data-sentinel-2/tiles/49/S/GV/S2B_MSIL1C_20220527T030539_N0400_R075_T49SGV_20220527T051042.SAFE/GRANULE/L1C_T49SGV_A027271_20220527T031740/MTD_TL.xml'</code>\n</pre> <pre><code># Trigger reading of metadata to inspect angles\ns2obj.read_metadata_tl()\n</code></pre> <pre><code>s2obj.mean_saa\n</code></pre> <pre>\n<code>131.536377934938</code>\n</pre> <pre><code>s2obj.mean_sza\n</code></pre> <pre>\n<code>19.9963398909342</code>\n</pre> <pre><code>s2obj.mean_vaa\n</code></pre> <pre>\n<code>{'B01': 126.71626827978,\n 'B02': 134.025373678555,\n 'B03': 131.374351951736,\n 'B04': 129.400002573406,\n 'B05': 128.353590682291,\n 'B06': 127.731729632175,\n 'B07': 127.498142587193,\n 'B08': 132.434175716618,\n 'B8A': 127.053148498046,\n 'B09': 126.379870378688,\n 'B10': 129.861408742839,\n 'B11': 127.893230596876,\n 'B12': 126.736610889672}</code>\n</pre> <pre><code>s2obj.mean_vza\n</code></pre> <pre>\n<code>{'B01': 3.68625117058342,\n 'B02': 3.0838728710074,\n 'B03': 3.18946067411809,\n 'B04': 3.29825904111417,\n 'B05': 3.36911102353786,\n 'B06': 3.44180307391012,\n 'B07': 3.52146467178658,\n 'B08': 3.13105485372435,\n 'B8A': 3.60143308327063,\n 'B09': 3.77484901438726,\n 'B10': 3.2696304921444,\n 'B11': 3.42988721523325,\n 'B12': 3.61676668649388}</code>\n</pre> <p>The <code>sza</code> and <code>vza</code> attributes are <code>GeoTensor</code> objects</p> <pre><code>s2obj.sza\n</code></pre> <pre>\n<code> \n         Transform: | 5000.00, 0.00, 699960.00|\n| 0.00,-5000.00, 4000020.00|\n| 0.00, 0.00, 1.00|\n         Shape: (23, 23)\n         Resolution: (5000.0, 5000.0)\n         Bounds: (699960.0, 3885020.0, 814960.0, 4000020.0)\n         CRS: EPSG:32649\n         fill_value_default: 0\n        </code>\n</pre> <pre><code>from georeader.plot import show\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(2,2,figsize=(10,10), tight_layout=True)\nshow(s2obj.vza[\"B12\"], add_colorbar_next_to=True, add_scalebar=True,\n    ax=ax[0,0],title=\"VZA B12\")\nshow(s2obj.vaa[\"B12\"], add_colorbar_next_to=True, add_scalebar=True,\n    ax=ax[0,1],title=\"VAA B12\")\nshow(s2obj.sza, add_colorbar_next_to=True, add_scalebar=True,\n    ax=ax[1,0],title=\"SZA\")\nshow(s2obj.saa, add_colorbar_next_to=True, add_scalebar=True,\n    ax=ax[1,1],title=\"SAA\")\n</code></pre> <pre>\n<code>&lt;Axes: title={'center': 'SAA'}&gt;</code>\n</pre> <pre><code># reads SRF from S2_SAFE_reader.SRF_FILE_DEFAULT\nsrf = S2_SAFE_reader.read_srf(s2obj.mission)\nsrf\n</code></pre> <pre>\n<code>/home/gonzalo/mambaforge/envs/marss2_vm/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n  warn(msg)\n</code>\n</pre> B01 B02 B03 B04 B05 B06 B07 B08 B8A B09 B10 B11 B12 SR_WL 411 0.006241 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 412 0.010240 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 413 0.004030 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 414 0.006422 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 415 0.005528 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000000 ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2299 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.020036 2300 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.013846 2301 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.008505 2302 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.004435 2303 0.000000 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.000853 <p>877 rows \u00d7 13 columns</p> <pre><code>fig, ax = plt.subplots(1,1,figsize=(14,4))\n\nfor idx, b in enumerate(S2_SAFE_reader.BANDS_S2):\n    mask_zero = srf[b] &amp;lt;=1e-4\n    ax.plot(srf.index[~mask_zero], \n            srf[b][~mask_zero], label=f\"{s2obj.mission}_{b}\")\n\n\nax.legend()\nax.set_xlabel(\"wavelength (nm)\")\n</code></pre> <pre>\n<code>Text(0.5, 0, 'wavelength (nm)')</code>\n</pre> <pre><code>%%time\nfrom georeader import read\n\ns2obj.bands = [\"B04\",\"B08\", \"B12\"]\n\ntensor = read.read_from_center_coords(s2obj, footprint.centroid.coords[0],shape=(512, 1024), crs_center_coords=\"epsg:4326\", trigger_load=True)\ntensor_toa = tensor / 10_000.\n</code></pre> <pre>\n<code>CPU times: user 1.35 s, sys: 199 ms, total: 1.55 s\nWall time: 27.9 s\n</code>\n</pre> <pre><code>tensor_toa = tensor / 10_000.\nshow(tensor_toa)\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>tensor_radiance = s2obj.DN_to_radiance(tensor)\ntensor_radiance.values\n</code></pre> <pre>\n<code>array([[[0.04348571, 0.04286764, 0.0406161 , ..., 0.04503088,\n         0.04269105, 0.04330912],\n        [0.04463355, 0.04269105, 0.03973313, ..., 0.04335326,\n         0.0436623 , 0.04361815],\n        [0.04441281, 0.04277934, 0.04114586, ..., 0.04520747,\n         0.04432452, 0.04273519],\n        ...,\n        [0.05620031, 0.05633275, 0.05527321, ..., 0.07010691,\n         0.06953299, 0.0693564 ],\n        [0.05518491, 0.05514076, 0.05522906, ..., 0.07050425,\n         0.07028349, 0.06997447],\n        [0.05522906, 0.05465514, 0.05558224, ..., 0.07059254,\n         0.07041594, 0.07041594]],\n\n       [[0.08320179, 0.08605824, 0.09405023, ..., 0.09356403,\n         0.09705862, 0.09936808],\n        [0.08782074, 0.09228774, 0.09256123, ..., 0.09456682,\n         0.09484031, 0.09490108],\n        [0.08894508, 0.08900585, 0.08289791, ..., 0.09429333,\n         0.09113299, 0.08943128],\n        ...,\n        [0.07010465, 0.06761285, 0.06600229, ..., 0.0859063 ,\n         0.08529855, 0.08456924],\n        [0.06691393, 0.06569842, 0.06621501, ..., 0.08560242,\n         0.08435652, 0.08423498],\n        [0.06536415, 0.06545531, 0.06670122, ..., 0.08675715,\n         0.08554165, 0.08481235]],\n\n       [[0.00283995, 0.00273495, 0.00261716, ..., 0.00309603,\n         0.00300896, 0.00296031],\n        [0.0029347 , 0.00278617, 0.00264533, ..., 0.00299104,\n         0.00291165, 0.00286812],\n        [0.00306274, 0.002863  , 0.00269142, ..., 0.00290141,\n         0.00282202, 0.00276824],\n        ...,\n        [0.00334443, 0.0033265 , 0.00332138, ..., 0.00334699,\n         0.00336235, 0.0033854 ],\n        [0.00332394, 0.00330346, 0.00329577, ..., 0.00335979,\n         0.00337516, 0.00339821],\n        [0.00330858, 0.00329065, 0.00329321, ..., 0.00336492,\n         0.00337516, 0.00339565]]], dtype=float32)</code>\n</pre> <pre><code># Make sense since radiance in B12 is much lower than in B04\ntensor_radiance.values[:, 100, 100]\n</code></pre> <pre>\n<code>array([0.04211712, 0.09052525, 0.00289629], dtype=float32)</code>\n</pre>"},{"location":"Sentinel-2/explore_metadata_s2/#metadata-files-in-s2-images","title":"Metadata files in S2 images","text":"<p>There are two metadata files in Sentinel-2 images, these are saved in the attributes:  * <code>s2obj.metadata_msi</code>. In this file we have the solar irradiance, scale factor U, quantification values and radio add offsets.  * <code>s2obj.metadata_tl</code>. Here we have the solar and viewing angles. This file is specific of L1C images</p>"},{"location":"Sentinel-2/explore_metadata_s2/#load-spectral-response-function","title":"Load Spectral Response function","text":""},{"location":"Sentinel-2/explore_metadata_s2/#reflectance-to-radiance-conversion","title":"Reflectance to radiance conversion","text":"<p>We want the pixels of our images in spectral radiances with units \\(W\u00b7sr^{-1}\u00b7m^{\u22122}\u00b7nm^{\u22121}\\). Spectral raciances are (watts per steradian per square meter per nanometer).</p> <p>According to this https://gis.stackexchange.com/questions/285996/convert-sentinel-2-1c-product-from-reflectance-to-radiance the formula to convert digital numbers (DN) in ToA images is:</p> <p>toaBandX = (pixelValueBandX + radioAddOffsetBandX ) / 10000</p> <p>radianceBandX = ((toaBandX * cos(incidenceAngle) * solarIrradianceBandX) / (pi * d2))</p> <p>where d2 is the earth-sun distance correction. d2 is 1.0/U</p> <p>The values for incidenceAngle, solarIrradianceBandX and U can be found in the 2 metadata files included in the download.</p> <ul> <li>In <code>metadata_msi</code> we can find the <code>solarIrradianceBandX</code>, the <code>radioAddOffsetBandX</code> and <code>U</code>. See xml content bellow!</li> <li>In <code>metadata_tl</code> we can find the <code>incidenceAngle</code> (which I assume is the solar zenith angle). </li> </ul> <p>If \\(J\\) is the Julian day of the day of acquisition (day of the year), d2 can be computed as:</p> <p>d2 = (1-e* cos(0.9856 * (J-4) * pi/180))^2</p> <p>Where e=0.01673 is the Earth's orbit eccentricity</p> <p>We're going to read an small crop of the image and convert it to radiances</p>"},{"location":"Sentinel-2/explore_metadata_s2/#licence","title":"Licence","text":"<p>The georeader package is published under a GNU Lesser GPL v3 licence</p> <p>If you find this work useful please cite:</p> <pre><code>@article{ruzicka_starcop_2023,\n    title = {Semantic segmentation of methane plumes with hyperspectral machine learning models},\n    volume = {13},\n    issn = {2045-2322},\n    url = {https://www.nature.com/articles/s41598-023-44918-6},\n    doi = {10.1038/s41598-023-44918-6},\n    number = {1},\n    journal = {Scientific Reports},\n    author = {R\u016f\u017ei\u010dka, V\u00edt and Mateo-Garcia, Gonzalo and G\u00f3mez-Chova, Luis and Vaughan, Anna, and Guanter, Luis and Markham, Andrew},\n    month = nov,\n    year = {2023},\n    pages = {19999},\n}\n</code></pre>"},{"location":"Sentinel-2/query_mosaic_s2_images/","title":"Mosaic","text":"<pre><code>import os\nimport datetime\nfrom shapely.geometry import box\nimport geopandas as gpd\nfrom georeader.readers import S2_SAFE_reader\n\n# Donwload key from next line link to access the buckets and requester pays requests to public bucket (this is needed to query Sentinel-2 data)\n# This is required to do advaced operations in the GCP bucket\n# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"path/to/file.json\"\n# os.environ[\"GS_USER_PROJECT\"] = \"project-name\"\n# S2_SAFE_reader.DEFAULT_REQUESTER_PAYS=True\n\nos.environ[\"GS_NO_SIGN_REQUEST\"] = \"YES\"\n</code></pre> <p>Create a geojson file using geojson.io</p> <pre><code>import geopandas as gpd\n\n# aoi = gpd.read_file(\"/home/gonzalo/Downloads/sagunt_small.geojson\")\naoi = gpd.read_file(\"/home/gonzalo/Downloads/liria.geojson\")\n# aoi.explore()\n</code></pre> <pre><code>from zoneinfo import ZoneInfo\n\ntz = ZoneInfo(\"Europe/Madrid\")\n\npolygon_read = aoi.unary_union\ncrs_polygon = aoi.crs\n\ndatetime_str = \"2019-09-28\"\ndate_of_interest = datetime.datetime.strptime(datetime_str, \"%Y-%m-%d\").replace(tzinfo=tz)\n\ndate_start_search = date_of_interest - datetime.timedelta(days=10)\ndate_end_search = date_of_interest + datetime.timedelta(days=6)\n\nprint(f\"Querying images between {date_start_search} and {date_end_search}\\nArea: {polygon_read}\")\n</code></pre> <pre>\n<code>Querying images between 2019-09-18 00:00:00+02:00 and 2019-10-04 00:00:00+02:00\nArea: POLYGON ((-0.74432373046875 39.52099229357195, -0.383148193359375 39.52099229357195, -0.383148193359375 39.81486542536203, -0.74432373046875 39.81486542536203, -0.74432373046875 39.52099229357195))\n</code>\n</pre> <pre><code>from georeader.readers import scihubcopernicus_query\n\n# from sentinelsat.sentinel import SentinelAPI\n# # 'https://scihub.copernicus.eu/apihub'\n# api = SentinelAPI('gonzmg88', \"yyyyyyy\", api_url='https://scihub.copernicus.eu/dhus/')\n\nproducts_gpd = scihubcopernicus_query.query(polygon_read, date_start_search, date_end_search)\nproducts_gpd[[\"overlappercentage\",\"cloudcoverpercentage\", \"utcdatetime\",\"localdatetime\",\"solardatetime\",\"solarday\"]]\n</code></pre> overlappercentage cloudcoverpercentage utcdatetime localdatetime solardatetime solarday title S2B_MSIL1C_20190918T105029_N0208_R051_T30SYJ_20190918T143346 54.697721 0.7080 2019-09-18 10:50:29.024000+00:00 2019-09-18 12:50:29.024000+02:00 2019-09-18 10:48:13.727369 2019-09-18 S2B_MSIL1C_20190918T105029_N0208_R051_T30TYK_20190918T132356 48.189182 5.3711 2019-09-18 10:50:29.024000+00:00 2019-09-18 12:50:29.024000+02:00 2019-09-18 10:48:13.727369 2019-09-18 S2B_MSIL1C_20190918T105029_N0208_R051_T30SXJ_20190918T143346 36.440780 0.2546 2019-09-18 10:50:29.024000+00:00 2019-09-18 12:50:29.024000+02:00 2019-09-18 10:48:13.727369 2019-09-18 S2B_MSIL1C_20190918T105029_N0208_R051_T30TXK_20190918T132356 32.170540 25.4126 2019-09-18 10:50:29.024000+00:00 2019-09-18 12:50:29.024000+02:00 2019-09-18 10:48:13.727369 2019-09-18 S2B_MSIL1C_20190928T105029_N0208_R051_T30SYJ_20190928T130836 54.697682 10.2055 2019-09-28 10:50:29.024000+00:00 2019-09-28 12:50:29.024000+02:00 2019-09-28 10:48:13.727369 2019-09-28 S2B_MSIL1C_20190928T105029_N0208_R051_T30TYK_20190928T130836 48.189182 12.7102 2019-09-28 10:50:29.024000+00:00 2019-09-28 12:50:29.024000+02:00 2019-09-28 10:48:13.727369 2019-09-28 S2B_MSIL1C_20190928T105029_N0208_R051_T30SXJ_20190928T130836 36.440780 12.5037 2019-09-28 10:50:29.024000+00:00 2019-09-28 12:50:29.024000+02:00 2019-09-28 10:48:13.727369 2019-09-28 S2B_MSIL1C_20190928T105029_N0208_R051_T30TXK_20190928T130836 32.170522 3.4074 2019-09-28 10:50:29.024000+00:00 2019-09-28 12:50:29.024000+02:00 2019-09-28 10:48:13.727369 2019-09-28 S2A_MSIL1C_20191003T105031_N0208_R051_T30SYJ_20191003T111605 54.697682 46.1493 2019-10-03 10:50:31.024000+00:00 2019-10-03 12:50:31.024000+02:00 2019-10-03 10:48:15.727369 2019-10-03 S2A_MSIL1C_20191003T105031_N0208_R051_T30TYK_20191003T111605 48.189182 43.6094 2019-10-03 10:50:31.024000+00:00 2019-10-03 12:50:31.024000+02:00 2019-10-03 10:48:15.727369 2019-10-03 S2A_MSIL1C_20191003T105031_N0208_R051_T30SXJ_20191003T111605 36.440780 35.3732 2019-10-03 10:50:31.024000+00:00 2019-10-03 12:50:31.024000+02:00 2019-10-03 10:48:15.727369 2019-10-03 <pre><code>import folium\n\nproducts_gpd[\"localdatetime_str\"] = products_gpd[\"localdatetime\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\nm = products_gpd[[\"geometry\",\"overlappercentage\",\"cloudcoverpercentage\", \"localdatetime_str\",\"solarday\"]].explore(\"solarday\",name=\"S2\")\naoi.explore(m=m,name=\"AoI\",color=\"red\")\nfolium.LayerControl(collapsed=False).add_to(m)\nm\n</code></pre> Make this Notebook Trusted to load map: File -&gt; Trust Notebook <pre><code>%%time\nimport numpy as np\nfrom georeader import read\nfrom georeader import mosaic\nfrom georeader import window_utils\nimport rasterio.plot as rstplt\nimport matplotlib.pyplot as plt\n\nfor day, products_gpd_day in products_gpd.groupby(\"solarday\"):    \n    products_read = products_gpd_day.index\n    print(f\"Selected {products_read.shape[0]} products for solar day {day}\")\n    s2objs = []\n    for product in products_read:\n        s2_safe_folder = S2_SAFE_reader.s2_public_bucket_path(product+\".SAFE\", check_exists=False)\n        s2objs.append(S2_SAFE_reader.s2loader(s2_safe_folder, out_res=10, bands=[\"B04\", \"B03\", \"B02\"]))\n\n    polygon_read_dst_crs = window_utils.polygon_to_crs(polygon_read, crs_polygon=crs_polygon, dst_crs=s2objs[0].crs)\n    data_memory = mosaic.spatial_mosaic(s2objs, polygon=polygon_read_dst_crs, dst_crs= s2objs[0].crs)\n    print(repr(data_memory))\n\n    fig, ax = plt.subplots(1,1,figsize=(8,8))\n    rstplt.show(np.clip((data_memory.values)/3_000,0,1), transform=data_memory.transform, ax=ax)\n    ax.set_title(day)\n    plt.show(fig)\n    plt.close(fig)\n</code></pre> <pre>\n<code>Selected 4 products for solar day 2019-09-18\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\n\n         Transform: | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 3347, 3187)\n         Resolution: (10.0, 10.0)\n         Bounds: (693070.0, 4377020.0, 724940.0, 4410490.0)\n         CRS: EPSG:32630\n         fill_value_default: 0\n         &lt;class 'georeader.geotensor.GeoTensor'&gt;\n</code>\n</pre> <pre>\n<code>Selected 4 products for solar day 2019-09-28\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\n\n         Transform: | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 3347, 3187)\n         Resolution: (10.0, 10.0)\n         Bounds: (693070.0, 4377020.0, 724940.0, 4410490.0)\n         CRS: EPSG:32630\n         fill_value_default: 0\n         &lt;class 'georeader.geotensor.GeoTensor'&gt;\n</code>\n</pre> <pre>\n<code>Selected 3 products for solar day 2019-10-03\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\nWindow(col_off=0, row_off=0, width=3187, height=3347) | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\n\n         Transform: | 10.00, 0.00, 693070.00|\n| 0.00,-10.00, 4410490.00|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 3347, 3187)\n         Resolution: (10.0, 10.0)\n         Bounds: (693070.0, 4377020.0, 724940.0, 4410490.0)\n         CRS: EPSG:32630\n         fill_value_default: 0\n         &lt;class 'georeader.geotensor.GeoTensor'&gt;\n</code>\n</pre> <pre>\n<code>CPU times: user 2min 39s, sys: 27.3 s, total: 3min 7s\nWall time: 7min 35s\n</code>\n</pre> <p>In the last day there's a missing image (for that reason we have a black square in the top left corner). We inspect the available products in the cell bellow.</p> <pre><code>import geopandas as gpd\n\npol_mosaic = data_memory.footprint(crs=crs_polygon)\n\nprint(f\"Overlap {pol_mosaic.intersection(polygon_read).area / polygon_read.area*100:.2f}%\")\n\nfootprint_downloaded = gpd.GeoDataFrame({\"geometry\": [pol_mosaic], \n                                         \"title\": [\"footprint mosaic\"], \n                                         \"group\": [\"footprint mosaic\"]},\n                                        crs=crs_polygon)\n\nm = footprint_downloaded.explore(name=\"footprint\",color=\"green\")\nm = aoi.explore(m=m,name=\"AoI\",color=\"red\")\n</code></pre> <pre>\n<code>Overlap 100.00%\n</code>\n</pre>"},{"location":"Sentinel-2/query_mosaic_s2_images/#query-sentinel-2-images","title":"Query Sentinel-2 images","text":"<p>In this notebook we will show how to query Sentinel-2 images over an area between two given dates. We will use the <code>sentinelsat</code> package to obtain the Sentinel-2 product names and we will read those from the public GCP bucket (<code>gs://gcp-public-data-sentinel-2/tiles</code>).</p> <p>Set the env variables to be able to read from the Google bucket. This  will incur in reading costs.</p>"},{"location":"Sentinel-2/query_mosaic_s2_images/#install-package-with-google-dependecies","title":"Install package with Google dependecies","text":"<p>This is needed to read image from S2 bucket and to query to Copernicus SciHub <pre><code>pip install georeader-spaceml fsspec gcsfs sentinelsat\n</code></pre></p>"},{"location":"Sentinel-2/query_mosaic_s2_images/#step-1-select-dates-and-area-of-interest-to-read","title":"Step 1: Select dates and area of interest to read","text":""},{"location":"Sentinel-2/query_mosaic_s2_images/#step-2-query-the-products","title":"Step 2: Query the products","text":""},{"location":"Sentinel-2/query_mosaic_s2_images/#show-products-queried","title":"Show products queried","text":""},{"location":"Sentinel-2/query_mosaic_s2_images/#step-3-read-plot-the-data","title":"Step 3: Read  &amp; plot the data","text":"<p>Here we will loop over the solar days querying and mosaicking the images over the AoI.</p>"},{"location":"Sentinel-2/query_mosaic_s2_images/#licence","title":"Licence","text":"<p>The georeader package is published under a GNU Lesser GPL v3 licence</p> <p>If you find this work useful please cite:</p> <pre><code>@article{portales-julia_global_2023,\n    title = {Global flood extent segmentation in optical satellite images},\n    volume = {13},\n    issn = {2045-2322},\n    doi = {10.1038/s41598-023-47595-7},\n    number = {1},\n    urldate = {2023-11-30},\n    journal = {Scientific Reports},\n    author = {Portal\u00e9s-Juli\u00e0, Enrique and Mateo-Garc\u00eda, Gonzalo and Purcell, Cormac and G\u00f3mez-Chova, Luis},\n    month = nov,\n    year = {2023},\n    pages = {20316},\n}\n</code></pre>"},{"location":"Sentinel-2/run_in_gee_image/","title":"From Google Earth Engine","text":"<pre><code>from cloudsen12_models import cloudsen12\nimport ee\nimport matplotlib.pyplot as plt\nfrom georeader import plot\nfrom shapely.geometry import box\nfrom georeader.readers import ee_image\n</code></pre> <pre><code>ee.Authenticate()\nee.Initialize()\n</code></pre> <pre><code>collection_name = \"COPERNICUS/S2_HARMONIZED\"\ntile = \"S2A_MSIL1C_20240417T064631_N0510_R020_T40RCN_20240417T091941\"\nimg_col = ee.ImageCollection(collection_name)\nimage = img_col.filter(ee.Filter.eq(\"PRODUCT_ID\", tile)).first()\ninfo_img = image.getInfo()\n# info_img\n</code></pre> <pre><code>%%time\n\nfrom rasterio import Affine\n# projgee = image.select(\"B2\").projection().getInfo()\n\naoi = box(55.325, 25.225, 55.415, 25.28)\n\nbands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B10', 'B11', 'B12']\ncrs = info_img[\"bands\"][1][\"crs\"]\ntransform = Affine(*info_img[\"bands\"][1][\"crs_transform\"])\nimg_local = ee_image.export_image(info_img['id'],\n                                  crs=crs, transform=transform,\n                                  bands_gee=bands,\n                                  geometry=aoi)\nimg_local\n</code></pre> <pre>\n<code>Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n</code>\n</pre> <pre>\n<code>CPU times: user 421 ms, sys: 86.6 ms, total: 508 ms\nWall time: 4.18 s\n</code>\n</pre> <pre>\n<code> \n         Transform: | 10.00, 0.00, 331260.00|\n| 0.00,-10.00, 2797010.00|\n| 0.00, 0.00, 1.00|\n         Shape: (13, 622, 916)\n         Resolution: (10.0, 10.0)\n         Bounds: (331260.0, 2790790.0, 340420.0, 2797010.0)\n         CRS: EPSG:32640\n         fill_value_default: 0.0\n        </code>\n</pre> <pre><code>swirnirred = (img_local.isel({\"band\": [bands.index(b) for b in [\"B11\",\"B8\",\"B4\"]]}) / 4_500.).clip(0,1)\n\nplot.show(swirnirred)\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>model = cloudsen12.load_model_by_name(name=\"UNetMobV2_V1\", weights_folder=\"cloudsen12_models\")\n</code></pre> <pre>\n<code>/home/gonzalo/git/cloudsen12_models/cloudsen12_models/cloudsen12.py:189: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  weights = torch.load(weights_file, map_location=device)\n</code>\n</pre> <pre><code>cloudsen12.MODELS_CLOUDSEN12.keys()\n</code></pre> <pre>\n<code>dict_keys(['cloudsen12', 'UNetMobV2_V1', 'UNetMobV2_V2', 'cloudsen12l2a', 'dtacs4bands', 'landsat30'])</code>\n</pre> <pre><code>cloudmask = model.predict(img_local/10_000)\n</code></pre> <pre><code>fig, ax = plt.subplots(1,2,figsize=(14,5),sharey=True, tight_layout=True)\n\nplot.show(swirnirred,ax=ax[0])\ncloudsen12.plot_cloudSEN12mask(cloudmask,ax=ax[1])\nfig.savefig(\"example_flood_dubai_2024.png\")\n</code></pre> <pre><code>modelv2 = cloudsen12.load_model_by_name(name=\"UNetMobV2_V2\", weights_folder=\"cloudsen12_models\")\ncloudmaskv2 = modelv2.predict(img_local/10_000)\nfig, ax = plt.subplots(1,2,figsize=(14,5),sharey=True, tight_layout=True)\n\nplot.show(swirnirred,ax=ax[0])\ncloudsen12.plot_cloudSEN12mask(cloudmaskv2,ax=ax[1])\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>from shapely.geometry import mapping\ncollection_name = \"COPERNICUS/S2_SR_HARMONIZED\"\ntile = \"S2A_MSIL2A_20240417T064631_N0510_R020_T40RCN_20240417T091941\"\naoi_ee = ee.Geometry(mapping(aoi))\nimg_col = ee.ImageCollection(collection_name).filterDate('2024-04-17', '2024-04-18').filterBounds(aoi_ee)\nimage = img_col.first()\ninfo_imgl2a = image.getInfo()\n# info_imgl2a\n</code></pre> <pre><code>bandsl2a = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']\ncrs = info_imgl2a[\"bands\"][1][\"crs\"]\ntransform = Affine(*info_imgl2a[\"bands\"][1][\"crs_transform\"])\nimg_local_l2a = ee_image.export_image(info_imgl2a['id'],\n                                  crs=crs, transform=transform,\n                                  bands_gee=bandsl2a,\n                                  geometry=aoi)\nimg_local_l2a\n</code></pre> <pre>\n<code>Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n</code>\n</pre> <pre>\n<code> \n         Transform: | 10.00, 0.00, 331260.00|\n| 0.00,-10.00, 2797010.00|\n| 0.00, 0.00, 1.00|\n         Shape: (12, 622, 916)\n         Resolution: (10.0, 10.0)\n         Bounds: (331260.0, 2790790.0, 340420.0, 2797010.0)\n         CRS: EPSG:32640\n         fill_value_default: 0.0\n        </code>\n</pre> <pre><code>swirnirred_l2a = (img_local_l2a.isel({\"band\": [bandsl2a.index(b) for b in [\"B11\",\"B8\",\"B4\"]]}) / 4_500.).clip(0,1)\n\nplot.show(swirnirred_l2a)\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code>modell2a = cloudsen12.load_model_by_name(name=\"cloudsen12l2a\", weights_folder=\"cloudsen12_models\")\ncloudmask_l2a = modell2a.predict(img_local_l2a/10_000)\nfig, ax = plt.subplots(1,2,figsize=(14,5),sharey=True, tight_layout=True)\n\nplot.show(swirnirred_l2a,ax=ax[0])\ncloudsen12.plot_cloudSEN12mask(cloudmask_l2a,ax=ax[1])\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre>"},{"location":"Sentinel-2/run_in_gee_image/#run-inference-on-a-sentinel-2-image-from-the-google-earth-engine","title":"Run inference on a Sentinel-2 image from the Google Earth Engine","text":"<ul> <li>Last Modified: 30-08-2024</li> <li>Author: Gonzalo Mateo-Garc\u00eda</li> </ul>"},{"location":"Sentinel-2/run_in_gee_image/#cloudsen12","title":"CloudSEN12","text":"<p>This notebook shows how to run the CloudSEN12 model over an image downloaded from the Google Earth Engine. Hence to run this notebook you a Google Earth Engine account. </p> <p>We will run the models UnetMobV2_V1 and UnetMobV2_V2 with all bands proposed in:</p> <p>Aybar, C., Ysuhuaylas, L., Loja, J., Gonzales, K., Herrera, F., Bautista, L., Yali, R., Flores, A., Diaz, L., Cuenca, N., Espinoza, W., Prudencio, F., Llactayo, V., Montero, D., Sudmanns, M., Tiede, D., Mateo-Garc\u00eda, G., &amp; G\u00f3mez-Chova, L. (2022). CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2. Scientific Data, 9(1), Article 1. DOI: 10.1038/s41597-022-01878-2</p> <p>Aybar, C., Bautista, L., Montero, D., Contreras, J., Ayala, D., Prudencio, F., Loja, J., Ysuhuaylas, L., Herrera, F., Gonzales, K., Valladares, J., Flores, L. A., Mamani, E., Qui\u00f1onez, M., Fajardo, R., Espinoza, W., Limas, A., Yali, R., Alc\u00e1ntara, A., Leyva, M., Loayza-Muro, M., Willems, M., Mateo-Garc\u00eda, G. &amp; G\u00f3mez-Chova, L. (2024). CloudSEN12+: The largest dataset of expert-labeled pixels for cloud and cloud shadow detection in Sentinel-2. Data in Brief, 110852. DOI: 10.1016/j.dib.2024.110852</p>"},{"location":"Sentinel-2/run_in_gee_image/#unetmobv2_v1","title":"UNetMobV2_V1","text":"<p>Model trained on the first version of CloudSEN12 Aybar et al. 2022.</p>"},{"location":"Sentinel-2/run_in_gee_image/#unetmobv2_v2","title":"UnetMobV2_V2","text":"<p>Model trained on the second version of CloudSEN12 (called CloudSEN12+) Aybar et al. 2024.</p>"},{"location":"Sentinel-2/run_in_gee_image/#sentinel-2-l2a","title":"Sentinel-2 L2A","text":"<p>Run the model for L2A images.</p>"},{"location":"Sentinel-2/run_in_gee_image/#licence","title":"Licence","text":"<p>The <code>cloudsen12_models</code> package is published under a GNU Lesser GPL v3 licence</p> <p>The CloudSEN12 database and all pre-trained models are released under a Creative Commons non-commercial licence. For using the models in comercial pipelines written consent by the authors must be provided.</p> <p>This notebook is released under a Creative Commons non-commercial licence.</p> <p>If you find this work useful please cite: <pre><code>@article{aybar_cloudsen12_2024,\n    title = {{CloudSEN12}+: {The} largest dataset of expert-labeled pixels for cloud and cloud shadow detection in {Sentinel}-2},\n    issn = {2352-3409},\n    url = {https://www.sciencedirect.com/science/article/pii/S2352340924008163},\n    doi = {10.1016/j.dib.2024.110852},\n    journal = {Data in Brief},\n    author = {Aybar, Cesar and Bautista, Lesly and Montero, David and Contreras, Julio and Ayala, Daryl and Prudencio, Fernando and Loja, Jhomira and Ysuhuaylas, Luis and Herrera, Fernando and Gonzales, Karen and Valladares, Jeanett and Flores, Lucy A. and Mamani, Evelin and Qui\u00f1onez, Maria and Fajardo, Rai and Espinoza, Wendy and Limas, Antonio and Yali, Roy and Alc\u00e1ntara, Alejandro and Leyva, Martin and Loayza-Muro, Rau\u00b4l and Willems, Bram and Mateo-Garc\u00eda, Gonzalo and G\u00f3mez-Chova, Luis},\n    month = aug,\n    year = {2024},\n    pages = {110852},\n}\n\n@article{aybar_cloudsen12_2022,\n    title = {{CloudSEN12}, a global dataset for semantic understanding of cloud and cloud shadow in {Sentinel}-2},\n    volume = {9},\n    issn = {2052-4463},\n    url = {https://www.nature.com/articles/s41597-022-01878-2},\n    doi = {10.1038/s41597-022-01878-2},\n    number = {1},\n    urldate = {2023-01-02},\n    journal = {Scientific Data},\n    author = {Aybar, Cesar and Ysuhuaylas, Luis and Loja, Jhomira and Gonzales, Karen and Herrera, Fernando and Bautista, Lesly and Yali, Roy and Flores, Angie and Diaz, Lissette and Cuenca, Nicole and Espinoza, Wendy and Prudencio, Fernando and Llactayo, Valeria and Montero, David and Sudmanns, Martin and Tiede, Dirk and Mateo-Garc\u00eda, Gonzalo and G\u00f3mez-Chova, Luis},\n    month = dec,\n    year = {2022},\n    pages = {782},\n}\n</code></pre></p>"},{"location":"Sentinel-2/s2_mosaic_from_gee/","title":"Mosaic from GEE","text":"<pre><code>from shapely.geometry import shape, mapping\nfrom datetime import datetime, timedelta\nimport ee\n\nee.Authenticate()\nee.Initialize()\n\nfootprint = shape({'type': 'Polygon',\n 'coordinates': (((58.21132510761841, 40.391771861041725),\n   (58.205632677871314, 40.07155762141618),\n   (58.649475248490724, 40.06608738064447),\n   (58.65726127535553, 40.38623968067468),\n   (58.21132510761841, 40.391771861041725)),)})\n\ndate_search = datetime.fromisoformat(\"2024-10-09T06:54:26+00:00\")\ndate_search\n</code></pre> <pre>\n<code>*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_0JLhFqfSY1uiEaW?source=Init\n</code>\n</pre> <pre>\n<code>datetime.datetime(2024, 10, 9, 6, 54, 26, tzinfo=datetime.timezone.utc)</code>\n</pre> <p>Earth Engine code adapted from This blog post.</p> <pre><code>s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\ncsPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED')\n\n\nROI = ee.Geometry(mapping(footprint))\n# ROI = ee.Geometry.Point(-119.9087, 37.4159)\n\nQA_BAND = 'cs'\nCLEAR_THRESHOLD = 0.60\n\ndate_search_min = date_search - timedelta(days=30)\ndate_search_max = date_search + timedelta(days=30)\ncomposite = s2.filterBounds(ROI)\\\n    .filterDate(date_search_min.strftime('%Y-%m-%d'), date_search_max.strftime('%Y-%m-%d'))\\\n    .linkCollection(csPlus, [QA_BAND])\\\n    .map(lambda img: img.updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)))\\\n    .median()\n\ncomposite\n</code></pre> <pre>\n<code>&lt;ee.image.Image at 0x7efee73ebf70&gt;</code>\n</pre> <pre><code>from georeader import get_utm_epsg\nfrom georeader import window_utils\n\ncrs_utm = get_utm_epsg(footprint)\nfootprint_utm = window_utils.polygon_to_crs(footprint, \"EPSG:4326\", crs_utm)\n\ntransform = window_utils.figure_out_transform(bounds=footprint_utm.bounds, resolution_dst=30)\ntransform\n</code></pre> <pre>\n<code>Affine(30.0, 0.0, 602806.2544585154,\n       0.0, -30.0, 4471945.817948307)</code>\n</pre> <pre><code>%%time\nfrom georeader.readers import ee_image\nimport numpy as np\n\nmosaic = ee_image.export_image(composite, footprint, transform=transform, crs=crs_utm, \n                               bands_gee=[\"B4\",\"B3\",\"B2\"])\nmosaic\n</code></pre> <pre>\n<code>CPU times: user 473 ms, sys: 50.6 ms, total: 523 ms\nWall time: 1min 8s\n</code>\n</pre> <pre>\n<code> \n         Transform: | 30.00, 0.00, 602806.25|\n| 0.00,-30.00, 4471945.82|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 1186, 1263)\n         Resolution: (30.0, 30.0)\n         Bounds: (602806.2544585154, 4436365.817948307, 640696.2544585154, 4471945.817948307)\n         CRS: EPSG:32640\n         fill_value_default: None\n        </code>\n</pre> <pre><code>from georeader import plot\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\n\nmosaic = mosaic.pad({\"x\": (5,5), \"y\": (5,5)})\nmosaic_rgb = (mosaic / 5_500).clip(0,1)\nplot.show(mosaic_rgb, ax=ax)\n\nplot.add_shape_to_plot(footprint, ax=ax, crs_plot=mosaic_rgb.crs, polygon_no_fill=True, crs_shape=\"EPSG:4326\",\n                       kwargs_geopandas_plot={\"color\":\"red\"})\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre> <pre><code># https://medium.com/@nst11/annual-landsat-cloud-free-composite-in-google-earth-engine-c623b69749f7\ndef maskL8KH(image):\n  # Bits 3 and 5 are cloud shadow and cloud, respectively.\n  cloudShadowBitMask = (1 &amp;lt;&amp;lt; 3)\n  cloudsBitMask = (1 &amp;lt;&amp;lt; 5)\n  # Get the pixel QA band.\n  qa = image.select('QA_PIXEL')\n  # Both flags should be set to zero, indicating clear conditions.\n  mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(qa.bitwiseAnd(cloudsBitMask).eq(0))\n  return image.updateMask(mask)\n\ncols = [\"LANDSAT/LC09/C02/T1_TOA\", \"LANDSAT/LC08/C02/T1_RT_TOA\", \"LANDSAT/LC08/C02/T2_TOA\",\"LANDSAT/LC09/C02/T2_TOA\"]\nl89col = ee.ImageCollection(cols[0])\nfor c in cols[1:]:\n    l89col.merge(ee.ImageCollection(c))\n\n\nROI = ee.Geometry(mapping(footprint))\n# ROI = ee.Geometry.Point(-119.9087, 37.4159)\n\ndate_search_min = date_search - timedelta(days=30)\ndate_search_max = date_search + timedelta(days=30)\ncomposite_l8 = l89col.filterBounds(ROI)\\\n    .filterDate(date_search_min.strftime('%Y-%m-%d'), date_search_max.strftime('%Y-%m-%d'))\\\n    .map(lambda img: maskL8KH(img))\\\n    .median()\n\ncomposite_l8\n</code></pre> <pre>\n<code>&lt;ee.image.Image at 0x7efed8dcbeb0&gt;</code>\n</pre> <pre><code>%%time\nmosaic_l8 = ee_image.export_image(composite, footprint, transform=transform, crs=crs_utm, \n                                  bands_gee=[\"B4\",\"B3\",\"B2\"])\nmosaic_l8\n</code></pre> <pre>\n<code> \n         Transform: | 30.00, 0.00, 602806.25|\n| 0.00,-30.00, 4471945.82|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 1186, 1263)\n         Resolution: (30.0, 30.0)\n         Bounds: (602806.2544585154, 4436365.817948307, 640696.2544585154, 4471945.817948307)\n         CRS: EPSG:32640\n         fill_value_default: None\n        </code>\n</pre> <pre><code>fig, ax = plt.subplots(1,1, figsize=(8,8))\n\nmosaic_l8 = mosaic_l8.pad({\"x\": (5,5), \"y\": (5,5)})\nmosaic_l8_rgb = (mosaic_l8 / 5_500).clip(0,1)\nplot.show(mosaic_l8_rgb, ax=ax)\n\nplot.add_shape_to_plot(footprint, ax=ax, crs_plot=mosaic_l8_rgb.crs, polygon_no_fill=True, crs_shape=\"EPSG:4326\",\n                       kwargs_geopandas_plot={\"color\":\"red\"})\n</code></pre> <pre>\n<code>&lt;Axes: &gt;</code>\n</pre>"},{"location":"Sentinel-2/s2_mosaic_from_gee/#query-a-spatial-mosaic-from-the-google-earth-engine","title":"Query a spatial mosaic from the Google Earth Engine","text":"<ul> <li>Last Modified: 3-12-2024</li> <li>Author: Gonzalo Mateo-Garc\u00eda</li> </ul> <p>This tutorial shows how to use the <code>georeaders.readers.ee_image</code> module to download an spatial composite with Sentinel-2 or Landsat. </p>"},{"location":"Sentinel-2/s2_mosaic_from_gee/#composite-for-landsat-8-and-9","title":"Composite for Landsat-8 and 9","text":"<p>Earth Engine code adapted from This blog post.</p>"},{"location":"advanced/error_read_write_in_remote_path/","title":"Reading from remote location: GDAL VSIL caching issue","text":"<p>Reading a raster from a remote location (e.g. Google, Amazon or Azure bucket) fails if the file is read and modified by other (non-GDAL) function/process. This happens even if the file is closed after reading and then modified. This is because GDAL has a global cache when reading data from remote locations. This notebook shows this problem and a fix implemented in <code>RasterioReader</code> to skip the caching (called <code>read_with_CPL_VSIL_CURL_NON_CACHED</code>). A direct fix in GDAL would be to call <code>VSICurlClearCache</code> or <code>VSICurlPartialClearCache</code> C functions; however these are not mapped in <code>rasterio</code>. </p> <p>The solution implemented with <code>rasterio</code> consists of setting the <code>CPL_VSIL_CURL_NON_CACHED</code> GDAL option before opening the file with <code>rasterio</code>; see the fix in <code>georeader.rasterio_reader.RasterioReader._rio_open</code> function.</p> <pre><code>import os\nimport fsspec\n\nos.environ[\"AZURE_STORAGE_CONNECTION_STRING\"] = \"????\"\nfs = fsspec.filesystem(\"az\")\n</code></pre> <p>This example will read a 3-band rgb COG and modify it by a one band COG with a different shape. We will see that when the COG is modified we can't read the file again if we don't set the <code>read_with_CPL_VSIL_CURL_NON_CACHED</code> option. We will see either a read error (if we haven't loaded the data) or we will see the old cached data (if we have load the data).</p> <pre><code># Set up the files\n# rasterio_reader.RIO_ENV_OPTIONS_DEFAULT[\"CPL_CURL_VERBOSE\"] = \"YES\"\nrgb_file = \"az://mycontainer/rgb.tif\"\none_band_file = \"az://mycontainer/one_band.tif\"\nassert fs.exists(rgb_file)\nassert fs.exists(one_band_file)\n\nfilepath = \"az://mycontainer/removeme.tif\"\nif fs.exists(filepath):\n    fs.delete(filepath)\n</code></pre> <pre><code>from georeader.rasterio_reader import RasterioReader\n\nfs.copy(rgb_file, filepath)\nrst = RasterioReader(filepath)\nrst\n</code></pre> <pre><code>         Paths: ['az://mycontainer/removeme.tif']\n         Transform: | 30.00, 0.00, 740744.72|\n| 0.00,-30.00, 4287081.96|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 1176, 1168)\n         Resolution: (30.0, 30.0)\n         Bounds: (740744.717767204, 4251801.958449183, 775784.717767204, 4287081.958449183)\n         CRS: EPSG:32641\n         nodata: 0.0\n         fill_value_default: 0.0\n</code></pre> <p>Reading now fails (we haven't loaded the data).</p> <pre><code>fs.copy(one_band_file, filepath)\nrst = RasterioReader(filepath)\ndata_rst = rst.load()\ndata_rst\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nCPLE_AppDefinedError                      Traceback (most recent call last)\n\nCPLE_AppDefinedError: LZWDecode:Corrupted LZW table at scanline 0\n\n\nThe above exception was the direct cause of the following exception:\n\n\nCPLE_AppDefinedError                      Traceback (most recent call last)\n\nCPLE_AppDefinedError: TIFFReadEncodedTile() failed.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nCPLE_AppDefinedError                      Traceback (most recent call last)\n\nFile rasterio/_io.pyx:969, in rasterio._io.DatasetReaderBase._read()\n\n\nFile rasterio/_io.pyx:199, in rasterio._io.io_multi_band()\n\n\nFile rasterio/_io.pyx:205, in rasterio._io.io_multi_band()\n\n\nFile rasterio/_err.pyx:325, in rasterio._err.StackChecker.exc_wrap_int()\n\n\nCPLE_AppDefinedError: removeme.tif, band 1: IReadBlock failed at X offset 0, Y offset 0: TIFFReadEncodedTile() failed.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nRasterioIOError                           Traceback (most recent call last)\n\nCell In[4], line 3\n      1 fs.copy(one_band_file, filepath)\n      2 rst = RasterioReader(filepath)\n----&gt; 3 data_rst = rst.load()\n      4 data_rst\n\n\nFile ~/git/georeader/georeader/rasterio_reader.py:554, in RasterioReader.load(self, boundless)\n    546 def load(self, boundless:bool=True) -&gt; geotensor.GeoTensor:\n    547     \"\"\"\n    548     Load all raster in memory in an GeoTensor object\n    549 \n   (...)\n    552 \n    553     \"\"\"\n--&gt; 554     np_data = self.read(boundless=boundless)\n    555     if boundless:\n    556         transform = self.transform\n\n\nFile ~/git/georeader/georeader/rasterio_reader.py:704, in RasterioReader.read(self, **kwargs)\n    699 for i, p in enumerate(self.paths):\n    700     # with rasterio.Env(**options):\n    701     #     with rasterio.open(p, \"r\", overview_level=self.overview_level) as src:\n    702     with self._rio_open(p, overview_level=self.overview_level) as src:\n    703         # rasterio.read API: https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.read\n--&gt; 704         read_data = src.read(**kwargs)\n    706         # Add pad when reading\n    707         if pad is not None and need_pad:\n\n\nFile rasterio/_io.pyx:644, in rasterio._io.DatasetReaderBase.read()\n\n\nFile rasterio/_io.pyx:972, in rasterio._io.DatasetReaderBase._read()\n\n\nRasterioIOError: Read failed. See previous exception for details.\n</code></pre> <pre><code>rst.rio_env_options\n</code></pre> <pre><code>{'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR',\n 'GDAL_HTTP_MERGE_CONSECUTIVE_RANGES': 'YES',\n 'GDAL_CACHEMAX': 2000000000,\n 'GDAL_HTTP_MULTIPLEX': 'YES'}\n</code></pre> <pre><code>fs.delete(filepath)\n</code></pre> <p>Reading and loading the data will return the old data instead of the new one. (The rgb raster had 3 bands and the other one only one).</p> <pre><code>filepath = \"az://mycontainer/removeme2.tif\"\nif fs.exists(filepath):\n    fs.delete(filepath)\n\nfs.copy(rgb_file, filepath)\nrst_mem = RasterioReader(filepath).load()\nrst_mem\n</code></pre> <pre><code>         Transform: | 30.00, 0.00, 740744.72|\n| 0.00,-30.00, 4287081.96|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 1176, 1168)\n         Resolution: (30.0, 30.0)\n         Bounds: (740744.717767204, 4251801.958449183, 775784.717767204, 4287081.958449183)\n         CRS: EPSG:32641\n         fill_value_default: 0.0\n</code></pre> <pre><code>fs.copy(one_band_file, filepath)\nrst = RasterioReader(filepath)\ndata_rst = rst.load()\ndata_rst\n</code></pre> <pre><code>         Transform: | 30.00, 0.00, 740744.72|\n| 0.00,-30.00, 4287081.96|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 1176, 1168)\n         Resolution: (30.0, 30.0)\n         Bounds: (740744.717767204, 4251801.958449183, 775784.717767204, 4287081.958449183)\n         CRS: EPSG:32641\n         fill_value_default: 0.0\n</code></pre> <pre><code>fs.delete(filepath)\n</code></pre> <p>Adding option  <code>read_with_CPL_VSIL_CURL_NON_CACHED</code> fixes the problem, we see that after the second copy the raster has 1 channel instead of 3.</p> <pre><code>from georeader import rasterio_reader\nrasterio_reader.RIO_ENV_OPTIONS_DEFAULT[\"read_with_CPL_VSIL_CURL_NON_CACHED\"] = True\n</code></pre> <pre><code>filepath = \"az://mycontainer/removeme3.tif\"\nif fs.exists(filepath):\n    fs.delete(filepath)\n\nfs.copy(rgb_file, filepath)\nrst_mem = RasterioReader(filepath).load()\nrst_mem\n</code></pre> <pre><code>         Transform: | 30.00, 0.00, 740744.72|\n| 0.00,-30.00, 4287081.96|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 1176, 1168)\n         Resolution: (30.0, 30.0)\n         Bounds: (740744.717767204, 4251801.958449183, 775784.717767204, 4287081.958449183)\n         CRS: EPSG:32641\n         fill_value_default: 0.0\n</code></pre> <pre><code>fs.copy(one_band_file, filepath)\nrst = RasterioReader(filepath)\ndata_rst = rst.load()\ndata_rst\n</code></pre> <pre><code>         Transform: | 30.00, 0.00, 255639.31|\n| 0.00,-30.00, 3165851.00|\n| 0.00, 0.00, 1.00|\n         Shape: (1, 1262, 1369)\n         Resolution: (30.0, 30.0)\n         Bounds: (255639.3130302397, 3127990.9952690094, 296709.31303023966, 3165850.9952690094)\n         CRS: EPSG:32640\n         fill_value_default: -1.0\n</code></pre> <pre><code>fs.delete(filepath)\n</code></pre> <p>If we don't load the data we don't have the error and the file is correctly readed too:</p> <pre><code>filepath = \"az://mycontainer/removeme3.tif\"\nif fs.exists(filepath):\n    fs.delete(filepath)\n\nfs.copy(rgb_file, filepath)\nrst = RasterioReader(filepath)\nrst\n</code></pre> <pre><code>         Paths: ['az://mycontainer/removeme3.tif']\n         Transform: | 30.00, 0.00, 740744.72|\n| 0.00,-30.00, 4287081.96|\n| 0.00, 0.00, 1.00|\n         Shape: (3, 1176, 1168)\n         Resolution: (30.0, 30.0)\n         Bounds: (740744.717767204, 4251801.958449183, 775784.717767204, 4287081.958449183)\n         CRS: EPSG:32641\n         nodata: 0.0\n         fill_value_default: 0.0\n</code></pre> <pre><code>fs.copy(one_band_file, filepath)\nrst = RasterioReader(filepath)\ndata_rst = rst.load()\ndata_rst\n</code></pre> <pre><code>         Transform: | 30.00, 0.00, 255639.31|\n| 0.00,-30.00, 3165851.00|\n| 0.00, 0.00, 1.00|\n         Shape: (1, 1262, 1369)\n         Resolution: (30.0, 30.0)\n         Bounds: (255639.3130302397, 3127990.9952690094, 296709.31303023966, 3165850.9952690094)\n         CRS: EPSG:32640\n         fill_value_default: -1.0\n</code></pre> <pre><code>rst.rio_env_options\n</code></pre> <pre><code>{'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR',\n 'GDAL_HTTP_MERGE_CONSECUTIVE_RANGES': 'YES',\n 'GDAL_CACHEMAX': 2000000000,\n 'GDAL_HTTP_MULTIPLEX': 'YES',\n 'read_with_CPL_VSIL_CURL_NON_CACHED': True}\n</code></pre>"},{"location":"modules/ee_image/","title":"ee_image","text":""},{"location":"modules/ee_image/#google-earth-engine-functions","title":"Google Earth Engine functions","text":"<p>We have implemented functions to query and export arbitrarly large images from the Google Earth Engine.  Functions to export images or cubes are in module <code>georeader.readers.ee_image</code> and functions to query Sentinel-1, Sentinel-2 and Landsat are available in <code>georeader.readers.ee_query</code>.</p>"},{"location":"modules/ee_image/#georeader.readers.ee_image.export_image","title":"<code>export_image(image_or_asset_id, geometry, transform, crs, bands_gee, dtype_dst=None, pad_add=(0, 0), crs_polygon='EPSG:4326', resolution_dst=None)</code>","text":"<p>Exports an image from the GEE as a GeoTensor.   It uses the <code>ee.data.getPixels</code> or <code>ee.data.computePixels</code> method to export the image.</p> <p>Parameters:</p> Name Type Description Default <code>image_or_asset_id</code> <code>Union[str, Image]</code> <p>Name of the asset or ee.Image object.</p> required <code>geometry</code> <code>Union[Polygon, MultiPolygon]</code> <p>geometry to export</p> required <code>transform</code> <code>Affine</code> <p>transform of the geometry</p> required <code>crs</code> <code>str</code> <p>crs of the geometry</p> required <code>pad_add</code> <code>Tuple[int, int]</code> <p>pad in pixels to add to the resulting <code>window</code> that is read. This is useful when this function  is called for interpolation/CNN prediction.</p> <code>(0, 0)</code> <code>bands_gee</code> <code>List[str]</code> <p>List of bands to export</p> required <code>crs_polygon</code> <code>str</code> <p>crs of the geometry. Defaults to \"EPSG:4326\".</p> <code>'EPSG:4326'</code> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>GeoTensor</code> <p>GeoTensor object</p> Source code in <code>georeader/readers/ee_image.py</code> <pre><code>def export_image(image_or_asset_id:Union[str, ee.Image], \n                 geometry:Union[Polygon, MultiPolygon],\n                 transform:Affine, crs:str,\n                 bands_gee:List[str], \n                 dtype_dst:Optional[str]=None,\n                 pad_add:Tuple[int, int]=(0, 0),\n                 crs_polygon:str=\"EPSG:4326\",\n                 resolution_dst: Optional[Union[float, Tuple[float, float]]]=None) -&gt; GeoTensor:\n    \"\"\"\n    Exports an image from the GEE as a GeoTensor. \n     It uses the `ee.data.getPixels` or `ee.data.computePixels` method to export the image.\n\n    Args:\n        image_or_asset_id (Union[str, ee.Image]): Name of the asset or ee.Image object.\n        geometry (Union[Polygon, MultiPolygon]): geometry to export\n        transform (Affine): transform of the geometry\n        crs (str): crs of the geometry\n        pad_add: pad in pixels to add to the resulting `window` that is read. This is useful when this function \n            is called for interpolation/CNN prediction.\n        bands_gee (List[str]): List of bands to export\n        crs_polygon (str, optional): crs of the geometry. Defaults to \"EPSG:4326\".\n\n    Returns:\n        GeoTensor: GeoTensor object\n    \"\"\"\n    if isinstance(image_or_asset_id, str):\n        method = ee.data.getPixels\n        request_params = {\"assetId\": image_or_asset_id}\n    elif isinstance(image_or_asset_id, ee.Image):\n        method = ee.data.computePixels\n        request_params = {\"expression\": image_or_asset_id}\n        # TODO if crs and transform are not provided get it from the image?\n    else:\n        raise ValueError(f\"image_or_asset_id must be a string or ee.Image object found {type(image_or_asset_id)}\")\n\n    geodata = FakeGeoData(crs=crs, transform=transform)\n\n    # Pixel coordinates surrounding the geometry\n    window_polygon = read.window_from_polygon(geodata, geometry, crs_polygon=crs_polygon,\n                                              window_surrounding=True)\n    if any(p &gt; 0 for p in pad_add):\n        window_polygon = window_utils.pad_window(window_polygon, pad_add)\n    window_polygon = window_utils.round_outer_window(window_polygon)\n\n    # Shift the window to the image coordinates\n    transform_window = rasterio.windows.transform(window_polygon, geodata.transform)\n\n    if resolution_dst is not None:\n        transform_window = window_utils.transform_to_resolution_dst(transform_window, resolution_dst)\n\n    request_params.update({\n                    'fileFormat':\"GEO_TIFF\", \n                    'bandIds':  bands_gee,\n                    'grid': {\n                        'dimensions': {\n                            'height': window_polygon.height, \n                            'width': window_polygon.width\n                        },\n                        'affineTransform': {\n                            'scaleX': transform_window.a,\n                            'shearX': transform_window.b,\n                            'translateX': transform_window.c,\n                            'shearY': transform_window.d,\n                            'scaleY': transform_window.e,\n                            'translateY': transform_window.f\n                        },\n                        'crsCode': geodata.crs\n                    }\n                    })\n\n    try:\n        data_raw = method(request_params)\n        data = rasterio.open(BytesIO(data_raw))\n        geotensor = GeoTensor(data.read(), transform=data.transform,\n                             crs=data.crs, fill_value_default=data.nodata)\n        if dtype_dst is not None:\n            geotensor = geotensor.astype(dtype_dst)\n\n    except ee.EEException as e:\n        # Check if the exception starts with Total request size\n        if str(e).startswith(\"Total request size\"):\n            # Split the geometry in two and call recursively\n            pols_execute = []\n            for sb in split_bounds(geometry.bounds):\n                pol = box(*sb)\n                if not geometry.intersects(pol):\n                    continue\n                pols_execute.append(pol.intersection(geometry))\n\n            def process_bound(poly):\n                gt = export_image(image_or_asset_id=image_or_asset_id, geometry=poly, \n                                  crs=crs, transform=transform, \n                                  bands_gee=bands_gee, dtype_dst=dtype_dst, \n                                  crs_polygon=crs_polygon,\n                                  resolution_dst=resolution_dst)\n                return gt\n\n            with ThreadPoolExecutor() as executor:\n                geotensors = list(executor.map(process_bound, pols_execute))\n\n            # Remove None values from the list\n            geotensors = [gt for gt in geotensors if gt is not None]\n\n            dst_crs = geotensors[0].crs\n            aoi_dst_crs = window_utils.polygon_to_crs(geometry, \n                                                      crs_polygon=crs_polygon, \n                                                      dst_crs=dst_crs)\n\n            geotensor = mosaic.spatial_mosaic(geotensors, \n                                              dtype_dst=dtype_dst,\n                                              polygon=aoi_dst_crs, \n                                              dst_crs=dst_crs)\n        else:\n            raise e\n    return geotensor\n</code></pre>"},{"location":"modules/ee_image/#georeader.readers.ee_image.export_cube","title":"<code>export_cube(query, geometry, transform=None, crs=None, dtype_dst=None, bands_gee=None, crs_polygon='EPSG:4326', display_progress=True)</code>","text":"<p>Download all images in the query that intersects the geometry. </p> <p>Note: This function is intended for small areas. If the area is too big that there are several images per day that intesesects the geometry, it will not group the images by day.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>GeoDataFrame</code> <p>dataframe from <code>georeaders.readers.query</code>. Required columns: gee_id, collection_name, bands_gee</p> required <code>geometry</code> <code>Union[Polygon, MultiPolygon]</code> <p>geometry to export</p> required <code>transform</code> <code>Optional[Affine]</code> <p>transform of the geometry. If None it will use the transform of the first image translated to the geometry.  Defaults to None.</p> <code>None</code> <code>crs</code> <code>Optional[str]</code> <p>crs of the geometry. If None it will use the crs of the first image. Defaults to None.</p> <code>None</code> <code>dtype_dst</code> <code>Optional[str]</code> <p>dtype of the output GeoTensor. Defaults to None.</p> <code>None</code> <code>bands_gee</code> <code>Optional[List[str]]</code> <p>List of bands to export. If None it will use the bands_gee column in the query. Defaults to None.</p> <code>None</code> <code>crs_polygon</code> <code>_type_</code> <p>crs of the geometry. Defaults to \"EPSG:4326\".</p> <code>'EPSG:4326'</code> <code>display_progress</code> <code>bool</code> <p>Display progress bar. Defaults to False.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>Optional[GeoTensor]</code> <p>GeoTensor object with 4 dimensions: (time, band, y, x)</p> Source code in <code>georeader/readers/ee_image.py</code> <pre><code>def export_cube(query:gpd.GeoDataFrame, geometry:Union[Polygon, MultiPolygon], \n                transform:Optional[Affine]=None, crs:Optional[str]=None,\n                dtype_dst:Optional[str]=None,\n                bands_gee:Optional[List[str]]=None,\n                crs_polygon:str=\"EPSG:4326\",\n                display_progress:bool=True) -&gt; Optional[GeoTensor]:\n    \"\"\"\n    Download all images in the query that intersects the geometry. \n\n    Note: This function is intended for small areas. If the area is too big that there are several images per day that intesesects the geometry, it will not group the images by day.\n\n    Args:\n        query (gpd.GeoDataFrame): dataframe from `georeaders.readers.query`. Required columns: gee_id, collection_name, bands_gee\n        geometry (Union[Polygon, MultiPolygon]): geometry to export\n        transform (Optional[Affine], optional): transform of the geometry. If None it will use the transform of the first image translated to the geometry. \n            Defaults to None.\n        crs (Optional[str], optional): crs of the geometry. If None it will use the crs of the first image. Defaults to None.\n        dtype_dst (Optional[str], optional): dtype of the output GeoTensor. Defaults to None.\n        bands_gee (Optional[List[str]], optional): List of bands to export. If None it will use the bands_gee column in the query. Defaults to None.\n        crs_polygon (_type_, optional): crs of the geometry. Defaults to \"EPSG:4326\".\n        display_progress (bool, optional): Display progress bar. Defaults to False.\n\n    Returns:\n        GeoTensor: GeoTensor object with 4 dimensions: (time, band, y, x)\n    \"\"\"\n\n    # TODO group by solar_day and satellite??\n    if query.shape[0] == 0:\n        return None\n\n    # Check required columns\n    required_columns = [\"gee_id\", \"collection_name\"]\n    if bands_gee is None:\n        required_columns.append(\"bands_gee\")\n    if not all([col in query.columns for col in required_columns]):\n        raise ValueError(f\"Columns {required_columns} are required in the query dataframe\")\n\n    # Get the first image to get the crs and transform if not provided\n    if crs is None:\n        first_image = query.iloc[0]\n        if \"proj\" not in first_image:\n            raise ValueError(\"proj column is required in the query dataframe if crs is not provided\")\n        crs = first_image[\"proj\"][\"crs\"]\n\n    if transform is None:\n        first_image = query.iloc[0]\n        if \"proj\" not in first_image:\n            raise ValueError(\"proj column is required in the query dataframe if transform is not provided\")\n        transform = Affine(*first_image[\"proj\"][\"transform\"])\n\n\n    # geotensor_list = []\n    # for i, image in query.iterrows():\n    #     asset_id = f'{image[\"collection_name\"]}/{image[\"gee_id\"]}'\n    #     geotensor = export_image_getpixels(asset_id, geometry, proj, image[\"bands_gee\"], crs_polygon=crs_polygon, dtype_dst=dtype_dst)\n    #     geotensor_list.append(geotensor)\n\n    def process_query_image(tuple_row):\n        _, image = tuple_row\n        asset_id = f'{image[\"collection_name\"]}/{image[\"gee_id\"]}'\n        if bands_gee is None:\n            bands_gee_iter = image[\"bands_gee\"]\n        else:\n            bands_gee_iter = bands_gee\n        geotensor = export_image(asset_id, geometry=geometry, crs=crs, transform=transform,\n                                 bands_gee_iter=bands_gee_iter, \n                                 crs_polygon=crs_polygon, dtype_dst=dtype_dst)\n        return geotensor\n\n    with ThreadPoolExecutor() as executor:\n        geotensor_list = list(tqdm(executor.map(process_query_image, query.iterrows()), \n                                   total=query.shape[0], disable=not display_progress))\n\n    return concatenate(geotensor_list)\n</code></pre>"},{"location":"modules/ee_image/#georeader.readers.ee_query.query","title":"<code>query(area, date_start, date_end, producttype='S2', filter_duplicates=True, return_collection=False, add_s2cloudless=False, extra_metadata_keys=None)</code>","text":"<p>Query Landsat and Sentinel-2 products from the Google Earth Engine.</p> <p>Parameters:</p> Name Type Description Default <code>area</code> <code>Union[MultiPolygon, Polygon]</code> <p>area to query images in EPSG:4326</p> required <code>date_start</code> <code>datetime</code> <p>datetime in a given timezone. If tz not provided UTC will be assumed.</p> required <code>date_end</code> <code>datetime</code> <p>datetime in UTC. If tz not provided UTC will be assumed.</p> required <code>producttype</code> <code>str</code> <p>'S2', \"Landsat\"-&gt; {\"L8\", \"L9\"}, \"both\" -&gt; {\"S2\", \"L8\", \"L9\"}, \"S2_SR\", \"L8\", \"L9\"</p> <code>'S2'</code> <code>filter_duplicates</code> <code>bool</code> <p>Filter S2 images that are duplicated</p> <code>True</code> <code>return_collection</code> <code>bool</code> <p>returns also the corresponding image collection</p> <code>False</code> <code>add_s2cloudless</code> <code>bool</code> <p>Adds a column that indicates if the s2cloudless image is available (from collection COPERNICUS/S2_CLOUD_PROBABILITY collection)</p> <code>False</code> <code>extra_metadata_keys</code> <code>Optional[List[str]]</code> <p>list of extra metadata keys to add to the geodataframe.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[GeoDataFrame, Tuple[GeoDataFrame, ImageCollection]]</code> <p>geodataframe with available products in the given area and time range</p> <code>Union[GeoDataFrame, Tuple[GeoDataFrame, ImageCollection]]</code> <p>if <code>return_collection</code> is True it also returns the <code>ee.ImageCollection</code> of available images</p> Source code in <code>georeader/readers/ee_query.py</code> <pre><code>def query(area:Union[MultiPolygon,Polygon],\n          date_start:datetime, date_end:datetime,\n          producttype:str='S2', filter_duplicates:bool=True,\n          return_collection:bool=False,\n          add_s2cloudless:bool=False,\n          extra_metadata_keys:Optional[List[str]]=None\n          )-&gt; Union[gpd.GeoDataFrame, Tuple[gpd.GeoDataFrame, ee.ImageCollection]]:\n    \"\"\"\n    Query Landsat and Sentinel-2 products from the Google Earth Engine.\n\n    Args:\n        area: area to query images in EPSG:4326\n        date_start: datetime in a given timezone. If tz not provided UTC will be assumed.\n        date_end: datetime in UTC. If tz not provided UTC will be assumed.\n        producttype: 'S2', \"Landsat\"-&gt; {\"L8\", \"L9\"}, \"both\" -&gt; {\"S2\", \"L8\", \"L9\"}, \"S2_SR\", \"L8\", \"L9\"\n        filter_duplicates: Filter S2 images that are duplicated\n        return_collection: returns also the corresponding image collection\n        add_s2cloudless: Adds a column that indicates if the s2cloudless image is available (from collection\n            COPERNICUS/S2_CLOUD_PROBABILITY collection)\n        extra_metadata_keys: list of extra metadata keys to add to the geodataframe.\n\n    Returns:\n        geodataframe with available products in the given area and time range\n        if `return_collection` is True it also returns the `ee.ImageCollection` of available images\n    \"\"\"\n\n    pol = ee.Geometry(mapping(area))\n\n    if date_start.tzinfo is not None:\n        tz = date_start.tzinfo\n        if isinstance(tz, ZoneInfo):\n            tz = tz.key\n\n        date_start = date_start.astimezone(timezone.utc)\n        date_end = date_end.astimezone(timezone.utc)\n    else:\n        tz = timezone.utc\n\n    assert date_end &gt;= date_start, f\"Date end: {date_end} prior to date start: {date_start}\"\n\n    if producttype == \"S2_SR\":\n        image_collection_name = \"COPERNICUS/S2_SR_HARMONIZED\"\n        keys_query = {\"PRODUCT_ID\": \"title\", 'CLOUDY_PIXEL_PERCENTAGE': \"cloudcoverpercentage\"}\n    elif producttype == \"S2\":\n        image_collection_name = \"COPERNICUS/S2_HARMONIZED\"\n        keys_query = {\"PRODUCT_ID\": \"title\", 'CLOUDY_PIXEL_PERCENTAGE': \"cloudcoverpercentage\"}\n    elif producttype == \"Landsat\":\n        image_collection_name = \"LANDSAT/LC08/C02/T1_RT_TOA\"\n        keys_query = {\"LANDSAT_PRODUCT_ID\": \"title\", 'CLOUD_COVER': \"cloudcoverpercentage\"}\n    elif producttype == \"L8\":\n        image_collection_name = \"LANDSAT/LC08/C02/T1_RT_TOA\"\n        keys_query = {\"LANDSAT_PRODUCT_ID\": \"title\", 'CLOUD_COVER': \"cloudcoverpercentage\"}\n    elif producttype == \"L9\":\n        image_collection_name = \"LANDSAT/LC09/C02/T1_TOA\"\n        keys_query = {\"LANDSAT_PRODUCT_ID\": \"title\", 'CLOUD_COVER': \"cloudcoverpercentage\"}\n    elif producttype == \"both\":\n        image_collection_name = \"LANDSAT/LC08/C02/T1_RT_TOA\"\n        keys_query = {\"LANDSAT_PRODUCT_ID\": \"title\", 'CLOUD_COVER': \"cloudcoverpercentage\"}\n    else:\n        raise NotImplementedError(f\"Unknown product type {producttype}\")\n\n    img_col = ee.ImageCollection(image_collection_name).filterDate(date_start.replace(tzinfo=None),\n                                                                   date_end.replace(tzinfo=None)).filterBounds(\n        pol)\n    if \"T1\" in image_collection_name:\n        # Add tier 2 data to the query\n        image_collection_name_t2 = image_collection_name.replace(\"T1_RT\", \"T2\").replace(\"T1\", \"T2\")\n        img_col_t1 = ee.ImageCollection(image_collection_name_t2).filterDate(date_start.replace(tzinfo=None),\n                                                                     date_end.replace(tzinfo=None)).filterBounds(\n            pol)\n        img_col = img_col.merge(img_col_t1)\n\n    if (producttype == \"Landsat\") or (producttype == \"both\"):\n        img_col_l9 = ee.ImageCollection(\"LANDSAT/LC09/C02/T1_TOA\").filterDate(date_start.replace(tzinfo=None),\n                                                                   date_end.replace(tzinfo=None)).filterBounds(\n        pol)\n        img_col = img_col.merge(img_col_l9)\n        img_col_l9_t2 = ee.ImageCollection(\"LANDSAT/LC09/C02/T2_TOA\").filterDate(date_start.replace(tzinfo=None),\n                                                                   date_end.replace(tzinfo=None)).filterBounds(\n        pol)\n        img_col = img_col.merge(img_col_l9_t2)\n\n    if extra_metadata_keys is None:\n        extra_metadata_keys = []\n\n    geodf = img_collection_to_feature_collection(img_col,\n                                                 [\"system:time_start\"] + list(keys_query.keys()) + extra_metadata_keys,\n                                                as_geopandas=True, band_crs=\"B2\")\n\n\n    geodf.rename(keys_query, axis=1, inplace=True)\n\n    # Filter tirs only image (title starts with LT08)\n    if geodf.shape[0] &gt; 0:\n        tile_starts_with_lt08 = geodf[\"title\"].str.startswith(\"LT08\")\n        if tile_starts_with_lt08.any():\n            warnings.warn(f\"Found {tile_starts_with_lt08.sum()} images of Landsat-8 TIRS only. Removing them.\")\n            geodf = geodf[~tile_starts_with_lt08].copy()\n        if (producttype == \"Landsat\") or (producttype == \"both\") or (producttype == \"L8\") or (producttype == \"L9\"):\n            geodf[\"collection_name\"] = geodf[\"title\"].apply(figure_out_collection_landsat)\n        else:\n            geodf[\"collection_name\"] = image_collection_name\n\n    img_col = img_col.map(lambda x: _rename_add_properties(x, keys_query))\n\n    if producttype == \"both\":\n        img_col_s2 = ee.ImageCollection(\"COPERNICUS/S2_HARMONIZED\").filterDate(date_start.replace(tzinfo=None),\n                                                                              date_end.replace(\n                                                                                  tzinfo=None)).filterBounds(\n            pol)\n        keys_query_s2 = {\"PRODUCT_ID\": \"title\", 'CLOUDY_PIXEL_PERCENTAGE': \"cloudcoverpercentage\"}\n        geodf_s2 = img_collection_to_feature_collection(img_col_s2,\n                                                        [\"system:time_start\"] + list(keys_query_s2.keys()) + extra_metadata_keys,\n                                                        as_geopandas=True, band_crs=\"B2\")\n        geodf_s2[\"collection_name\"] = \"COPERNICUS/S2_HARMONIZED\"\n        geodf_s2.rename(keys_query_s2, axis=1, inplace=True)\n        if geodf_s2.shape[0] &gt; 0:\n            if geodf.shape[0] == 0:\n                geodf = geodf_s2\n            else:\n                geodf = pd.concat([geodf_s2, geodf], ignore_index=True)\n\n            img_col_s2 = img_col_s2.map(lambda x: _rename_add_properties(x, keys_query_s2))\n            img_col = img_col.merge(img_col_s2)\n\n    if geodf.shape[0] == 0:\n        warnings.warn(f\"Not images found of collection {producttype} between dates {date_start} and {date_end}\")\n        if return_collection:\n            return geodf, img_col\n        return geodf\n\n    if add_s2cloudless and producttype in [\"both\", \"S2\"]:\n        values_s2_idx = geodf.title.apply(lambda x: x.startswith(\"S2\"))\n        indexes_s2 = geodf.gee_id[values_s2_idx].tolist()\n        img_col_cloudprob = ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\").filterDate(date_start.replace(tzinfo=None),\n                                                                              date_end.replace(\n                                                                                  tzinfo=None)).filterBounds(\n            pol)\n        img_col_cloudprob = img_col_cloudprob.filter(ee.Filter.inList(\"system:index\", ee.List(indexes_s2)))\n        geodf_cloudprob = img_collection_to_feature_collection(img_col_cloudprob,\n                                                               [\"system:time_start\"],\n                                                               as_geopandas=True)\n        geodf[\"s2cloudless\"] = False\n        list_geeid = geodf_cloudprob.gee_id.tolist()\n        geodf.loc[values_s2_idx, \"s2cloudless\"] = geodf.loc[values_s2_idx, \"gee_id\"].apply(lambda x: x in list_geeid)\n\n\n    geodf = _add_stuff(geodf, area, tz)\n\n    # Fix ids of Landsat to remove initial shit in the names\n    # projects/earthengine-public/assets/LANDSAT/LC09/C02/T1_TOA/1_2_LO09_037031_20220315\n    if geodf.satellite.str.startswith(\"LC0\").any():\n        geodf.loc[geodf.satellite.str.startswith(\"LC0\"),\"gee_id\"] = geodf.loc[geodf.satellite.str.startswith(\"LC0\"),\"gee_id\"].apply(lambda x: \"LC0\"+x.split(\"LC0\")[1])\n\n    # Fix ids of Landsat to remove initial shit in the names also if satellite starts with LO0\n    if geodf.satellite.str.startswith(\"LO0\").any():\n        geodf.loc[geodf.satellite.str.startswith(\"LO0\"),\"gee_id\"] = geodf.loc[geodf.satellite.str.startswith(\"LO0\"),\"gee_id\"].apply(lambda x: \"LO0\"+x.split(\"LO0\")[1])\n\n\n    if filter_duplicates:\n        # TODO filter prioritizing s2cloudless?\n        geodf = query_utils.filter_products_overlap(area, geodf,\n                                                    groupkey=[\"solarday\", \"satellite\"]).copy()\n        # filter img_col:\n        img_col = img_col.filter(ee.Filter.inList(\"title\", ee.List(geodf.index.tolist())))\n\n    geodf.sort_values(\"utcdatetime\")\n    img_col = img_col.sort(\"system:time_start\")\n\n    if return_collection:\n        return geodf, img_col\n\n    return geodf\n</code></pre>"},{"location":"modules/ee_image/#georeader.readers.ee_query.query_s1","title":"<code>query_s1(area, date_start, date_end, filter_duplicates=True, return_collection=False)</code>","text":"<p>Query S1 products from the Google Earth Engine</p> <p>Parameters:</p> Name Type Description Default <code>area</code> <code>Union[MultiPolygon, Polygon]</code> required <code>date_start</code> <code>datetime</code> required <code>date_end</code> <code>datetime</code> required <code>filter_duplicates</code> <code>bool</code> <code>True</code> <code>return_collection</code> <code>bool</code> <code>False</code> <p>Returns:</p> Source code in <code>georeader/readers/ee_query.py</code> <pre><code>def query_s1(area:Union[MultiPolygon,Polygon],\n             date_start:datetime, date_end:datetime,\n             filter_duplicates:bool=True,\n             return_collection:bool=False)-&gt; Union[gpd.GeoDataFrame, Tuple[gpd.GeoDataFrame, ee.ImageCollection]]:\n    \"\"\"\n    Query S1 products from the Google Earth Engine\n\n    Args:\n        area:\n        date_start:\n        date_end:\n        filter_duplicates:\n        return_collection:\n\n    Returns:\n\n    \"\"\"\n    pol = ee.Geometry(mapping(area))\n\n    if date_start.tzinfo is not None:\n        tz = date_start.tzinfo\n        if isinstance(tz, ZoneInfo):\n            tz = tz.key\n\n        date_start = date_start.astimezone(timezone.utc)\n        date_end = date_end.astimezone(timezone.utc)\n    else:\n        tz = timezone.utc\n\n    assert date_end &gt;= date_start, f\"Date end: {date_end} prior to date start: {date_start}\"\n\n    img_col = ee.ImageCollection('COPERNICUS/S1_GRD').\\\n       filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).\\\n       filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).\\\n       filter(ee.Filter.eq('instrumentMode', 'IW')).\\\n       filterDate(date_start.replace(tzinfo=None),\n                  date_end.replace(tzinfo=None)).\\\n       filterBounds(pol)\n\n    keys_query = {\"orbitProperties_pass\": \"orbitProperties_pass\"}\n\n    geodf = img_collection_to_feature_collection(img_col,\n                                                 [\"system:time_start\"] + list(keys_query.keys()),\n                                                 as_geopandas=True, band_crs=\"VV\")\n    geodf.rename(keys_query, axis=1, inplace=True)\n    geodf[\"title\"] = geodf[\"gee_id\"]\n    geodf[\"collection_name\"] = \"COPERNICUS/S1_GRD\"\n    geodf = _add_stuff(geodf, area, tz)\n\n    if filter_duplicates:\n        geodf = query_utils.filter_products_overlap(area, geodf,\n                                                    groupkey=[\"solarday\", \"satellite\",\"orbitProperties_pass\"]).copy()\n        # filter img_col:\n        img_col = img_col.filter(ee.Filter.inList(\"system:index\", ee.List(geodf.index.tolist())))\n\n    geodf.sort_values(\"utcdatetime\")\n    img_col = img_col.sort(\"system:time_start\")\n\n    if return_collection:\n        return geodf, img_col\n\n    return geodf\n</code></pre>"},{"location":"modules/ee_image/#georeader.readers.ee_query.query_landsat_457","title":"<code>query_landsat_457(area, date_start, date_end, producttype='all', filter_duplicates=True, return_collection=False, extra_metadata_keys=None)</code>","text":"<p>Query Landsat-7, Landsat-5 or Landsat-4 products from the Google Earth Engine.</p> <p>Parameters:</p> Name Type Description Default <code>area</code> <code>Union[MultiPolygon, Polygon]</code> <p>area to query images in EPSG:4326</p> required <code>date_start</code> <code>datetime</code> <p>datetime in a given timezone. If tz not provided UTC will be assumed.</p> required <code>date_end</code> <code>datetime</code> <p>datetime in UTC. If tz not provided UTC will be assumed.</p> required <code>producttype</code> <code>str</code> <p>'all' -&gt; {\"L4\", \"L5\", \"L7\"}, \"L4\", \"L5\" or \"L7\". Defaults to \"all\".</p> <code>'all'</code> <code>filter_duplicates</code> <code>bool</code> <p>filter duplicate images over the same area. Defaults to True.</p> <code>True</code> <code>return_collection</code> <code>bool</code> <p>returns also the corresponding image collection. Defaults to False.</p> <code>False</code> <code>extra_metadata_keys</code> <code>Optional[List[str]]</code> <p>extra metadata keys to add to the geodataframe. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[GeoDataFrame, Tuple[GeoDataFrame, ImageCollection]]</code> <p>Union[gpd.GeoDataFrame, Tuple[gpd.GeoDataFrame, ee.ImageCollection]]: geodataframe with available products in the given area and time range</p> Source code in <code>georeader/readers/ee_query.py</code> <pre><code>def query_landsat_457(area:Union[MultiPolygon,Polygon],\n                      date_start:datetime, date_end:datetime,\n                      producttype:str=\"all\",\n                      filter_duplicates:bool=True,\n                      return_collection:bool=False,\n                      extra_metadata_keys:Optional[List[str]]=None\n          )-&gt; Union[gpd.GeoDataFrame, Tuple[gpd.GeoDataFrame, ee.ImageCollection]]:\n    \"\"\"\n    Query Landsat-7, Landsat-5 or Landsat-4 products from the Google Earth Engine.\n\n    Args:\n        area (Union[MultiPolygon,Polygon]): area to query images in EPSG:4326\n        date_start (datetime): datetime in a given timezone. If tz not provided UTC will be assumed.\n        date_end (datetime): datetime in UTC. If tz not provided UTC will be assumed.\n        producttype (str, optional): 'all' -&gt; {\"L4\", \"L5\", \"L7\"}, \"L4\", \"L5\" or \"L7\". Defaults to \"all\".\n        filter_duplicates (bool, optional): filter duplicate images over the same area. Defaults to True.\n        return_collection (bool, optional): returns also the corresponding image collection. Defaults to False.\n        extra_metadata_keys (Optional[List[str]], optional): extra metadata keys to add to the geodataframe. Defaults to None.\n\n    Returns:\n        Union[gpd.GeoDataFrame, Tuple[gpd.GeoDataFrame, ee.ImageCollection]]: geodataframe with available products in the given area and time range\n    \"\"\"\n\n    pol = ee.Geometry(mapping(area))\n\n    if date_start.tzinfo is not None:\n        tz = date_start.tzinfo\n        if isinstance(tz, ZoneInfo):\n            tz = tz.key\n\n        date_start = date_start.astimezone(timezone.utc)\n        date_end = date_end.astimezone(timezone.utc)\n    else:\n        tz = timezone.utc\n\n    assert date_end &gt;= date_start, f\"Date end: {date_end} prior to date start: {date_start}\"\n\n    if extra_metadata_keys is None:\n        extra_metadata_keys = []\n\n    if producttype == \"all\" or producttype == \"L5\":\n        image_collection_name = \"LANDSAT/LT05/C02/T1_TOA\"\n    elif producttype == \"L4\":\n        image_collection_name = \"LANDSAT/LT04/C02/T1_TOA\"\n    elif producttype == \"L7\":\n        image_collection_name = \"LANDSAT/LE07/C02/T1_TOA\"\n    else:\n        raise NotImplementedError(f\"Unknown product type {producttype}\")\n\n    keys_query = {\"LANDSAT_PRODUCT_ID\": \"title\", 'CLOUD_COVER': \"cloudcoverpercentage\"}\n    img_col = ee.ImageCollection(image_collection_name).filterDate(date_start.replace(tzinfo=None),\n                                                                   date_end.replace(tzinfo=None)).filterBounds(\n        pol)\n    # Merge T2 collection\n    img_col_t2 = ee.ImageCollection(image_collection_name.replace(\"T1\", \"T2\")).filterDate(date_start.replace(tzinfo=None),\n                                                                   date_end.replace(tzinfo=None)).filterBounds(\n        pol)\n    img_col = img_col.merge(img_col_t2)\n\n    if producttype == \"all\":\n        img_col_l4 = ee.ImageCollection(\"LANDSAT/LT04/C02/T1_TOA\").filterDate(date_start.replace(tzinfo=None),\n                                                                   date_end.replace(tzinfo=None)).filterBounds(\n        pol)\n        img_col_l4_t2 = ee.ImageCollection(\"LANDSAT/LT04/C02/T2_TOA\").filterDate(date_start.replace(tzinfo=None),\n                                                                     date_end.replace(tzinfo=None)).filterBounds(\n            pol)\n        img_col_l4 = img_col_l4.merge(img_col_l4_t2)\n        img_col = img_col.merge(img_col_l4)\n\n        # Add L7 T1 and T2\n        img_col_l7 = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_TOA\").filterDate(date_start.replace(tzinfo=None),\n                                                                   date_end.replace(tzinfo=None)).filterBounds(\n        pol)\n        img_col_l7_t2 = ee.ImageCollection(\"LANDSAT/LE07/C02/T2_TOA\").filterDate(date_start.replace(tzinfo=None),\n                                                                        date_end.replace(tzinfo=None)).filterBounds(\n                pol)\n        img_col_l7 = img_col_l7.merge(img_col_l7_t2)\n        img_col = img_col.merge(img_col_l7)\n\n    geodf = img_collection_to_feature_collection(img_col,\n                                                 [\"system:time_start\"] + list(keys_query.keys()) + extra_metadata_keys,\n                                                as_geopandas=True, band_crs=\"B2\")\n\n    geodf.rename(keys_query, axis=1, inplace=True)\n\n    if geodf.shape[0] == 0:\n        warnings.warn(f\"Not images found of collection {producttype} between dates {date_start} and {date_end}\")\n        if return_collection:\n            return geodf, img_col\n        return geodf\n\n    img_col = img_col.map(lambda x: _rename_add_properties(x, keys_query))\n    geodf[\"collection_name\"] = geodf.title.apply(lambda x: figure_out_collection_landsat(x))\n\n    geodf = _add_stuff(geodf, area, tz)\n\n    # Fix ids of Landsat to remove initial shit in the names\n    geodf[\"gee_id\"] = geodf[\"gee_id\"].apply(lambda x: \"L\"+x.split(\"L\")[1])\n\n    if filter_duplicates:\n        geodf = query_utils.filter_products_overlap(area, geodf,\n                                                    groupkey=[\"solarday\", \"satellite\"]).copy()\n        # filter img_col:\n        img_col = img_col.filter(ee.Filter.inList(\"title\", ee.List(geodf.index.tolist())))\n\n    geodf.sort_values(\"utcdatetime\")\n    img_col = img_col.sort(\"system:time_start\")\n\n    if return_collection:\n        return geodf, img_col\n\n    return geodf\n</code></pre>"},{"location":"modules/geotensor_module/","title":"GeoTensor","text":""},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor","title":"<code>GeoTensor</code>","text":"<p>This class is a wrapper around a numpy or torch tensor with geospatial information. It can store 2D, 3D or 4D tensors. The last two dimensions are the spatial dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Tensor</code> <p>numpy or torch tensor (2D, 3D or 4D).</p> required <code>transform</code> <code>Affine</code> <p>affine geospatial transform</p> required <code>crs</code> <code>Any</code> <p>coordinate reference system</p> required <code>fill_value_default</code> <code>Optional[Union[int, float]]</code> <p>Value to fill when  reading out of bounds. Could be None. Defaults to 0.</p> <code>0</code> <p>Attributes:</p> Name Type Description <code>values</code> <code>Tensor</code> <p>numpy or torch tensor</p> <code>transform</code> <code>Affine</code> <p>affine geospatial transform</p> <code>crs</code> <code>Any</code> <p>coordinate reference system</p> <code>fill_value_default</code> <code>Optional[Union[int, float]]</code> <p>Value to fill when  reading out of bounds. Could be None. Defaults to 0.</p> <code>shape</code> <code>Tuple</code> <p>shape of the tensor</p> <code>res</code> <code>Tuple[float, float]</code> <p>resolution of the tensor</p> <code>dtype</code> <p>data type of the tensor</p> <code>height</code> <code>int</code> <p>height of the tensor</p> <code>width</code> <code>int</code> <p>width of the tensor</p> <code>count</code> <code>int</code> <p>number of bands in the tensor</p> <code>bounds</code> <code>Tuple[float, float, float, float]</code> <p>bounds of the tensor</p> <code>dims</code> <code>Tuple[str]</code> <p>names of the dimensions</p> <code>attrs</code> <code>Dict[str, Any]</code> <p>dictionary with the attributes of the GeoTensor</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; transform = rasterio.Affine(1, 0, 0, 0, -1, 0)\n&gt;&gt;&gt; crs = \"EPSG:4326\"\n&gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n</code></pre> Source code in <code>georeader/geotensor.py</code> <pre><code>class GeoTensor:\n    \"\"\"\n        This class is a wrapper around a numpy or torch tensor with geospatial information.\n        It can store 2D, 3D or 4D tensors. The last two dimensions are the spatial dimensions.\n\n        Args:\n            values (Tensor): numpy or torch tensor (2D, 3D or 4D).\n            transform (rasterio.Affine): affine geospatial transform\n            crs (Any): coordinate reference system\n            fill_value_default (Optional[Union[int, float]], optional): Value to fill when \n                reading out of bounds. Could be None. Defaults to 0.\n\n        Attributes:\n            values (Tensor): numpy or torch tensor\n            transform (rasterio.Affine): affine geospatial transform\n            crs (Any): coordinate reference system\n            fill_value_default (Optional[Union[int, float]], optional): Value to fill when \n                reading out of bounds. Could be None. Defaults to 0.\n            shape (Tuple): shape of the tensor\n            res (Tuple[float, float]): resolution of the tensor\n            dtype: data type of the tensor\n            height (int): height of the tensor\n            width (int): width of the tensor\n            count (int): number of bands in the tensor\n            bounds (Tuple[float, float, float, float]): bounds of the tensor\n            dims (Tuple[str]): names of the dimensions\n            attrs (Dict[str, Any]): dictionary with the attributes of the GeoTensor\n\n        Examples:\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; transform = rasterio.Affine(1, 0, 0, 0, -1, 0)\n            &gt;&gt;&gt; crs = \"EPSG:4326\"\n            &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n\n    \"\"\"\n\n    def __init__(self, values:Tensor,\n                 transform:rasterio.Affine, crs:Any,\n                 fill_value_default:Optional[Union[int, float]]=0):\n        \"\"\"\n        This class is a wrapper around a numpy or torch tensor with geospatial information.\n\n        Args:\n            values (Tensor): numpy or torch tensor\n            transform (rasterio.Affine): affine geospatial transform\n            crs (Any): coordinate reference system\n            fill_value_default (Optional[Union[int, float]], optional): Value to fill when \n                reading out of bounds. Could be None. Defaults to 0.\n\n        Raises:\n            ValueError: when the shape of the tensor is not 2d, 3d or 4d.\n        \"\"\"\n        self.values = values\n        self.transform = transform\n        self.crs = crs\n        self.fill_value_default = fill_value_default\n        shape = self.shape\n        if (len(shape) &lt; 2) or (len(shape) &gt; 4):\n            raise ValueError(f\"Expected 2d-4d array found {shape}\")\n\n    @property\n    def dims(self) -&gt; Tuple[str]:\n        # TODO allow different ordering of dimensions?\n        shape = self.shape\n        if len(shape) == 2:\n            dims = (\"y\", \"x\")\n        elif len(shape) == 3:\n            dims = (\"band\", \"y\", \"x\")\n        elif len(shape) == 4:\n            dims = (\"time\", \"band\", \"y\", \"x\")\n        else:\n            raise ValueError(f\"Unexpected 2d-4d array found {shape}\")\n\n        return dims\n\n    def to_json(self) -&gt; Dict[str, Any]:\n        return {\n            \"values\": self.values.tolist(),\n            \"transform\": [self.transform.a,self.transform.b,self.transform.c, \n                          self.transform.d, self.transform.e, self.transform.f] ,\n            \"crs\": str(self.crs),\n            \"fill_value_default\": self.fill_value_default\n        }\n\n    @classmethod\n    def from_json(cls, json:Dict[str, Any]) -&gt; '__class__':\n        return cls(np.array(json[\"values\"]), \n                   rasterio.Affine(*json[\"transform\"]),\n                   json[\"crs\"], \n                   json[\"fill_value_default\"])\n\n    @property\n    def shape(self) -&gt; Tuple:\n        return tuple(self.values.shape)\n\n    @property\n    def res(self) -&gt; Tuple[float, float]:\n        return window_utils.res(self.transform)\n\n    @property\n    def dtype(self):\n        return self.values.dtype\n\n    @property\n    def height(self) -&gt; int:\n        return self.shape[-2]\n\n    @property\n    def width(self) -&gt; int:\n        return self.shape[-1]\n\n    @property\n    def count(self) -&gt; int:\n        return self.shape[-3]\n\n    @property\n    def bounds(self) -&gt; Tuple[float, float, float, float]:\n        return window_bounds(rasterio.windows.Window(row_off=0, col_off=0, height=self.height, width=self.width),\n                             self.transform)\n\n    def set_dtype(self, dtype):\n        # TODO implement for torch tensor\n        self.values = self.values.astype(dtype=dtype)\n\n    def astype(self, dtype) -&gt; '__class__':\n        return GeoTensor(self.values.astype(dtype), \n                         self.transform, self.crs, self.fill_value_default)\n\n    @property\n    def attrs(self) -&gt; Dict[str, Any]:\n        return vars(self)\n\n    def meshgrid(self, dst_crs:Optional[Any]=None) -&gt; Tuple[NDArray, NDArray]:\n        from georeader import griddata\n        return griddata.meshgrid(self.transform, self.width, self.height, source_crs=self.crs, dst_crs=dst_crs)\n\n    def load(self) -&gt; '__class__':\n        return self\n\n    def __copy__(self) -&gt; '__class__':\n        return GeoTensor(self.values.copy(), self.transform, self.crs, self.fill_value_default)\n\n    def copy(self) -&gt; '__class__':\n        return self.__copy__()\n\n    def same_extent(self, other:'__class__', precision:float=1e-3) -&gt; bool:\n        \"\"\"\n        Check if two GeoTensors have the same georeferencing (crs and transform)\n\n        Args:\n            other (__class__ | GeoData): GeoTensor to compare with. Other GeoData object can be passed (it requires crs, transform and shape attributes)\n            precision (float, optional): precision to compare the transform. Defaults to 1e-3.\n\n        Returns:\n            bool: True if both GeoTensors have the same georeferencing.\n        \"\"\"\n        return self.transform.almost_equals(other.transform, precision=precision) and window_utils.compare_crs(self.crs, other.crs) and (self.shape[-2:] == other.shape[-2:])\n\n    def __add__(self, other:Union[numbers.Number,'__class__']) -&gt; '__class__':\n        \"\"\" \n        Add two GeoTensors. The georeferencing must match.\n\n        Args:\n            other (GeoTensor): GeoTensor to add.\n\n        Raises:\n            ValueError: if the georeferencing does not match.\n            TypeError: if other is not a GeoTensor.\n\n        Returns:\n            GeoTensor: GeoTensor with the result of the addition.\n        \"\"\"\n        if isinstance(other, GeoTensor):\n            if self.same_extent(other):\n                other =  other.values\n            else:\n                raise ValueError(\"GeoTensor georref must match for addition. \"\n                                 \"Use `read.read_reproject_like(other, self)` to \"\n                                 \"to reproject `other` to `self` georreferencing.\")\n\n        result_values = self.values + other\n\n        return GeoTensor(result_values, transform=self.transform, crs=self.crs,\n                         fill_value_default=self.fill_value_default)\n\n    def __sub__(self, other:Union[numbers.Number,'__class__']) -&gt; '__class__':\n        \"\"\"\n        Substract two GeoTensors. The georeferencing must match.\n\n        Args:\n            other (GeoTensor): GeoTensor to add.\n\n        Raises:\n            ValueError: if the georeferencing does not match.\n            TypeError: if other is not a GeoTensor.\n\n        Returns:\n            GeoTensor: GeoTensor with the result of the substraction.\n\n        \"\"\"\n        if isinstance(other, GeoTensor):\n            if self.same_extent(other):\n                other =  other.values\n            else:\n                raise ValueError(\"GeoTensor georref must match for substraction. \"\n                                 \"Use `read.read_reproject_like(other, self)` to \"\n                                 \"to reproject `other` to `self` georreferencing.\")\n\n        result_values = self.values - other\n\n        return GeoTensor(result_values, transform=self.transform, crs=self.crs,\n                         fill_value_default=self.fill_value_default)\n\n    def __mul__(self, other:Union[numbers.Number,'__class__']) -&gt; '__class__':\n        \"\"\"\n        Multiply two GeoTensors. The georeferencing must match.\n\n        Args:\n            other (GeoTensor): GeoTensor to add.\n\n        Raises:\n            ValueError: if the georeferencing does not match.\n            TypeError: if other is not a GeoTensor.\n\n        Returns:\n            GeoTensor: GeoTensor with the result of the multiplication.\n        \"\"\"\n        if isinstance(other, GeoTensor):\n            if self.same_extent(other):\n                other =  other.values\n            else:\n                raise ValueError(\"GeoTensor georref must match for multiplication. \"\n                                 \"Use `read.read_reproject_like(other, self)` to \"\n                                 \"to reproject `other` to `self` georreferencing.\")\n\n        result_values = self.values * other\n\n        return GeoTensor(result_values, transform=self.transform, crs=self.crs,\n                         fill_value_default=self.fill_value_default)\n\n    def __truediv__(self, other:Union[ArrayLike,'__class__']) -&gt; '__class__':\n        \"\"\"\n        Divide two GeoTensors. The georeferencing must match.\n\n        Args:\n            other (GeoTensor): GeoTensor to add.\n\n        Raises:\n            ValueError: if the georeferencing does not match.\n            TypeError: if other is not a GeoTensor.\n\n        Returns:\n            GeoTensor: GeoTensor with the result of the division.\n        \"\"\"\n        if isinstance(other, GeoTensor):\n            if self.same_extent(other):\n                other =  other.values\n            else:\n                raise ValueError(\"GeoTensor georref must match for division. \"\n                                 \"Use `read.read_reproject_like(other, self)` to \"\n                                 \"to reproject `other` to `self` georreferencing.\")\n\n        result_values = self.values / other\n\n        return GeoTensor(result_values, transform=self.transform, crs=self.crs,\n                         fill_value_default=self.fill_value_default)\n\n    def __setitem__(self, index: np.ndarray, value: Union[np.ndarray, numbers.Number]) -&gt; None:\n        \"\"\"\n        Set the values of the GeoTensor object using an index and a new value.\n\n        Args:\n            index (tuple or numpy.ndarray): Index or boolean mask to apply to the GeoTensor values.\n            value (numpy.ndarray): New value to assign to the GeoTensor values at the specified index.\n\n        Raises:\n            ValueError: If the index is not a tuple or a boolean numpy array with the same shape as the GeoTensor values.\n\n        Examples:\n            &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n            &gt;&gt;&gt; boolmask = gt.values &gt; 0.5\n            &gt;&gt;&gt; gt[boolmask] = 0.5\n        \"\"\"\n        if isinstance(index, np.ndarray) and (index.dtype == bool) and (index.shape == self.values.shape):\n            # If the index is a boolean numpy array with the same shape as the values,\n            # use it to mask the values and assign the new values to the masked values\n            self.values[index] = value\n        else:\n            raise ValueError(f\"Unsupported index type {type(index)} {index.dtype} {index} for GeoTensor set operation.\")\n\n    def squeeze(self) -&gt; '__class__':\n        \"\"\"\n        Remove single-dimensional entries from the shape of the GeoTensor values.\n        It does not squeeze the spatial dimensions (last two dimensions).\n\n        Returns:\n            GeoTensor: GeoTensor with the squeezed values.\n        \"\"\"\n\n        # squeeze all but last two dimensions\n        squeezed_values = np.squeeze(self.values, axis=tuple(range(self.values.ndim - 2)))\n\n        return GeoTensor(squeezed_values, transform=self.transform, crs=self.crs,\n                         fill_value_default=self.fill_value_default)\n\n    def clip(self, a_min:Optional[np.array], a_max:Optional[np.array]) -&gt; '__class__':\n        \"\"\"\n        Clip the GeoTensor values between the GeoTensor min and max values.\n\n        Args:\n            a_min (float): Minimum value.\n            a_max (float): Maximum value.\n\n        Returns:\n            GeoTensor: GeoTensor with the clipped values.\n        \"\"\"\n        clipped_values = np.clip(self.values, a_min, a_max)\n        return GeoTensor(clipped_values, transform=self.transform, crs=self.crs,\n                         fill_value_default=self.fill_value_default)\n\n\n    def isel(self, sel: Dict[str, Union[slice, list, int]]) -&gt; '__class__':\n        \"\"\"\n        Slicing with dict. It doesn't work with negative indexes!\n\n        Args:\n            sel: Dict with slice selection; i.e. `{\"x\": slice(10, 20), \"y\": slice(20, 340)}`.\n\n        Returns:\n            GeoTensor: GeoTensor with the sliced values.\n\n        Examples:\n            &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n            &gt;&gt;&gt; gt.isel({\"x\": slice(10, 20), \"y\": slice(20, 340)})\n        \"\"\"\n        for k in sel:\n            if k not in self.dims:\n                raise NotImplementedError(f\"Axis {k} not in {self.dims}\")\n\n        slice_list = self._slice_tuple(sel)\n\n        slices_window = []\n        for k in [\"y\", \"x\"]:\n            if k in sel:\n                if not isinstance(sel[k], slice):\n                    raise NotImplementedError(f\"Only slice selection supported for x, y dims, found {sel[k]}\")\n                slices_window.append(sel[k])\n            else:\n                size = self.width if (k == \"x\") else self.height\n                slices_window.append(slice(0, size))\n\n        window_current = rasterio.windows.Window.from_slices(*slices_window, boundless=False, height=self.height,\n                                                             width=self.width)\n\n        transform_current = rasterio.windows.transform(window_current, transform=self.transform)\n\n        return GeoTensor(self.values[slice_list], transform_current, self.crs,\n                         self.fill_value_default)\n\n    def _slice_tuple(self, sel: Dict[str, Union[slice, list, int]]) -&gt; tuple:\n        slice_list = []\n        # shape_ = self.shape\n        # sel_copy = sel.copy()\n        for _i, k in enumerate(self.dims):\n            if k in sel:\n                if not isinstance(sel[k], slice) and not isinstance(sel[k], list) and not isinstance(sel[k], int):\n                    raise NotImplementedError(f\"Only slice selection supported for x, y dims, found {sel[k]}\")\n                # sel_copy[k] = slice(max(0, sel_copy[k].start), min(shape_[_i], sel_copy[k].stop))\n                slice_list.append(sel[k])\n            else:\n                slice_list.append(slice(None))\n        return tuple(slice_list)\n\n    def footprint(self, crs:Optional[str]=None) -&gt; Polygon:\n        \"\"\"Returns the footprint of the GeoTensor as a Polygon.\n\n        Args:\n            crs (Optional[str], optional): Coordinate reference system. Defaults to None.\n\n        Returns:\n            Polygon: footprint of the GeoTensor.\n\n        Examples:\n            &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n            &gt;&gt;&gt; gt.footprint(crs=\"EPSG:4326\") # returns a Polygon in WGS84\n        \"\"\"\n        pol = window_utils.window_polygon(rasterio.windows.Window(row_off=0, col_off=0, height=self.shape[-2], width=self.shape[-1]),\n                                          self.transform)\n        if (crs is None) or window_utils.compare_crs(self.crs, crs):\n            return pol\n\n        return window_utils.polygon_to_crs(pol, self.crs, crs)\n\n    def valid_footprint(self, crs:Optional[str]=None, method:str=\"all\") -&gt; Union[MultiPolygon, Polygon]:\n        \"\"\"\n        vectorizes the valid values of the GeoTensor and returns the footprint as a Polygon.\n\n        Args:\n            crs (Optional[str], optional): Coordinate reference system. Defaults to None.\n            method (str, optional): \"all\" or \"any\" to aggregate the channels of the image. Defaults to \"all\".\n\n        Returns:\n            Polygon or MultiPolygon: footprint of the GeoTensor.\n        \"\"\"\n        valid_values = self.values != self.fill_value_default\n        if len(valid_values.shape) &gt; 2:\n            if method == \"all\":\n                valid_values = np.all(valid_values, \n                                      axis=tuple(np.arange(0, len(valid_values.shape)-2).tolist()))\n            elif method == \"any\":\n                valid_values = np.any(valid_values, \n                                      axis=tuple(np.arange(0, len(valid_values.shape)-2).tolist()))\n            else:\n                raise NotImplementedError(f\"Method {method} to aggregate channels not implemented\")\n\n        from georeader import vectorize\n        polygons = vectorize.get_polygons(valid_values, transform=self.transform)\n        if len(polygons) == 0:\n            raise ValueError(\"GeoTensor has no valid values\")\n        elif len(polygons) == 1:\n            pol = polygons[0]\n        else:\n            pol = MultiPolygon(polygons)\n        if crs is None:\n            return pol\n\n        return window_utils.polygon_to_crs(pol, self.crs, crs)\n\n    def __repr__(self)-&gt;str:\n        return f\"\"\" \n         Transform: {self.transform}\n         Shape: {self.shape}\n         Resolution: {self.res}\n         Bounds: {self.bounds}\n         CRS: {self.crs}\n         fill_value_default: {self.fill_value_default}\n        \"\"\"\n\n    def pad(self, pad_width:Dict[str, Tuple[int, int]], mode:str=\"constant\",\n            constant_values:Optional[Any]=None)-&gt; '__class__':\n        \"\"\"\n        Pad the GeoTensor.\n\n        Args:\n            pad_width (_type_, optional):  dictionary with Tuple to pad for each dimension \n                `{\"x\": (pad_x_0, pad_x_1), \"y\": (pad_y_0, pad_y_1)}`. \n            mode (str, optional): pad mode (see np.pad or torch.nn.functional.pad). Defaults to \"constant\".\n            constant_values (Any, optional): _description_. Defaults to `self.fill_value_default`.\n\n        Returns:\n            GeoTensor: padded GeoTensor.\n\n        Examples:\n            &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n            &gt;&gt;&gt; gt.pad({\"x\": (10, 10), \"y\": (10, 10)})\n            &gt;&gt;&gt; assert gt.shape == (3, 120, 120)\n        \"\"\"\n        if constant_values is None and mode == \"constant\":\n            constant_values = self.fill_value_default\n\n        # Pad the data\n        pad_torch = False\n        if torch_installed:\n            if isinstance(self.values, torch.Tensor):\n                pad_torch = True\n\n        if pad_torch:\n            pad_list_torch = []\n            for k in reversed(self.dims):\n                if k in pad_width:\n                    pad_list_torch.extend(list(pad_width[k]))\n                else:\n                    pad_list_torch.extend([0,0])\n\n            kwargs_extra = {}\n            if mode == \"constant\":\n                kwargs_extra[\"value\"] = constant_values\n            values_new = torch.nn.functional.pad(self.values, tuple(pad_list_torch), mode=mode, **kwargs_extra)\n        else:\n            pad_list_np = []\n            for k in self.dims:\n                if k in pad_width:\n                    pad_list_np.append(pad_width[k])\n                else:\n                    pad_list_np.append((0,0))\n\n            kwargs_extra = {}\n            if mode == \"constant\":\n                kwargs_extra[\"constant_values\"] = constant_values\n            values_new = np.pad(self.values, tuple(pad_list_np), mode=mode, **kwargs_extra)\n\n        # Compute the new transform\n        slices_window = []\n        for k in [\"y\", \"x\"]:\n            size = self.width if (k == \"x\") else self.height\n            if k in pad_width:\n                slices_window.append(slice(-pad_width[k][0], size+pad_width[k][1]))\n            else:\n                slices_window.append(slice(0, size))\n\n        window_current = rasterio.windows.Window.from_slices(*slices_window, boundless=True)\n        transform_current = rasterio.windows.transform(window_current, transform=self.transform)\n        return GeoTensor(values_new, transform_current, self.crs,\n                         self.fill_value_default)\n\n    def resize(self, output_shape:Optional[Tuple[int,int]]=None,\n               resolution_dst:Optional[Tuple[float,float]]=None,\n               anti_aliasing:bool=True, anti_aliasing_sigma:Optional[Union[float,np.ndarray]]=None,\n               interpolation:Optional[str]=\"bilinear\",\n               mode_pad:str=\"constant\")-&gt; '__class__':\n        \"\"\"\n        Resize the geotensor to match a certain size output_shape. This function works with GeoTensors of 2D, 3D and 4D.\n        The geoinformation of the output tensor is changed accordingly.\n\n        Args:\n            output_shape: output spatial shape if None resolution_dst must be provided. If not provided, \n                the output shape is computed from the resolution_dst rounding to the closest integer.\n            resolution_dst: output resolution if None output_shape must be provided.\n            anti_aliasing: Whether to apply a Gaussian filter to smooth the image prior to downsampling\n            anti_aliasing_sigma:  anti_aliasing_sigma : {float}, optional\n                Standard deviation for Gaussian filtering used when anti-aliasing.\n                By default, this value is chosen as (s - 1) / 2 where s is the\n                downsampling factor, where s &gt; 1\n            interpolation: Algorithm used for resizing: 'nearest' | 'bilinear' | 'bicubic'\n            mode_pad: mode pad for resize function\n\n        Returns:\n             resized GeoTensor\n\n        Examples:\n            &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n            &gt;&gt;&gt; resized = gt.resize((50, 50))\n            &gt;&gt;&gt; assert resized.shape == (3, 50, 50)\n            &gt;&gt;&gt; assert resized.res == (2*gt.res[0], 2*gt.res[1])\n        \"\"\"\n        input_shape = self.shape\n        spatial_shape = input_shape[-2:]\n        resolution_or = self.res\n\n        if output_shape is None:\n            assert resolution_dst is not None, f\"Can't have output_shape and resolution_dst as None\"\n            output_shape = int(round(spatial_shape[0] * resolution_or[0] / resolution_dst[0])), \\\n                            int(round(spatial_shape[1] * resolution_or[1] / resolution_dst[1]))\n        else:\n            assert resolution_dst is None, f\"Both output_shape and resolution_dst can't be provided\"\n            assert len(output_shape) == 2, f\"Expected output shape to be the spatial dimensions found: {output_shape}\"\n            resolution_dst =  spatial_shape[0] * resolution_or[0] / output_shape[0], \\\n                          spatial_shape[1] * resolution_or[1] / output_shape[1]\n\n        # Compute output transform\n        transform_scale = rasterio.Affine.scale(resolution_dst[0]/resolution_or[0], resolution_dst[1]/resolution_or[1])\n        transform = self.transform * transform_scale\n\n        resize_kornia = False\n        if torch_installed:\n            if isinstance(self.values, torch.Tensor):\n                resize_kornia = True\n\n        if resize_kornia:\n            # TODO\n            # https://kornia.readthedocs.io/en/latest/geometry.transform.html#kornia.geometry.transform.resize\n            raise NotImplementedError(f\"Not implemented for torch Tensors\")\n        else:\n            from skimage.transform import resize\n            # https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.resize\n            output_tensor = np.ndarray(input_shape[:-2]+output_shape, dtype=self.dtype)\n            if len(input_shape) == 4:\n                for i,j in product(range(0,input_shape[0]), range(0, input_shape[1])):\n                    if (not anti_aliasing) or (anti_aliasing_sigma is None) or isinstance(anti_aliasing_sigma, numbers.Number):\n                        anti_aliasing_sigma_iter = anti_aliasing_sigma\n                    else:\n                        anti_aliasing_sigma_iter = anti_aliasing_sigma[i, j]\n                    output_tensor[i,j] = resize(self.values[i,j], output_shape, order=ORDERS[interpolation],\n                                                anti_aliasing=anti_aliasing, preserve_range=False,\n                                                cval=self.fill_value_default,mode=mode_pad,\n                                                anti_aliasing_sigma=anti_aliasing_sigma_iter)\n            elif len(input_shape) == 3:\n                for i in range(0,input_shape[0]):\n                    if (not anti_aliasing) or (anti_aliasing_sigma is None) or isinstance(anti_aliasing_sigma, numbers.Number):\n                        anti_aliasing_sigma_iter = anti_aliasing_sigma\n                    else:\n                        anti_aliasing_sigma_iter = anti_aliasing_sigma[i]\n                    output_tensor[i] = resize(self.values[i], output_shape, order=ORDERS[interpolation],\n                                              anti_aliasing=anti_aliasing, preserve_range=False,\n                                              cval=self.fill_value_default,mode=mode_pad,\n                                              anti_aliasing_sigma=anti_aliasing_sigma_iter)\n            else:\n                output_tensor[...] = resize(self.values, output_shape, order=ORDERS[interpolation],\n                                            anti_aliasing=anti_aliasing, preserve_range=False,\n                                            cval=self.fill_value_default,mode=mode_pad,\n                                            anti_aliasing_sigma=anti_aliasing_sigma)\n\n        return GeoTensor(output_tensor, transform=transform, crs=self.crs,\n                         fill_value_default=self.fill_value_default)\n\n    def write_from_window(self, data:Tensor, window:rasterio.windows.Window):\n        \"\"\"\n        Writes array to GeoTensor values object at the given window position. If window surpasses the bounds of this\n        object it crops the data to fit the object.\n\n        Args:\n            data: Tensor to write. Expected: spatial dimensions `window.width`, `window.height`. Rest: same as `self`\n            window: Window object that specifies the spatial location to write the data\n\n        Examples:\n            &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n            &gt;&gt;&gt; data = np.random.rand(3, 50, 50)\n            &gt;&gt;&gt; window = rasterio.windows.Window(col_off=7, row_off=9, width=50, height=50)\n            &gt;&gt;&gt; gt.write_from_window(data, window)\n\n        \"\"\"\n        window_data = rasterio.windows.Window(col_off=0, row_off=0,\n                                              width=self.width, height=self.height)\n        if not rasterio.windows.intersect(window, window_data):\n            return\n\n        assert data.shape[-2:] == (window.width, window.height), f\"window {window} has different shape than data {data.shape}\"\n        assert data.shape[:-2] == self.shape[:-2], f\"Dimension of data in non-spatial channels found {data.shape} expected: {self.shape}\"\n\n        slice_dict, pad_width = window_utils.get_slice_pad(window_data, window)\n        slice_list = self._slice_tuple(slice_dict)\n        # need_pad = any(p != 0 for p in pad_width[\"x\"] + pad_width[\"y\"])\n\n        slice_data_spatial_x = slice(pad_width[\"x\"][0], None if pad_width[\"x\"][1] == 0 else -pad_width[\"x\"][1])\n        slice_data_spatial_y = slice(pad_width[\"y\"][0], None if pad_width[\"y\"][1] == 0 else -pad_width[\"y\"][1])\n        slice_data = self._slice_tuple({\"x\": slice_data_spatial_x, \"y\" : slice_data_spatial_y})\n        self.values[slice_list] = data[slice_data]\n\n    def read_from_window(self, window:rasterio.windows.Window, boundless:bool=True) -&gt; '__class__':\n        \"\"\"\n        returns a new GeoTensor object with the spatial dimensions sliced\n\n        Args:\n            window: window to slice the current GeoTensor\n            boundless: read from window in boundless mode (i.e. if the window is larger or negative it will pad\n                the GeoTensor with `self.fill_value_default`)\n\n        Raises:\n            rasterio.windows.WindowError: if `window` does not intersect the data\n\n        Returns:\n            GeoTensor object with the spatial dimensions sliced\n\n        \"\"\"\n\n        window_data = rasterio.windows.Window(col_off=0, row_off=0,\n                                              width=self.width, height=self.height)\n        if boundless:\n            slice_dict, pad_width = window_utils.get_slice_pad(window_data, window)\n            need_pad = any(p != 0 for p in pad_width[\"x\"] + pad_width[\"y\"])\n            X_sliced = self.isel(slice_dict)\n            if need_pad:\n                X_sliced = X_sliced.pad(pad_width=pad_width, mode=\"constant\",\n                                        constant_values=self.fill_value_default)\n            return X_sliced\n        else:\n            window_read = rasterio.windows.intersection(window, window_data)\n            slice_y, slice_x = window_read.toslices()\n            slice_dict = {\"x\": slice_x, \"y\": slice_y}\n            slices_ = self._slice_tuple(slice_dict)\n            transform_current = rasterio.windows.transform(window_read, transform=self.transform)\n            return GeoTensor(self.values[slices_], transform_current, self.crs,\n                             self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.__add__","title":"<code>__add__(other)</code>","text":"<p>Add two GeoTensors. The georeferencing must match.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>GeoTensor</code> <p>GeoTensor to add.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the georeferencing does not match.</p> <code>TypeError</code> <p>if other is not a GeoTensor.</p> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>__class__</code> <p>GeoTensor with the result of the addition.</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def __add__(self, other:Union[numbers.Number,'__class__']) -&gt; '__class__':\n    \"\"\" \n    Add two GeoTensors. The georeferencing must match.\n\n    Args:\n        other (GeoTensor): GeoTensor to add.\n\n    Raises:\n        ValueError: if the georeferencing does not match.\n        TypeError: if other is not a GeoTensor.\n\n    Returns:\n        GeoTensor: GeoTensor with the result of the addition.\n    \"\"\"\n    if isinstance(other, GeoTensor):\n        if self.same_extent(other):\n            other =  other.values\n        else:\n            raise ValueError(\"GeoTensor georref must match for addition. \"\n                             \"Use `read.read_reproject_like(other, self)` to \"\n                             \"to reproject `other` to `self` georreferencing.\")\n\n    result_values = self.values + other\n\n    return GeoTensor(result_values, transform=self.transform, crs=self.crs,\n                     fill_value_default=self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.__init__","title":"<code>__init__(values, transform, crs, fill_value_default=0)</code>","text":"<p>This class is a wrapper around a numpy or torch tensor with geospatial information.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Tensor</code> <p>numpy or torch tensor</p> required <code>transform</code> <code>Affine</code> <p>affine geospatial transform</p> required <code>crs</code> <code>Any</code> <p>coordinate reference system</p> required <code>fill_value_default</code> <code>Optional[Union[int, float]]</code> <p>Value to fill when  reading out of bounds. Could be None. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>when the shape of the tensor is not 2d, 3d or 4d.</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def __init__(self, values:Tensor,\n             transform:rasterio.Affine, crs:Any,\n             fill_value_default:Optional[Union[int, float]]=0):\n    \"\"\"\n    This class is a wrapper around a numpy or torch tensor with geospatial information.\n\n    Args:\n        values (Tensor): numpy or torch tensor\n        transform (rasterio.Affine): affine geospatial transform\n        crs (Any): coordinate reference system\n        fill_value_default (Optional[Union[int, float]], optional): Value to fill when \n            reading out of bounds. Could be None. Defaults to 0.\n\n    Raises:\n        ValueError: when the shape of the tensor is not 2d, 3d or 4d.\n    \"\"\"\n    self.values = values\n    self.transform = transform\n    self.crs = crs\n    self.fill_value_default = fill_value_default\n    shape = self.shape\n    if (len(shape) &lt; 2) or (len(shape) &gt; 4):\n        raise ValueError(f\"Expected 2d-4d array found {shape}\")\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiply two GeoTensors. The georeferencing must match.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>GeoTensor</code> <p>GeoTensor to add.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the georeferencing does not match.</p> <code>TypeError</code> <p>if other is not a GeoTensor.</p> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>__class__</code> <p>GeoTensor with the result of the multiplication.</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def __mul__(self, other:Union[numbers.Number,'__class__']) -&gt; '__class__':\n    \"\"\"\n    Multiply two GeoTensors. The georeferencing must match.\n\n    Args:\n        other (GeoTensor): GeoTensor to add.\n\n    Raises:\n        ValueError: if the georeferencing does not match.\n        TypeError: if other is not a GeoTensor.\n\n    Returns:\n        GeoTensor: GeoTensor with the result of the multiplication.\n    \"\"\"\n    if isinstance(other, GeoTensor):\n        if self.same_extent(other):\n            other =  other.values\n        else:\n            raise ValueError(\"GeoTensor georref must match for multiplication. \"\n                             \"Use `read.read_reproject_like(other, self)` to \"\n                             \"to reproject `other` to `self` georreferencing.\")\n\n    result_values = self.values * other\n\n    return GeoTensor(result_values, transform=self.transform, crs=self.crs,\n                     fill_value_default=self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.__setitem__","title":"<code>__setitem__(index, value)</code>","text":"<p>Set the values of the GeoTensor object using an index and a new value.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>tuple or ndarray</code> <p>Index or boolean mask to apply to the GeoTensor values.</p> required <code>value</code> <code>ndarray</code> <p>New value to assign to the GeoTensor values at the specified index.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the index is not a tuple or a boolean numpy array with the same shape as the GeoTensor values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; boolmask = gt.values &gt; 0.5\n&gt;&gt;&gt; gt[boolmask] = 0.5\n</code></pre> Source code in <code>georeader/geotensor.py</code> <pre><code>def __setitem__(self, index: np.ndarray, value: Union[np.ndarray, numbers.Number]) -&gt; None:\n    \"\"\"\n    Set the values of the GeoTensor object using an index and a new value.\n\n    Args:\n        index (tuple or numpy.ndarray): Index or boolean mask to apply to the GeoTensor values.\n        value (numpy.ndarray): New value to assign to the GeoTensor values at the specified index.\n\n    Raises:\n        ValueError: If the index is not a tuple or a boolean numpy array with the same shape as the GeoTensor values.\n\n    Examples:\n        &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; boolmask = gt.values &gt; 0.5\n        &gt;&gt;&gt; gt[boolmask] = 0.5\n    \"\"\"\n    if isinstance(index, np.ndarray) and (index.dtype == bool) and (index.shape == self.values.shape):\n        # If the index is a boolean numpy array with the same shape as the values,\n        # use it to mask the values and assign the new values to the masked values\n        self.values[index] = value\n    else:\n        raise ValueError(f\"Unsupported index type {type(index)} {index.dtype} {index} for GeoTensor set operation.\")\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.__sub__","title":"<code>__sub__(other)</code>","text":"<p>Substract two GeoTensors. The georeferencing must match.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>GeoTensor</code> <p>GeoTensor to add.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the georeferencing does not match.</p> <code>TypeError</code> <p>if other is not a GeoTensor.</p> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>__class__</code> <p>GeoTensor with the result of the substraction.</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def __sub__(self, other:Union[numbers.Number,'__class__']) -&gt; '__class__':\n    \"\"\"\n    Substract two GeoTensors. The georeferencing must match.\n\n    Args:\n        other (GeoTensor): GeoTensor to add.\n\n    Raises:\n        ValueError: if the georeferencing does not match.\n        TypeError: if other is not a GeoTensor.\n\n    Returns:\n        GeoTensor: GeoTensor with the result of the substraction.\n\n    \"\"\"\n    if isinstance(other, GeoTensor):\n        if self.same_extent(other):\n            other =  other.values\n        else:\n            raise ValueError(\"GeoTensor georref must match for substraction. \"\n                             \"Use `read.read_reproject_like(other, self)` to \"\n                             \"to reproject `other` to `self` georreferencing.\")\n\n    result_values = self.values - other\n\n    return GeoTensor(result_values, transform=self.transform, crs=self.crs,\n                     fill_value_default=self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.__truediv__","title":"<code>__truediv__(other)</code>","text":"<p>Divide two GeoTensors. The georeferencing must match.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>GeoTensor</code> <p>GeoTensor to add.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the georeferencing does not match.</p> <code>TypeError</code> <p>if other is not a GeoTensor.</p> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>__class__</code> <p>GeoTensor with the result of the division.</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def __truediv__(self, other:Union[ArrayLike,'__class__']) -&gt; '__class__':\n    \"\"\"\n    Divide two GeoTensors. The georeferencing must match.\n\n    Args:\n        other (GeoTensor): GeoTensor to add.\n\n    Raises:\n        ValueError: if the georeferencing does not match.\n        TypeError: if other is not a GeoTensor.\n\n    Returns:\n        GeoTensor: GeoTensor with the result of the division.\n    \"\"\"\n    if isinstance(other, GeoTensor):\n        if self.same_extent(other):\n            other =  other.values\n        else:\n            raise ValueError(\"GeoTensor georref must match for division. \"\n                             \"Use `read.read_reproject_like(other, self)` to \"\n                             \"to reproject `other` to `self` georreferencing.\")\n\n    result_values = self.values / other\n\n    return GeoTensor(result_values, transform=self.transform, crs=self.crs,\n                     fill_value_default=self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.clip","title":"<code>clip(a_min, a_max)</code>","text":"<p>Clip the GeoTensor values between the GeoTensor min and max values.</p> <p>Parameters:</p> Name Type Description Default <code>a_min</code> <code>float</code> <p>Minimum value.</p> required <code>a_max</code> <code>float</code> <p>Maximum value.</p> required <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>__class__</code> <p>GeoTensor with the clipped values.</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def clip(self, a_min:Optional[np.array], a_max:Optional[np.array]) -&gt; '__class__':\n    \"\"\"\n    Clip the GeoTensor values between the GeoTensor min and max values.\n\n    Args:\n        a_min (float): Minimum value.\n        a_max (float): Maximum value.\n\n    Returns:\n        GeoTensor: GeoTensor with the clipped values.\n    \"\"\"\n    clipped_values = np.clip(self.values, a_min, a_max)\n    return GeoTensor(clipped_values, transform=self.transform, crs=self.crs,\n                     fill_value_default=self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.footprint","title":"<code>footprint(crs=None)</code>","text":"<p>Returns the footprint of the GeoTensor as a Polygon.</p> <p>Parameters:</p> Name Type Description Default <code>crs</code> <code>Optional[str]</code> <p>Coordinate reference system. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>footprint of the GeoTensor.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; gt.footprint(crs=\"EPSG:4326\") # returns a Polygon in WGS84\n</code></pre> Source code in <code>georeader/geotensor.py</code> <pre><code>def footprint(self, crs:Optional[str]=None) -&gt; Polygon:\n    \"\"\"Returns the footprint of the GeoTensor as a Polygon.\n\n    Args:\n        crs (Optional[str], optional): Coordinate reference system. Defaults to None.\n\n    Returns:\n        Polygon: footprint of the GeoTensor.\n\n    Examples:\n        &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; gt.footprint(crs=\"EPSG:4326\") # returns a Polygon in WGS84\n    \"\"\"\n    pol = window_utils.window_polygon(rasterio.windows.Window(row_off=0, col_off=0, height=self.shape[-2], width=self.shape[-1]),\n                                      self.transform)\n    if (crs is None) or window_utils.compare_crs(self.crs, crs):\n        return pol\n\n    return window_utils.polygon_to_crs(pol, self.crs, crs)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.isel","title":"<code>isel(sel)</code>","text":"<p>Slicing with dict. It doesn't work with negative indexes!</p> <p>Parameters:</p> Name Type Description Default <code>sel</code> <code>Dict[str, Union[slice, list, int]]</code> <p>Dict with slice selection; i.e. <code>{\"x\": slice(10, 20), \"y\": slice(20, 340)}</code>.</p> required <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>__class__</code> <p>GeoTensor with the sliced values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; gt.isel({\"x\": slice(10, 20), \"y\": slice(20, 340)})\n</code></pre> Source code in <code>georeader/geotensor.py</code> <pre><code>def isel(self, sel: Dict[str, Union[slice, list, int]]) -&gt; '__class__':\n    \"\"\"\n    Slicing with dict. It doesn't work with negative indexes!\n\n    Args:\n        sel: Dict with slice selection; i.e. `{\"x\": slice(10, 20), \"y\": slice(20, 340)}`.\n\n    Returns:\n        GeoTensor: GeoTensor with the sliced values.\n\n    Examples:\n        &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; gt.isel({\"x\": slice(10, 20), \"y\": slice(20, 340)})\n    \"\"\"\n    for k in sel:\n        if k not in self.dims:\n            raise NotImplementedError(f\"Axis {k} not in {self.dims}\")\n\n    slice_list = self._slice_tuple(sel)\n\n    slices_window = []\n    for k in [\"y\", \"x\"]:\n        if k in sel:\n            if not isinstance(sel[k], slice):\n                raise NotImplementedError(f\"Only slice selection supported for x, y dims, found {sel[k]}\")\n            slices_window.append(sel[k])\n        else:\n            size = self.width if (k == \"x\") else self.height\n            slices_window.append(slice(0, size))\n\n    window_current = rasterio.windows.Window.from_slices(*slices_window, boundless=False, height=self.height,\n                                                         width=self.width)\n\n    transform_current = rasterio.windows.transform(window_current, transform=self.transform)\n\n    return GeoTensor(self.values[slice_list], transform_current, self.crs,\n                     self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.pad","title":"<code>pad(pad_width, mode='constant', constant_values=None)</code>","text":"<p>Pad the GeoTensor.</p> <p>Parameters:</p> Name Type Description Default <code>pad_width</code> <code>_type_</code> <p>dictionary with Tuple to pad for each dimension  <code>{\"x\": (pad_x_0, pad_x_1), \"y\": (pad_y_0, pad_y_1)}</code>. </p> required <code>mode</code> <code>str</code> <p>pad mode (see np.pad or torch.nn.functional.pad). Defaults to \"constant\".</p> <code>'constant'</code> <code>constant_values</code> <code>Any</code> <p>description. Defaults to <code>self.fill_value_default</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>__class__</code> <p>padded GeoTensor.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; gt.pad({\"x\": (10, 10), \"y\": (10, 10)})\n&gt;&gt;&gt; assert gt.shape == (3, 120, 120)\n</code></pre> Source code in <code>georeader/geotensor.py</code> <pre><code>def pad(self, pad_width:Dict[str, Tuple[int, int]], mode:str=\"constant\",\n        constant_values:Optional[Any]=None)-&gt; '__class__':\n    \"\"\"\n    Pad the GeoTensor.\n\n    Args:\n        pad_width (_type_, optional):  dictionary with Tuple to pad for each dimension \n            `{\"x\": (pad_x_0, pad_x_1), \"y\": (pad_y_0, pad_y_1)}`. \n        mode (str, optional): pad mode (see np.pad or torch.nn.functional.pad). Defaults to \"constant\".\n        constant_values (Any, optional): _description_. Defaults to `self.fill_value_default`.\n\n    Returns:\n        GeoTensor: padded GeoTensor.\n\n    Examples:\n        &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; gt.pad({\"x\": (10, 10), \"y\": (10, 10)})\n        &gt;&gt;&gt; assert gt.shape == (3, 120, 120)\n    \"\"\"\n    if constant_values is None and mode == \"constant\":\n        constant_values = self.fill_value_default\n\n    # Pad the data\n    pad_torch = False\n    if torch_installed:\n        if isinstance(self.values, torch.Tensor):\n            pad_torch = True\n\n    if pad_torch:\n        pad_list_torch = []\n        for k in reversed(self.dims):\n            if k in pad_width:\n                pad_list_torch.extend(list(pad_width[k]))\n            else:\n                pad_list_torch.extend([0,0])\n\n        kwargs_extra = {}\n        if mode == \"constant\":\n            kwargs_extra[\"value\"] = constant_values\n        values_new = torch.nn.functional.pad(self.values, tuple(pad_list_torch), mode=mode, **kwargs_extra)\n    else:\n        pad_list_np = []\n        for k in self.dims:\n            if k in pad_width:\n                pad_list_np.append(pad_width[k])\n            else:\n                pad_list_np.append((0,0))\n\n        kwargs_extra = {}\n        if mode == \"constant\":\n            kwargs_extra[\"constant_values\"] = constant_values\n        values_new = np.pad(self.values, tuple(pad_list_np), mode=mode, **kwargs_extra)\n\n    # Compute the new transform\n    slices_window = []\n    for k in [\"y\", \"x\"]:\n        size = self.width if (k == \"x\") else self.height\n        if k in pad_width:\n            slices_window.append(slice(-pad_width[k][0], size+pad_width[k][1]))\n        else:\n            slices_window.append(slice(0, size))\n\n    window_current = rasterio.windows.Window.from_slices(*slices_window, boundless=True)\n    transform_current = rasterio.windows.transform(window_current, transform=self.transform)\n    return GeoTensor(values_new, transform_current, self.crs,\n                     self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.read_from_window","title":"<code>read_from_window(window, boundless=True)</code>","text":"<p>returns a new GeoTensor object with the spatial dimensions sliced</p> <p>Parameters:</p> Name Type Description Default <code>window</code> <code>Window</code> <p>window to slice the current GeoTensor</p> required <code>boundless</code> <code>bool</code> <p>read from window in boundless mode (i.e. if the window is larger or negative it will pad the GeoTensor with <code>self.fill_value_default</code>)</p> <code>True</code> <p>Raises:</p> Type Description <code>WindowError</code> <p>if <code>window</code> does not intersect the data</p> <p>Returns:</p> Type Description <code>__class__</code> <p>GeoTensor object with the spatial dimensions sliced</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def read_from_window(self, window:rasterio.windows.Window, boundless:bool=True) -&gt; '__class__':\n    \"\"\"\n    returns a new GeoTensor object with the spatial dimensions sliced\n\n    Args:\n        window: window to slice the current GeoTensor\n        boundless: read from window in boundless mode (i.e. if the window is larger or negative it will pad\n            the GeoTensor with `self.fill_value_default`)\n\n    Raises:\n        rasterio.windows.WindowError: if `window` does not intersect the data\n\n    Returns:\n        GeoTensor object with the spatial dimensions sliced\n\n    \"\"\"\n\n    window_data = rasterio.windows.Window(col_off=0, row_off=0,\n                                          width=self.width, height=self.height)\n    if boundless:\n        slice_dict, pad_width = window_utils.get_slice_pad(window_data, window)\n        need_pad = any(p != 0 for p in pad_width[\"x\"] + pad_width[\"y\"])\n        X_sliced = self.isel(slice_dict)\n        if need_pad:\n            X_sliced = X_sliced.pad(pad_width=pad_width, mode=\"constant\",\n                                    constant_values=self.fill_value_default)\n        return X_sliced\n    else:\n        window_read = rasterio.windows.intersection(window, window_data)\n        slice_y, slice_x = window_read.toslices()\n        slice_dict = {\"x\": slice_x, \"y\": slice_y}\n        slices_ = self._slice_tuple(slice_dict)\n        transform_current = rasterio.windows.transform(window_read, transform=self.transform)\n        return GeoTensor(self.values[slices_], transform_current, self.crs,\n                         self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.resize","title":"<code>resize(output_shape=None, resolution_dst=None, anti_aliasing=True, anti_aliasing_sigma=None, interpolation='bilinear', mode_pad='constant')</code>","text":"<p>Resize the geotensor to match a certain size output_shape. This function works with GeoTensors of 2D, 3D and 4D. The geoinformation of the output tensor is changed accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>output_shape</code> <code>Optional[Tuple[int, int]]</code> <p>output spatial shape if None resolution_dst must be provided. If not provided,  the output shape is computed from the resolution_dst rounding to the closest integer.</p> <code>None</code> <code>resolution_dst</code> <code>Optional[Tuple[float, float]]</code> <p>output resolution if None output_shape must be provided.</p> <code>None</code> <code>anti_aliasing</code> <code>bool</code> <p>Whether to apply a Gaussian filter to smooth the image prior to downsampling</p> <code>True</code> <code>anti_aliasing_sigma</code> <code>Optional[Union[float, ndarray]]</code> <p>anti_aliasing_sigma : {float}, optional Standard deviation for Gaussian filtering used when anti-aliasing. By default, this value is chosen as (s - 1) / 2 where s is the downsampling factor, where s &gt; 1</p> <code>None</code> <code>interpolation</code> <code>Optional[str]</code> <p>Algorithm used for resizing: 'nearest' | 'bilinear' | 'bicubic'</p> <code>'bilinear'</code> <code>mode_pad</code> <code>str</code> <p>mode pad for resize function</p> <code>'constant'</code> <p>Returns:</p> Type Description <code>__class__</code> <p>resized GeoTensor</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; resized = gt.resize((50, 50))\n&gt;&gt;&gt; assert resized.shape == (3, 50, 50)\n&gt;&gt;&gt; assert resized.res == (2*gt.res[0], 2*gt.res[1])\n</code></pre> Source code in <code>georeader/geotensor.py</code> <pre><code>def resize(self, output_shape:Optional[Tuple[int,int]]=None,\n           resolution_dst:Optional[Tuple[float,float]]=None,\n           anti_aliasing:bool=True, anti_aliasing_sigma:Optional[Union[float,np.ndarray]]=None,\n           interpolation:Optional[str]=\"bilinear\",\n           mode_pad:str=\"constant\")-&gt; '__class__':\n    \"\"\"\n    Resize the geotensor to match a certain size output_shape. This function works with GeoTensors of 2D, 3D and 4D.\n    The geoinformation of the output tensor is changed accordingly.\n\n    Args:\n        output_shape: output spatial shape if None resolution_dst must be provided. If not provided, \n            the output shape is computed from the resolution_dst rounding to the closest integer.\n        resolution_dst: output resolution if None output_shape must be provided.\n        anti_aliasing: Whether to apply a Gaussian filter to smooth the image prior to downsampling\n        anti_aliasing_sigma:  anti_aliasing_sigma : {float}, optional\n            Standard deviation for Gaussian filtering used when anti-aliasing.\n            By default, this value is chosen as (s - 1) / 2 where s is the\n            downsampling factor, where s &gt; 1\n        interpolation: Algorithm used for resizing: 'nearest' | 'bilinear' | 'bicubic'\n        mode_pad: mode pad for resize function\n\n    Returns:\n         resized GeoTensor\n\n    Examples:\n        &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; resized = gt.resize((50, 50))\n        &gt;&gt;&gt; assert resized.shape == (3, 50, 50)\n        &gt;&gt;&gt; assert resized.res == (2*gt.res[0], 2*gt.res[1])\n    \"\"\"\n    input_shape = self.shape\n    spatial_shape = input_shape[-2:]\n    resolution_or = self.res\n\n    if output_shape is None:\n        assert resolution_dst is not None, f\"Can't have output_shape and resolution_dst as None\"\n        output_shape = int(round(spatial_shape[0] * resolution_or[0] / resolution_dst[0])), \\\n                        int(round(spatial_shape[1] * resolution_or[1] / resolution_dst[1]))\n    else:\n        assert resolution_dst is None, f\"Both output_shape and resolution_dst can't be provided\"\n        assert len(output_shape) == 2, f\"Expected output shape to be the spatial dimensions found: {output_shape}\"\n        resolution_dst =  spatial_shape[0] * resolution_or[0] / output_shape[0], \\\n                      spatial_shape[1] * resolution_or[1] / output_shape[1]\n\n    # Compute output transform\n    transform_scale = rasterio.Affine.scale(resolution_dst[0]/resolution_or[0], resolution_dst[1]/resolution_or[1])\n    transform = self.transform * transform_scale\n\n    resize_kornia = False\n    if torch_installed:\n        if isinstance(self.values, torch.Tensor):\n            resize_kornia = True\n\n    if resize_kornia:\n        # TODO\n        # https://kornia.readthedocs.io/en/latest/geometry.transform.html#kornia.geometry.transform.resize\n        raise NotImplementedError(f\"Not implemented for torch Tensors\")\n    else:\n        from skimage.transform import resize\n        # https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.resize\n        output_tensor = np.ndarray(input_shape[:-2]+output_shape, dtype=self.dtype)\n        if len(input_shape) == 4:\n            for i,j in product(range(0,input_shape[0]), range(0, input_shape[1])):\n                if (not anti_aliasing) or (anti_aliasing_sigma is None) or isinstance(anti_aliasing_sigma, numbers.Number):\n                    anti_aliasing_sigma_iter = anti_aliasing_sigma\n                else:\n                    anti_aliasing_sigma_iter = anti_aliasing_sigma[i, j]\n                output_tensor[i,j] = resize(self.values[i,j], output_shape, order=ORDERS[interpolation],\n                                            anti_aliasing=anti_aliasing, preserve_range=False,\n                                            cval=self.fill_value_default,mode=mode_pad,\n                                            anti_aliasing_sigma=anti_aliasing_sigma_iter)\n        elif len(input_shape) == 3:\n            for i in range(0,input_shape[0]):\n                if (not anti_aliasing) or (anti_aliasing_sigma is None) or isinstance(anti_aliasing_sigma, numbers.Number):\n                    anti_aliasing_sigma_iter = anti_aliasing_sigma\n                else:\n                    anti_aliasing_sigma_iter = anti_aliasing_sigma[i]\n                output_tensor[i] = resize(self.values[i], output_shape, order=ORDERS[interpolation],\n                                          anti_aliasing=anti_aliasing, preserve_range=False,\n                                          cval=self.fill_value_default,mode=mode_pad,\n                                          anti_aliasing_sigma=anti_aliasing_sigma_iter)\n        else:\n            output_tensor[...] = resize(self.values, output_shape, order=ORDERS[interpolation],\n                                        anti_aliasing=anti_aliasing, preserve_range=False,\n                                        cval=self.fill_value_default,mode=mode_pad,\n                                        anti_aliasing_sigma=anti_aliasing_sigma)\n\n    return GeoTensor(output_tensor, transform=transform, crs=self.crs,\n                     fill_value_default=self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.same_extent","title":"<code>same_extent(other, precision=0.001)</code>","text":"<p>Check if two GeoTensors have the same georeferencing (crs and transform)</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>__class__ | GeoData</code> <p>GeoTensor to compare with. Other GeoData object can be passed (it requires crs, transform and shape attributes)</p> required <code>precision</code> <code>float</code> <p>precision to compare the transform. Defaults to 1e-3.</p> <code>0.001</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if both GeoTensors have the same georeferencing.</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def same_extent(self, other:'__class__', precision:float=1e-3) -&gt; bool:\n    \"\"\"\n    Check if two GeoTensors have the same georeferencing (crs and transform)\n\n    Args:\n        other (__class__ | GeoData): GeoTensor to compare with. Other GeoData object can be passed (it requires crs, transform and shape attributes)\n        precision (float, optional): precision to compare the transform. Defaults to 1e-3.\n\n    Returns:\n        bool: True if both GeoTensors have the same georeferencing.\n    \"\"\"\n    return self.transform.almost_equals(other.transform, precision=precision) and window_utils.compare_crs(self.crs, other.crs) and (self.shape[-2:] == other.shape[-2:])\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.squeeze","title":"<code>squeeze()</code>","text":"<p>Remove single-dimensional entries from the shape of the GeoTensor values. It does not squeeze the spatial dimensions (last two dimensions).</p> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>__class__</code> <p>GeoTensor with the squeezed values.</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def squeeze(self) -&gt; '__class__':\n    \"\"\"\n    Remove single-dimensional entries from the shape of the GeoTensor values.\n    It does not squeeze the spatial dimensions (last two dimensions).\n\n    Returns:\n        GeoTensor: GeoTensor with the squeezed values.\n    \"\"\"\n\n    # squeeze all but last two dimensions\n    squeezed_values = np.squeeze(self.values, axis=tuple(range(self.values.ndim - 2)))\n\n    return GeoTensor(squeezed_values, transform=self.transform, crs=self.crs,\n                     fill_value_default=self.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.valid_footprint","title":"<code>valid_footprint(crs=None, method='all')</code>","text":"<p>vectorizes the valid values of the GeoTensor and returns the footprint as a Polygon.</p> <p>Parameters:</p> Name Type Description Default <code>crs</code> <code>Optional[str]</code> <p>Coordinate reference system. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>\"all\" or \"any\" to aggregate the channels of the image. Defaults to \"all\".</p> <code>'all'</code> <p>Returns:</p> Type Description <code>Union[MultiPolygon, Polygon]</code> <p>Polygon or MultiPolygon: footprint of the GeoTensor.</p> Source code in <code>georeader/geotensor.py</code> <pre><code>def valid_footprint(self, crs:Optional[str]=None, method:str=\"all\") -&gt; Union[MultiPolygon, Polygon]:\n    \"\"\"\n    vectorizes the valid values of the GeoTensor and returns the footprint as a Polygon.\n\n    Args:\n        crs (Optional[str], optional): Coordinate reference system. Defaults to None.\n        method (str, optional): \"all\" or \"any\" to aggregate the channels of the image. Defaults to \"all\".\n\n    Returns:\n        Polygon or MultiPolygon: footprint of the GeoTensor.\n    \"\"\"\n    valid_values = self.values != self.fill_value_default\n    if len(valid_values.shape) &gt; 2:\n        if method == \"all\":\n            valid_values = np.all(valid_values, \n                                  axis=tuple(np.arange(0, len(valid_values.shape)-2).tolist()))\n        elif method == \"any\":\n            valid_values = np.any(valid_values, \n                                  axis=tuple(np.arange(0, len(valid_values.shape)-2).tolist()))\n        else:\n            raise NotImplementedError(f\"Method {method} to aggregate channels not implemented\")\n\n    from georeader import vectorize\n    polygons = vectorize.get_polygons(valid_values, transform=self.transform)\n    if len(polygons) == 0:\n        raise ValueError(\"GeoTensor has no valid values\")\n    elif len(polygons) == 1:\n        pol = polygons[0]\n    else:\n        pol = MultiPolygon(polygons)\n    if crs is None:\n        return pol\n\n    return window_utils.polygon_to_crs(pol, self.crs, crs)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.GeoTensor.write_from_window","title":"<code>write_from_window(data, window)</code>","text":"<p>Writes array to GeoTensor values object at the given window position. If window surpasses the bounds of this object it crops the data to fit the object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Tensor</code> <p>Tensor to write. Expected: spatial dimensions <code>window.width</code>, <code>window.height</code>. Rest: same as <code>self</code></p> required <code>window</code> <code>Window</code> <p>Window object that specifies the spatial location to write the data</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; data = np.random.rand(3, 50, 50)\n&gt;&gt;&gt; window = rasterio.windows.Window(col_off=7, row_off=9, width=50, height=50)\n&gt;&gt;&gt; gt.write_from_window(data, window)\n</code></pre> Source code in <code>georeader/geotensor.py</code> <pre><code>def write_from_window(self, data:Tensor, window:rasterio.windows.Window):\n    \"\"\"\n    Writes array to GeoTensor values object at the given window position. If window surpasses the bounds of this\n    object it crops the data to fit the object.\n\n    Args:\n        data: Tensor to write. Expected: spatial dimensions `window.width`, `window.height`. Rest: same as `self`\n        window: Window object that specifies the spatial location to write the data\n\n    Examples:\n        &gt;&gt;&gt; gt = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; data = np.random.rand(3, 50, 50)\n        &gt;&gt;&gt; window = rasterio.windows.Window(col_off=7, row_off=9, width=50, height=50)\n        &gt;&gt;&gt; gt.write_from_window(data, window)\n\n    \"\"\"\n    window_data = rasterio.windows.Window(col_off=0, row_off=0,\n                                          width=self.width, height=self.height)\n    if not rasterio.windows.intersect(window, window_data):\n        return\n\n    assert data.shape[-2:] == (window.width, window.height), f\"window {window} has different shape than data {data.shape}\"\n    assert data.shape[:-2] == self.shape[:-2], f\"Dimension of data in non-spatial channels found {data.shape} expected: {self.shape}\"\n\n    slice_dict, pad_width = window_utils.get_slice_pad(window_data, window)\n    slice_list = self._slice_tuple(slice_dict)\n    # need_pad = any(p != 0 for p in pad_width[\"x\"] + pad_width[\"y\"])\n\n    slice_data_spatial_x = slice(pad_width[\"x\"][0], None if pad_width[\"x\"][1] == 0 else -pad_width[\"x\"][1])\n    slice_data_spatial_y = slice(pad_width[\"y\"][0], None if pad_width[\"y\"][1] == 0 else -pad_width[\"y\"][1])\n    slice_data = self._slice_tuple({\"x\": slice_data_spatial_x, \"y\" : slice_data_spatial_y})\n    self.values[slice_list] = data[slice_data]\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.concatenate","title":"<code>concatenate(geotensors, axis=0)</code>","text":"<p>Concatenates a list of geotensors along a given axis, assert that all of them has same shape, transform and crs.</p> <p>Parameters:</p> Name Type Description Default <code>geotensors</code> <code>List[GeoTensor]</code> <p>list of geotensors to concat. All with same shape, transform and crs.</p> required <code>axis</code> <code>int</code> <p>axis to concatenate. Must be less than the number of dimensions of the geotensors minus 2. default is 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>GeoTensor</code> <p>geotensor with extra dim at the front: (len(geotensors),) + shape</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gt1 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; gt2 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; gt3 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; gt = concatenate([gt1, gt2, gt3], axis=0)\n&gt;&gt;&gt; assert gt.shape == (9, 100, 100)\n</code></pre> Source code in <code>georeader/geotensor.py</code> <pre><code>def concatenate(geotensors:List[GeoTensor], axis:int=0) -&gt; GeoTensor:\n    \"\"\"\n    Concatenates a list of geotensors along a given axis, assert that all of them has same shape, transform and crs.\n\n    Args:\n        geotensors: list of geotensors to concat. All with same shape, transform and crs.\n        axis: axis to concatenate. Must be less than the number of dimensions of the geotensors minus 2.\n            default is 0.\n\n    Returns:\n        geotensor with extra dim at the front: (len(geotensors),) + shape\n\n    Examples:\n        &gt;&gt;&gt; gt1 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; gt2 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; gt3 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; gt = concatenate([gt1, gt2, gt3], axis=0)\n        &gt;&gt;&gt; assert gt.shape == (9, 100, 100)\n    \"\"\"\n    assert len(geotensors) &gt; 0, \"Empty list provided can't concat\"\n\n    if len(geotensors) == 1:\n        return geotensors[0].copy()\n\n    first_geotensor = geotensors[0]\n\n    # Assert the axis is NOT an spatial axis\n    assert axis &lt; len(first_geotensor.shape) - 2, f\"Can't concatenate along spatial axis\"\n\n    array_out = np.concatenate([gt.values for gt in geotensors], axis=axis)\n\n    return GeoTensor(array_out, transform=first_geotensor.transform, crs=first_geotensor.crs,\n                     fill_value_default=first_geotensor.fill_value_default)\n</code></pre>"},{"location":"modules/geotensor_module/#georeader.geotensor.stack","title":"<code>stack(geotensors)</code>","text":"<p>Stacks a list of geotensors, assert that all of them has same shape, transform and crs.</p> <p>Parameters:</p> Name Type Description Default <code>geotensors</code> <code>List[GeoTensor]</code> <p>list of geotensors to concat. All with same shape, transform and crs.</p> required <p>Returns:</p> Type Description <code>GeoTensor</code> <p>geotensor with extra dim at the front: (len(geotensors),) + shape</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gt1 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; gt2 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; gt3 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n&gt;&gt;&gt; gt = stack([gt1, gt2, gt3])\n&gt;&gt;&gt; assert gt.shape == (3, 3, 100, 100)\n</code></pre> Source code in <code>georeader/geotensor.py</code> <pre><code>def stack(geotensors:List[GeoTensor]) -&gt; GeoTensor:\n    \"\"\"\n    Stacks a list of geotensors, assert that all of them has same shape, transform and crs.\n\n    Args:\n        geotensors: list of geotensors to concat. All with same shape, transform and crs.\n\n    Returns:\n        geotensor with extra dim at the front: (len(geotensors),) + shape\n\n    Examples:\n        &gt;&gt;&gt; gt1 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; gt2 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; gt3 = GeoTensor(np.random.rand(3, 100, 100), transform, crs)\n        &gt;&gt;&gt; gt = stack([gt1, gt2, gt3])\n        &gt;&gt;&gt; assert gt.shape == (3, 3, 100, 100)\n    \"\"\"\n    assert len(geotensors) &gt; 0, \"Empty list provided can't concat\"\n\n    if len(geotensors) == 1:\n        gt = geotensors[0].copy()\n        gt.values = gt.values[np.newaxis]\n        return gt\n\n    first_geotensor = geotensors[0]\n    array_out = np.zeros((len(geotensors),) + first_geotensor.shape,\n                         dtype=first_geotensor.dtype)\n    array_out[0] = first_geotensor.values\n\n    for i, geo in enumerate(geotensors[1:]):\n        assert geo.same_extent(first_geotensor), f\"Different size in concat\"\n        assert geo.shape == first_geotensor.shape, f\"Different shape in concat\"\n        assert geo.fill_value_default == first_geotensor.fill_value_default, \"Different fill_value_default in concat\"\n        array_out[i + 1] = geo.values\n\n    return GeoTensor(array_out, transform=first_geotensor.transform, crs=first_geotensor.crs,\n                     fill_value_default=first_geotensor.fill_value_default)\n</code></pre>"},{"location":"modules/rasterio_reader/","title":"RasterioReader","text":""},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader","title":"<code>RasterioReader</code>","text":"<p>Class to read a raster or a set of rasters files (<code>paths</code>). If the path is a single file it will return a 3D np.ndarray  with shape (C, H, W). If <code>paths</code> is a list, the <code>read</code> method will return a 4D np.ndarray with shape (len(paths), C, H, W)</p> <p>It checks that all rasters have same CRS, transform and shape. The <code>read</code> method will open the file every time it is called to work in parallel processing scenario.</p>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader--parameters","title":"Parameters","text":"<ul> <li>paths : <code>Union[List[str], str]</code>     Single path or list of paths of the rasters to read.</li> <li>allow_different_shape : <code>bool</code>     If True, will allow different shapes to be read (still checks that all rasters have same CRS,     transform and number of bands).</li> <li>window_focus : <code>Optional[rasterio.windows.Window]</code>     Window to read from. If provided, all windows in read call will be relative to this window.</li> <li>fill_value_default : <code>Optional[Union[int, float]]</code>     Value to fill when boundless read. It defaults to nodata if it is not None, otherwise it will be     set to zero.</li> <li>stack : <code>bool</code>     If <code>True</code>, returns 4D tensors; otherwise, it returns 3D tensors concatenated over the first dim. If      paths is string this argument is ignored and will be set to False (3D tensor).</li> <li>indexes : <code>Optional[List[int]]</code>     If not None, it will read from each raster only the specified bands. This argument is 1-based as in rasterio.</li> <li>overview_level : <code>Optional[int]</code>     If not None, it will read from the corresponding pyramid level. This argument is 0-based as in rasterio     (None -&gt; default resolution and 0 is the first overview).</li> <li>check : <code>bool</code>     Check all paths are OK.</li> <li>rio_env_options : <code>Optional[Dict[str, str]]</code>     GDAL options for reading. Defaults to: <code>RIO_ENV_OPTIONS_DEFAULT</code>. If you read rasters that might change     from a remote source, you might want to set <code>read_with_CPL_VSIL_CURL_NON_CACHED</code> to True.</li> </ul>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader--attributes","title":"Attributes","text":"<ul> <li>crs : <code>rasterio.crs.CRS</code>     Coordinate reference system.</li> <li>transform : <code>rasterio.Affine</code>     Transform of the rasters. If <code>window_focus</code> is provided, this transform will be relative to the window.</li> <li>dtype : <code>str</code>     Type of the input.</li> <li>count : <code>int</code>     Number of bands of the rasters.</li> <li>nodata : <code>Optional[Union[int, float]]</code>     Nodata value of the first raster in paths.</li> <li>fill_value_default : <code>Union[int, float]</code>     Value to fill when boundless read. Defaults to nodata.</li> <li>res : <code>Tuple[float, float]</code>     Resolution of the rasters.</li> <li>width : <code>int</code>     Width of the rasters. If <code>window_focus</code> is not None, this will be the width of the window.</li> <li>height : <code>int</code>     Height of the rasters. If <code>window_focus</code> is not None, this will be the height of the window.</li> <li>bounds : <code>Tuple[float, float, float, float]</code>     Bounds of the rasters. If <code>window_focus</code> is provided, these bounds will be relative to the window.</li> <li>dims : <code>List[str]</code>     Name of the dims (to make it compatible with xr.DataArray functions).</li> <li>attrs : <code>Dict[str, Any]</code>     Dictionary to store extra attributes.</li> </ul> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>class RasterioReader:\n    \"\"\"\n    Class to read a raster or a set of rasters files (``paths``). If the path is a single file it will return a 3D np.ndarray \n    with shape (C, H, W). If `paths` is a list, the `read` method will return a 4D np.ndarray with shape (len(paths), C, H, W)\n\n    It checks that all rasters have same CRS, transform and shape. The `read` method will open the file every time it\n    is called to work in parallel processing scenario.\n\n    Parameters\n    -------------------\n\n    - paths : `Union[List[str], str]`\n        Single path or list of paths of the rasters to read.\n    - allow_different_shape : `bool`\n        If True, will allow different shapes to be read (still checks that all rasters have same CRS,\n        transform and number of bands).\n    - window_focus : `Optional[rasterio.windows.Window]`\n        Window to read from. If provided, all windows in read call will be relative to this window.\n    - fill_value_default : `Optional[Union[int, float]]`\n        Value to fill when boundless read. It defaults to nodata if it is not None, otherwise it will be\n        set to zero.\n    - stack : `bool`\n        If `True`, returns 4D tensors; otherwise, it returns 3D tensors concatenated over the first dim. If \n        paths is string this argument is ignored and will be set to False (3D tensor).\n    - indexes : `Optional[List[int]]`\n        If not None, it will read from each raster only the specified bands. This argument is 1-based as in rasterio.\n    - overview_level : `Optional[int]`\n        If not None, it will read from the corresponding pyramid level. This argument is 0-based as in rasterio\n        (None -&gt; default resolution and 0 is the first overview).\n    - check : `bool`\n        Check all paths are OK.\n    - rio_env_options : `Optional[Dict[str, str]]`\n        GDAL options for reading. Defaults to: `RIO_ENV_OPTIONS_DEFAULT`. If you read rasters that might change\n        from a remote source, you might want to set `read_with_CPL_VSIL_CURL_NON_CACHED` to True.\n\n    Attributes\n    -------------------\n\n    - crs : `rasterio.crs.CRS`\n        Coordinate reference system.\n    - transform : `rasterio.Affine`\n        Transform of the rasters. If `window_focus` is provided, this transform will be relative to the window.\n    - dtype : `str`\n        Type of the input.\n    - count : `int`\n        Number of bands of the rasters.\n    - nodata : `Optional[Union[int, float]]`\n        Nodata value of the first raster in paths.\n    - fill_value_default : `Union[int, float]`\n        Value to fill when boundless read. Defaults to nodata.\n    - res : `Tuple[float, float]`\n        Resolution of the rasters.\n    - width : `int`\n        Width of the rasters. If `window_focus` is not None, this will be the width of the window.\n    - height : `int`\n        Height of the rasters. If `window_focus` is not None, this will be the height of the window.\n    - bounds : `Tuple[float, float, float, float]`\n        Bounds of the rasters. If `window_focus` is provided, these bounds will be relative to the window.\n    - dims : `List[str]`\n        Name of the dims (to make it compatible with xr.DataArray functions).\n    - attrs : `Dict[str, Any]`\n        Dictionary to store extra attributes.\n    \"\"\"\n    def __init__(self, paths:Union[List[str], str], allow_different_shape:bool=False,\n                 window_focus:Optional[rasterio.windows.Window]=None,\n                 fill_value_default:Optional[Union[int, float]]=None,\n                 stack:bool=True, indexes:Optional[List[int]]=None,\n                 overview_level:Optional[int]=None, check:bool=True,\n                 rio_env_options:Optional[Dict[str, str]]=None):\n\n        # Syntactic sugar\n        if isinstance(paths, str):\n            paths = [paths]\n            stack = False\n\n        if rio_env_options is None:\n            self.rio_env_options = RIO_ENV_OPTIONS_DEFAULT\n        else:\n            self.rio_env_options = rio_env_options\n\n        self.paths = paths\n\n        self.stack = stack\n\n        # TODO keep just a global nodata of size (T,C,) and fill with these values?\n        self.fill_value_default = fill_value_default\n        self.overview_level = overview_level\n        with rasterio.Env(**self._get_rio_options_path(paths[0])):\n            with rasterio.open(paths[0], \"r\", overview_level=overview_level) as src:\n                self.real_transform = src.transform\n                self.crs = src.crs\n                self.dtype = src.profile[\"dtype\"]\n                self.real_count = src.count\n                self.real_indexes = list(range(1, self.real_count + 1))\n                if self.stack:\n                    self.real_shape = (len(self.paths), src.count,) + src.shape\n                else:\n                    self.real_shape = (len(self.paths) * self.real_count, ) + src.shape\n\n                self.real_width = src.width\n                self.real_height = src.height\n\n                self.nodata = src.nodata\n                if self.fill_value_default is None:\n                    self.fill_value_default = self.nodata if (self.nodata is not None) else 0\n\n                self.res = src.res\n\n        # if (abs(self.real_transform.b) &gt; 1e-6) or (abs(self.real_transform.d) &gt; 1e-6):\n        #     warnings.warn(f\"transform of {self.paths[0]} is not rectilinear {self.real_transform}. \"\n        #                   f\"The vast majority of the code expect rectilinear transforms. This transform \"\n        #                   f\"could cause unexpected behaviours\")\n\n        self.attrs = {}\n        self.window_focus = rasterio.windows.Window(row_off=0, col_off=0,\n                                                    width=self.real_width, height=self.real_height)\n        self.real_window = rasterio.windows.Window(row_off=0, col_off=0,\n                                                   width=self.real_width, height=self.real_height)\n        self.set_indexes(self.real_indexes, relative=False)\n        self.set_window(window_focus, relative=False)\n\n        self.allow_different_shape = allow_different_shape\n\n        if self.stack:\n            self.dims = [\"time\", \"band\", \"y\", \"x\"]\n        else:\n            self.dims = [\"band\", \"y\", \"x\"]\n\n        self._coords = None\n\n        # Assert all paths have same tranform and crs\n        #  (checking width and height will not be needed since we're reading with boundless option but I don't see the point to ignore it)\n        if check and len(self.paths) &gt; 1:\n            for p in self.paths:\n                with rasterio.Env(**self._get_rio_options_path(p)):\n                    with rasterio.open(p, \"r\", overview_level=overview_level) as src:\n                        if not src.transform.almost_equals(self.real_transform, 1e-6):\n                            raise ValueError(f\"Different transform in {self.paths[0]} and {p}: {self.real_transform} {src.transform}\")\n                        if not str(src.crs).lower() == str(self.crs).lower():\n                            raise ValueError(f\"Different CRS in {self.paths[0]} and {p}: {self.crs} {src.crs}\")\n                        if self.real_count != src.count:\n                            raise ValueError(f\"Different number of bands in {self.paths[0]} and {p} {self.real_count} {src.count}\")\n                        if src.nodata != self.nodata:\n                            warnings.warn(\n                                f\"Different nodata in {self.paths[0]} and {p}: {self.nodata} {src.nodata}. This might lead to unexpected behaviour\")\n\n                        if (self.real_width != src.width) or (self.real_height != src.height):\n                            if allow_different_shape:\n                                warnings.warn(f\"Different shape in {self.paths[0]} and {p}: ({self.real_height}, {self.real_width}) ({src.height}, {src.width}) Might lead to unexpected behaviour\")\n                            else:\n                                raise ValueError(f\"Different shape in {self.paths[0]} and {p}: ({self.real_height}, {self.real_width}) ({src.height}, {src.width})\")\n\n        self.check = check\n        if indexes is not None:\n            self.set_indexes(indexes)\n\n    def set_indexes(self, indexes:List[int], relative:bool=True)-&gt; None:\n        \"\"\"\n        Set the channels to read. This is useful for processing only some channels of the raster. The indexes\n        passed will be relative to self.indexes\n        Args:\n            indexes: 1-based array to mantain rasterio convention\n            relative: True means the indexes arg will be treated ad relative to the current self.indexes. If false\n                     it sets self.indexes = indexes (and update the count attribute)\n        Examples:\n            &gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\", indexes=[2,3,4]) # Read all bands except the first one.\n            &gt;&gt;&gt; r.set_indexes([2,3], relative=True) # will read bands 2 and 3 of the original raster\n        \"\"\"\n        if relative:\n            new_indexes = [self.indexes[idx - 1] for idx in indexes]\n        else:\n            new_indexes = indexes\n\n        # Check if indexes are valid\n        assert all((s &gt;= 1) and (s &lt;= self.real_count) for s in new_indexes), \\\n               f\"Indexes (1-based) out of real bounds current: {self.indexes} asked: {new_indexes} number of bands:{self.real_count}\"\n\n        self.indexes = new_indexes\n\n        assert all((s &gt;= 1) and (s &lt;= self.real_count) for s in\n                   self.indexes), f\"Indexes out of real bounds current: {self.indexes} asked: {indexes} number of bands:{self.real_count}\"\n\n        self.count = len(self.indexes)\n\n    def set_indexes_by_name(self, names:List[str]) -&gt; None:\n        \"\"\"\n        Function to set the indexes by the name of the band which is stored in the descriptions attribute\n\n        Args:\n            names: List of band names to read\n\n        Examples:\n            &gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\") # Read all bands except the first one.\n            &gt;&gt;&gt; # Assume r.descriptions = [\"B1\", \"B2\", \"B3\"]\n            &gt;&gt;&gt; r.set_indexes_by_name([\"B2\", \"B3\"])\n\n        \"\"\"\n        descriptions = self.descriptions\n        if len(self.paths) == 1:\n            if self.stack:\n                descriptions = descriptions[0]\n        else:\n            assert all(d == descriptions[0] for d in descriptions), \"There are tiffs with different names\"\n            descriptions = descriptions[0]\n\n        bands = [descriptions.index(b) + 1 for b in names]\n        self.set_indexes(bands, relative=False)\n\n    @property\n    def shape(self):\n        if self.stack:\n            return len(self.paths), self.count, self.height, self.width\n        return len(self.paths) * self.count, self.height, self.width\n\n    def same_extent(self, other:Union[GeoData,'RasterioReader'], precision:float=1e-3) -&gt; bool:\n        \"\"\"\n        Check if two GeoData objects have the same extent\n\n        Args:\n            other: GeoData object to compare\n            precision: precision to compare the bounds\n\n        Returns:\n            True if both objects have the same extent\n\n        \"\"\"\n        return same_extent(self, other, precision=precision)\n\n    def set_window(self, window_focus:Optional[rasterio.windows.Window] = None,\n                   relative:bool = True, boundless:bool=True)-&gt;None:\n        \"\"\"\n        Set window to read. This is useful for processing only some part of the raster. The windows passed as\n         arguments in the read calls will be relative to this window.\n\n        Args:\n            window_focus: rasterio window. If None will be set to the full raster tile\n            relative: provided window is relative to current self.window_focus\n            boundless: if boundless is false the windows that do not overlap the total raster will be\n                intersected.\n\n        Examples:\n            &gt;&gt;&gt; # Read the first 1000x1000 pixels of the raster\n            &gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\")\n            &gt;&gt;&gt; r.set_window(rasterio.windows.Window(col_off=0, row_off=0, width=1000, height=1000))\n            &gt;&gt;&gt; r.load() #  returns GeoTensor with shape (1, 1, 1000, 1000)\n\n        \"\"\"\n        if window_focus is None:\n            self.window_focus = rasterio.windows.Window(row_off=0, col_off=0,\n                                                        width=self.real_width, height=self.real_height)\n        elif relative:\n            self.window_focus = rasterio.windows.Window(col_off=window_focus.col_off + self.window_focus.col_off,\n                                                        row_off=window_focus.row_off + self.window_focus.row_off,\n                                                        height=window_focus.height, width=window_focus.width)\n        else:\n            self.window_focus = window_focus\n\n        if not boundless:\n            self.window_focus = rasterio.windows.intersection(self.real_window, self.window_focus)\n\n        self.height = self.window_focus.height\n        self.width = self.window_focus.width\n\n        self.bounds = window_bounds(self.window_focus, self.real_transform)\n        self.transform = rasterio.windows.transform(self.window_focus, self.real_transform)\n\n    def tags(self) -&gt; Union[List[Dict[str, str]], Dict[str, str]]:\n        \"\"\"\n        Returns a list with the tags for each tiff file.\n        If stack and len(self.paths) == 1 it returns just the dictionary of the tags\n\n        \"\"\"\n        tags = []\n        for i, p in enumerate(self.paths):\n            with rasterio.Env(**self._get_rio_options_path(p)):\n                with rasterio.open(p, mode=\"r\") as src:\n                    tags.append(src.tags())\n\n        if (not self.stack) and (len(tags) == 1):\n            return tags[0]\n\n        return tags\n\n    def _get_rio_options_path(self, path:str) -&gt; Dict[str, str]:\n        options = self.rio_env_options\n        if \"read_with_CPL_VSIL_CURL_NON_CACHED\" in options:\n            options = options.copy()\n            if options[\"read_with_CPL_VSIL_CURL_NON_CACHED\"]:\n                options[\"CPL_VSIL_CURL_NON_CACHED\"] = _vsi_path(path)\n            del options[\"read_with_CPL_VSIL_CURL_NON_CACHED\"]\n        return options\n\n    # This function does not work for e.g. returning the descriptions of the bands\n    # @contextmanager\n    # def _rio_open(self, path:str, mode:str=\"r\", overview_level:Optional[int]=None) -&gt; rasterio.DatasetReader:\n    #     with rasterio.Env(**self._get_rio_options_path(path)):\n    #         with rasterio.open(path, mode=mode, overview_level=overview_level) as src:\n    #             yield src\n\n    @property\n    def descriptions(self) -&gt; Union[List[List[str]], List[str]]:\n        \"\"\"\n        Returns a list with the descriptions for each tiff file. (This is usually the name of the bands of the raster)\n\n\n        Returns:\n            If `stack` it returns the flattened list of descriptions for each tiff file. If not `stack` it returns a list of lists.\n\n        Examples:\n            &gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\") # Raster with band names B1, B2, B3\n            &gt;&gt;&gt; r.descriptions # returns [\"B1\", \"B2\", \"B3\"]\n        \"\"\"\n        descriptions_all = []\n        for i, p in enumerate(self.paths):\n            with rasterio.Env(**self._get_rio_options_path(p)):\n                with rasterio.open(p) as src:\n                    desc = src.descriptions\n\n            if self.stack:\n                descriptions_all.append([desc[i-1] for i in self.indexes])\n            else:\n                descriptions_all.extend([desc[i-1] for i in self.indexes])\n\n        return descriptions_all\n\n    def read_from_window(self, window:rasterio.windows.Window, boundless:bool=True) -&gt; '__class__':\n        \"\"\"\n        Returns a new reader with window focus the window `window` relative to `self.window_focus`\n\n        Args:\n            window: rasterio.window.Window to read\n            boundless: if boundless is False if the window do not overlap the total raster  it will be\n                intersected.\n\n        Raises:\n            rasterio.windows.WindowError: if bounless is False and window does not intersects self.window_focus\n\n        Returns:\n            New reader object\n        \"\"\"\n        rst_reader = RasterioReader(list(self.paths),\n                                    allow_different_shape=self.allow_different_shape,\n                                    window_focus=self.window_focus, fill_value_default=self.fill_value_default,\n                                    stack=self.stack, overview_level=self.overview_level,\n                                    check=False)\n\n        rst_reader.set_window(window, relative=True, boundless=boundless)\n        rst_reader.set_indexes(self.indexes, relative=False)\n        return rst_reader\n\n    def isel(self, sel: Dict[str, Union[slice, List[int], int]], boundless:bool=True) -&gt; '__class__':\n        \"\"\"\n        Creates a copy of the current RasterioReader slicing the data with a given selection dict. This function\n        mimics ``xr.DataArray.isel()`` method.\n\n        Args:\n            sel: Dict of slices to slice the current reader\n            boundless: If `True` slices in \"x\" and \"y\" are boundless (i.e. negative means negative indexes rather than\n                values from the other side of the array as in numpy).\n\n        Returns:\n            Copy of the current reader\n\n        Examples:\n            &gt;&gt;&gt; r = RasterioReader([\"path/to/raster1.tif\", \"path/to/raster2.tif\"])\n            &gt;&gt;&gt; r.isel({\"time\": 0, \"band\": [0]}) # returns a reader with the first band of the first raster\n            &gt;&gt;&gt; r.isel({\"time\": slice(0, 1), \"band\": [0]}) # returns a reader with the first band of the first raster and second raster\n            &gt;&gt;&gt; r.isel({\"x\": slice(4000, 5000), \"band\": [0, 1]}) # returns a reader slicing the x axis from 4000 to 5000 and the first two bands\n        \"\"\"\n        for k in sel:\n            if k not in self.dims:\n                raise NotImplementedError(f\"Axis {k} not in dims: {self.dims}\")\n\n        stack = self.stack\n        if \"time\" in sel: # time allowed only if self.stack (would have raised error above)\n            if isinstance(sel[\"time\"], Iterable):\n                paths = [self.paths[i] for i in sel[\"time\"]]\n            elif isinstance(sel[\"time\"], slice):\n                paths = self.paths[sel[\"time\"]]\n            elif isinstance(sel[\"time\"], numbers.Number):\n                paths = [self.paths[sel[\"time\"]]]\n                stack = False\n            else:\n                raise NotImplementedError(f\"Don't know how to slice {sel['time']} in dim time\")\n        else:\n            paths = self.paths\n\n        # Band slicing\n        if \"band\" in sel:\n            if not self.stack:\n                # if `True` returns 4D tensors otherwise it returns 3D tensors concatenated over the first dim\n                assert (len(self.paths) == 1) or (len(self.indexes) == 1), f\"Dont know how to slice {self.paths} and {self.indexes}\"\n\n            if self.stack or (len(self.paths) == 1):\n                if isinstance(sel[\"band\"], Iterable):\n                    indexes = [self.indexes[i] for i in sel[\"band\"]] # indexes relative to current indexes\n                elif isinstance(sel[\"band\"], slice):\n                    indexes = self.indexes[sel[\"band\"]]\n                elif isinstance(sel[\"band\"], numbers.Number):\n                    raise NotImplementedError(f\"Slicing band with a single number is not supported (use a list)\")\n                else:\n                    raise NotImplementedError(f\"Don't know how to slice {sel['band']} in dim band\")\n            else:\n                indexes = self.indexes\n                # len(indexes) == 1 and not self.stack in this case band slicing correspond to paths\n                if isinstance(sel[\"band\"], Iterable):\n                    paths = [self.paths[i] for i in sel[\"band\"]]\n                elif isinstance(sel[\"band\"], slice):\n                    paths = self.paths[sel[\"band\"]]\n                elif isinstance(sel[\"band\"], numbers.Number):\n                    paths = [self.paths[sel[\"band\"]]]\n                else:\n                    raise NotImplementedError(f\"Don't know how to slice {sel['time']} in dim time\")\n        else:\n            indexes = self.indexes\n\n        # Spatial slicing\n        slice_ = []\n        spatial_shape = (self.height, self.width)\n        for _i, spatial_name in enumerate([\"y\", \"x\"]):\n            if spatial_name in sel:\n                if not isinstance(sel[spatial_name], slice):\n                    raise NotImplementedError(f\"spatial dimension {spatial_name} only accept slice objects\")\n                slice_.append(sel[spatial_name])\n            else:\n                slice_.append(slice(0, spatial_shape[_i]))\n\n        rst_reader = RasterioReader(paths, allow_different_shape=self.allow_different_shape,\n                                    window_focus=self.window_focus, fill_value_default=self.fill_value_default,\n                                    stack=stack, overview_level=self.overview_level,\n                                    check=False)\n        window_current = rasterio.windows.Window.from_slices(*slice_, boundless=boundless,\n                                                             width=self.width, height=self.height)\n\n        # Set bands to read\n        rst_reader.set_indexes(indexes=indexes, relative=False)\n\n        # set window_current relative to self.window_focus\n        rst_reader.set_window(window_current, relative=True)\n\n        return rst_reader\n\n    def __copy__(self) -&gt; '__class__':\n        return RasterioReader(self.paths, allow_different_shape=self.allow_different_shape,\n                              window_focus=self.window_focus, \n                              fill_value_default=self.fill_value_default,\n                              stack=self.stack, overview_level=self.overview_level,\n                              check=False)\n\n    def overviews(self, index:int=1, time_index:int=0) -&gt; List[int]:\n        \"\"\"\n        Returns a list of the available overview levels for the current raster.\n        \"\"\"\n        with rasterio.Env(**self._get_rio_options_path(self.paths[time_index])):\n            with rasterio.open(self.paths[time_index]) as src:\n                return src.overviews(index)\n\n    def reader_overview(self, overview_level:int) -&gt; '__class__':\n        if overview_level &lt; 0:\n            overview_level = len(self.overviews()) + overview_level\n\n        return RasterioReader(self.paths, allow_different_shape=self.allow_different_shape,\n                              window_focus=self.window_focus, \n                              fill_value_default=self.fill_value_default,\n                              stack=self.stack, overview_level=overview_level,\n                              check=False)\n\n    def block_windows(self, bidx:int=1, time_idx:int=0) -&gt; List[Tuple[int, rasterio.windows.Window]]:\n        \"\"\"\n        return the block windows within the object\n        (see https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.block_windows)\n\n        Args:\n            bidx: band index to read (1-based)\n            time_idx: time index to read (0-based)\n\n        Returns:\n            list of (block_idx, window)\n\n        \"\"\"\n        with rasterio.Env(**self._get_rio_options_path(self.paths[time_idx])):\n            with rasterio.open(self.paths[time_idx]) as src:\n                windows_return = [(block_idx, rasterio.windows.intersection(window, self.window_focus)) for block_idx, window in src.block_windows(bidx) if rasterio.windows.intersect(self.window_focus, window)]\n\n        return windows_return\n\n    def copy(self) -&gt; '__class__':\n        return self.__copy__()\n\n    def load(self, boundless:bool=True) -&gt; geotensor.GeoTensor:\n        \"\"\"\n        Load all raster in memory in an GeoTensor object\n\n        Returns:\n            GeoTensor (wrapper of numpy array with spatial information)\n\n        \"\"\"\n        np_data = self.read(boundless=boundless)\n        if boundless:\n            transform = self.transform\n        else:\n            # update transform, shape and coords\n            window = self.window_focus\n            start_col = max(window.col_off, 0)\n            end_col = min(window.col_off + window.width, self.real_width)\n            start_row = max(window.row_off, 0)\n            end_row = min(window.row_off + window.height, self.real_height)\n            spatial_shape = (end_row - start_row, end_col - start_col)\n            assert np_data.shape[-2:] == spatial_shape, f\"Different shapes {np_data.shape[-2:]} {spatial_shape}\"\n\n            window_real = rasterio.windows.Window(row_off=start_row, col_off=start_col,\n                                                  width=spatial_shape[1], height=spatial_shape[0])\n            transform = rasterio.windows.transform(window_real, self.real_transform)\n\n        return geotensor.GeoTensor(np_data, transform=transform, crs=self.crs, fill_value_default=self.fill_value_default)\n\n    @property\n    def values(self) -&gt; np.ndarray:\n        \"\"\"\n        This property is added to be consistent with xr.DataArray. It reads the whole raster in memory and returns it\n\n        Returns:\n            np.ndarray raster loaded in memory\n        \"\"\"\n        return self.read()\n\n    def footprint(self, crs:Optional[str]=None) -&gt; Polygon:\n        pol = window_utils.window_polygon(rasterio.windows.Window(row_off=0, col_off=0, height=self.shape[-2], width=self.shape[-1]),\n                                          self.transform)\n        if (crs is None) or window_utils.compare_crs(self.crs, crs):\n            return pol\n\n        return window_utils.polygon_to_crs(pol, self.crs, crs)\n\n    def meshgrid(self, dst_crs:Optional[Any]=None) -&gt; Tuple[NDArray, NDArray]:\n        from georeader import griddata\n        return griddata.meshgrid(self.transform, self.width, self.height, source_crs=self.crs, dst_crs=dst_crs)\n\n    def __repr__(self)-&gt;str:\n        return f\"\"\" \n         Paths: {self.paths}\n         Transform: {self.transform}\n         Shape: {self.shape}\n         Resolution: {self.res}\n         Bounds: {self.bounds}\n         CRS: {self.crs}\n         nodata: {self.nodata}\n         fill_value_default: {self.fill_value_default}\n        \"\"\"\n\n    def read(self, **kwargs) -&gt; np.ndarray:\n        \"\"\"\n        Read data from the list of rasters. It reads with boundless=True by default and\n        fill_value=self.fill_value_default by default.\n\n        This function is process safe (opens and closes the rasterio object every time is called).\n\n        For arguments see: https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.read\n\n        Returns:\n            if self.stack:\n                4D np.ndarray with shape (len(paths), C, H, W)\n            if self.stack is False:\n                3D np.ndarray with shape (len(paths)*C, H, W)\n        \"\"\"\n\n        if (\"window\" in kwargs) and kwargs[\"window\"] is not None:\n            window_read = kwargs[\"window\"]\n            if isinstance(window_read, tuple):\n                window_read = rasterio.windows.Window.from_slices(*window_read,\n                                                                  boundless=kwargs.get(\"boundless\", True))\n\n            # Windows are relative to the windows_focus window.\n            window = rasterio.windows.Window(col_off=window_read.col_off + self.window_focus.col_off,\n                                             row_off=window_read.row_off + self.window_focus.row_off,\n                                             height=window_read.height, width=window_read.width)\n        else:\n            window = self.window_focus\n\n        kwargs[\"window\"] = window\n\n        if \"boundless\" not in kwargs:\n            kwargs[\"boundless\"] = True\n\n        if not rasterio.windows.intersect([self.real_window, window]) and not kwargs[\"boundless\"]:\n            return None\n\n        if not kwargs[\"boundless\"]:\n            window = window.intersection(self.real_window)\n\n        if \"fill_value\" not in kwargs:\n            kwargs[\"fill_value\"] = self.fill_value_default\n\n        if  kwargs.get(\"indexes\", None) is not None:\n            # Indexes are relative to the self.indexes window.\n            indexes = kwargs[\"indexes\"]\n            if isinstance(indexes, numbers.Number):\n                n_bands_read = 1\n                kwargs[\"indexes\"] = [self.indexes[kwargs[\"indexes\"] - 1]]\n                flat_channels = True\n            else:\n                n_bands_read = len(indexes)\n                kwargs[\"indexes\"] = [self.indexes[i - 1] for i in kwargs[\"indexes\"]]\n                flat_channels = False\n        else:\n            kwargs[\"indexes\"] = self.indexes\n            n_bands_read = self.count\n            flat_channels = False\n\n        if kwargs.get(\"out_shape\", None) is not None:\n            if len(kwargs[\"out_shape\"]) == 2:\n                kwargs[\"out_shape\"] = (n_bands_read, ) + kwargs[\"out_shape\"]\n            elif len(kwargs[\"out_shape\"]) == 3:\n                assert kwargs[\"out_shape\"][0] == n_bands_read, f\"Expected to read {n_bands_read} but found out_shape: {kwargs['out_shape']}\"\n            else:\n                raise NotImplementedError(f\"Expected out_shape of len 2 or 3 found out_shape: {kwargs['out_shape']}\")\n            spatial_shape = kwargs[\"out_shape\"][1:]\n        else:\n            spatial_shape = (window.height, window.width)\n\n        shape = (len(self.paths), n_bands_read) + spatial_shape\n\n        obj_out = np.full(shape, kwargs[\"fill_value\"], dtype=self.dtype)\n        if rasterio.windows.intersect([self.real_window, window]):\n            pad = None\n            if kwargs[\"boundless\"]:\n                slice_, pad = get_slice_pad(self.real_window, window)\n                need_pad = any(x != 0 for x in pad[\"x\"] + pad[\"y\"])\n\n                #  read and pad instead of using boundless attribute when transform is not rectilinear (otherwise rasterio fails!)\n                if (abs(self.real_transform.b) &gt; 1e-6) or (abs(self.real_transform.d) &gt; 1e-6):\n                    if need_pad:\n                        assert kwargs.get(\"out_shape\", None) is None, \"out_shape not compatible with boundless and non rectilinear transform!\"\n                        kwargs[\"window\"] = rasterio.windows.Window.from_slices(slice_[\"y\"], slice_[\"x\"])\n                        kwargs[\"boundless\"] = False\n                    else:\n                        kwargs[\"boundless\"] = False\n                else:\n                    #  if transform is rectilinear read boundless if needed\n                    kwargs[\"boundless\"] = need_pad\n                    pad = None\n\n            for i, p in enumerate(self.paths):\n                with rasterio.Env(**self._get_rio_options_path(p)):\n                    with rasterio.open(p, \"r\", overview_level=self.overview_level) as src:\n                    # rasterio.read API: https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.read\n                        read_data = src.read(**kwargs)\n\n                        # Add pad when reading\n                        if pad is not None and need_pad:\n                            slice_y = slice(pad[\"y\"][0], -pad[\"y\"][1] if pad[\"y\"][1] !=0 else None)\n                            slice_x = slice(pad[\"x\"][0], -pad[\"x\"][1] if pad[\"x\"][1] !=0 else None)\n                            obj_out[i, :, slice_y, slice_x] = read_data\n                        else:\n                            obj_out[i] = read_data\n                        # pad_list_np = _get_pad_list(pad)\n                    #\n                    # read_data = np.pad(read_data, tuple(pad_list_np), mode=\"constant\",\n                    #                    constant_values=self.fill_value_default)\n\n\n\n        if flat_channels:\n            obj_out = obj_out[:, 0]\n\n        if not self.stack:\n            if obj_out.shape[0] == 1:\n                obj_out = obj_out[0]\n            else:\n                obj_out = np.concatenate([obj_out[i] for i in range(obj_out.shape[0])],\n                                         axis=0)\n\n        return obj_out\n\n    def read_from_tile(self, x:int, y:int, z:int, \n                       out_shape:Tuple[int,int]=(SIZE_DEFAULT, SIZE_DEFAULT),\n                       dst_crs:Optional[Any]=WEB_MERCATOR_CRS) -&gt; geotensor.GeoTensor:\n        \"\"\"\n        Read a web mercator tile from a raster.\n\n        Tiles are TMS tiles defined as: (https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames)\n\n        Args:\n            x (int): x coordinate of the tile in the TMS system.\n            y (int): y coordinate of the tile in the TMS system.\n            z (int): z coordinate of the tile in the TMS system.\n            out_shape (Tuple[int,int]: size of the tile to read. Defaults to (read.SIZE_DEFAULT, read.SIZE_DEFAULT).\n            dst_crs (Optional[Any], optional): CRS of the output tile. Defaults to read.WEB_MERCATOR_CRS.\n\n        Returns:\n            geotensor.GeoTensor: geotensor with the tile data.\n        \"\"\"\n        window = window_from_tile(self, x, y, z)\n        window = window_utils.round_outer_window(window)\n        data = read_out_shape(self, out_shape=out_shape, window=window)\n\n        if window_utils.compare_crs(self.crs, dst_crs):\n            return data\n\n        # window = window_utils.pad_window(window, (1, 1))\n        # data = read_out_shape(self, out_shape=size_out, window=window)\n\n        return read_from_tile(data, x, y, z, dst_crs=dst_crs, out_shape=out_shape)\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.descriptions","title":"<code>descriptions: Union[List[List[str]], List[str]]</code>  <code>property</code>","text":"<p>Returns a list with the descriptions for each tiff file. (This is usually the name of the bands of the raster)</p> <p>Returns:</p> Type Description <code>Union[List[List[str]], List[str]]</code> <p>If <code>stack</code> it returns the flattened list of descriptions for each tiff file. If not <code>stack</code> it returns a list of lists.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\") # Raster with band names B1, B2, B3\n&gt;&gt;&gt; r.descriptions # returns [\"B1\", \"B2\", \"B3\"]\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.values","title":"<code>values: np.ndarray</code>  <code>property</code>","text":"<p>This property is added to be consistent with xr.DataArray. It reads the whole raster in memory and returns it</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray raster loaded in memory</p>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.block_windows","title":"<code>block_windows(bidx=1, time_idx=0)</code>","text":"<p>return the block windows within the object (see https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.block_windows)</p> <p>Parameters:</p> Name Type Description Default <code>bidx</code> <code>int</code> <p>band index to read (1-based)</p> <code>1</code> <code>time_idx</code> <code>int</code> <p>time index to read (0-based)</p> <code>0</code> <p>Returns:</p> Type Description <code>List[Tuple[int, Window]]</code> <p>list of (block_idx, window)</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def block_windows(self, bidx:int=1, time_idx:int=0) -&gt; List[Tuple[int, rasterio.windows.Window]]:\n    \"\"\"\n    return the block windows within the object\n    (see https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.block_windows)\n\n    Args:\n        bidx: band index to read (1-based)\n        time_idx: time index to read (0-based)\n\n    Returns:\n        list of (block_idx, window)\n\n    \"\"\"\n    with rasterio.Env(**self._get_rio_options_path(self.paths[time_idx])):\n        with rasterio.open(self.paths[time_idx]) as src:\n            windows_return = [(block_idx, rasterio.windows.intersection(window, self.window_focus)) for block_idx, window in src.block_windows(bidx) if rasterio.windows.intersect(self.window_focus, window)]\n\n    return windows_return\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.isel","title":"<code>isel(sel, boundless=True)</code>","text":"<p>Creates a copy of the current RasterioReader slicing the data with a given selection dict. This function mimics <code>xr.DataArray.isel()</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>sel</code> <code>Dict[str, Union[slice, List[int], int]]</code> <p>Dict of slices to slice the current reader</p> required <code>boundless</code> <code>bool</code> <p>If <code>True</code> slices in \"x\" and \"y\" are boundless (i.e. negative means negative indexes rather than values from the other side of the array as in numpy).</p> <code>True</code> <p>Returns:</p> Type Description <code>__class__</code> <p>Copy of the current reader</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; r = RasterioReader([\"path/to/raster1.tif\", \"path/to/raster2.tif\"])\n&gt;&gt;&gt; r.isel({\"time\": 0, \"band\": [0]}) # returns a reader with the first band of the first raster\n&gt;&gt;&gt; r.isel({\"time\": slice(0, 1), \"band\": [0]}) # returns a reader with the first band of the first raster and second raster\n&gt;&gt;&gt; r.isel({\"x\": slice(4000, 5000), \"band\": [0, 1]}) # returns a reader slicing the x axis from 4000 to 5000 and the first two bands\n</code></pre> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def isel(self, sel: Dict[str, Union[slice, List[int], int]], boundless:bool=True) -&gt; '__class__':\n    \"\"\"\n    Creates a copy of the current RasterioReader slicing the data with a given selection dict. This function\n    mimics ``xr.DataArray.isel()`` method.\n\n    Args:\n        sel: Dict of slices to slice the current reader\n        boundless: If `True` slices in \"x\" and \"y\" are boundless (i.e. negative means negative indexes rather than\n            values from the other side of the array as in numpy).\n\n    Returns:\n        Copy of the current reader\n\n    Examples:\n        &gt;&gt;&gt; r = RasterioReader([\"path/to/raster1.tif\", \"path/to/raster2.tif\"])\n        &gt;&gt;&gt; r.isel({\"time\": 0, \"band\": [0]}) # returns a reader with the first band of the first raster\n        &gt;&gt;&gt; r.isel({\"time\": slice(0, 1), \"band\": [0]}) # returns a reader with the first band of the first raster and second raster\n        &gt;&gt;&gt; r.isel({\"x\": slice(4000, 5000), \"band\": [0, 1]}) # returns a reader slicing the x axis from 4000 to 5000 and the first two bands\n    \"\"\"\n    for k in sel:\n        if k not in self.dims:\n            raise NotImplementedError(f\"Axis {k} not in dims: {self.dims}\")\n\n    stack = self.stack\n    if \"time\" in sel: # time allowed only if self.stack (would have raised error above)\n        if isinstance(sel[\"time\"], Iterable):\n            paths = [self.paths[i] for i in sel[\"time\"]]\n        elif isinstance(sel[\"time\"], slice):\n            paths = self.paths[sel[\"time\"]]\n        elif isinstance(sel[\"time\"], numbers.Number):\n            paths = [self.paths[sel[\"time\"]]]\n            stack = False\n        else:\n            raise NotImplementedError(f\"Don't know how to slice {sel['time']} in dim time\")\n    else:\n        paths = self.paths\n\n    # Band slicing\n    if \"band\" in sel:\n        if not self.stack:\n            # if `True` returns 4D tensors otherwise it returns 3D tensors concatenated over the first dim\n            assert (len(self.paths) == 1) or (len(self.indexes) == 1), f\"Dont know how to slice {self.paths} and {self.indexes}\"\n\n        if self.stack or (len(self.paths) == 1):\n            if isinstance(sel[\"band\"], Iterable):\n                indexes = [self.indexes[i] for i in sel[\"band\"]] # indexes relative to current indexes\n            elif isinstance(sel[\"band\"], slice):\n                indexes = self.indexes[sel[\"band\"]]\n            elif isinstance(sel[\"band\"], numbers.Number):\n                raise NotImplementedError(f\"Slicing band with a single number is not supported (use a list)\")\n            else:\n                raise NotImplementedError(f\"Don't know how to slice {sel['band']} in dim band\")\n        else:\n            indexes = self.indexes\n            # len(indexes) == 1 and not self.stack in this case band slicing correspond to paths\n            if isinstance(sel[\"band\"], Iterable):\n                paths = [self.paths[i] for i in sel[\"band\"]]\n            elif isinstance(sel[\"band\"], slice):\n                paths = self.paths[sel[\"band\"]]\n            elif isinstance(sel[\"band\"], numbers.Number):\n                paths = [self.paths[sel[\"band\"]]]\n            else:\n                raise NotImplementedError(f\"Don't know how to slice {sel['time']} in dim time\")\n    else:\n        indexes = self.indexes\n\n    # Spatial slicing\n    slice_ = []\n    spatial_shape = (self.height, self.width)\n    for _i, spatial_name in enumerate([\"y\", \"x\"]):\n        if spatial_name in sel:\n            if not isinstance(sel[spatial_name], slice):\n                raise NotImplementedError(f\"spatial dimension {spatial_name} only accept slice objects\")\n            slice_.append(sel[spatial_name])\n        else:\n            slice_.append(slice(0, spatial_shape[_i]))\n\n    rst_reader = RasterioReader(paths, allow_different_shape=self.allow_different_shape,\n                                window_focus=self.window_focus, fill_value_default=self.fill_value_default,\n                                stack=stack, overview_level=self.overview_level,\n                                check=False)\n    window_current = rasterio.windows.Window.from_slices(*slice_, boundless=boundless,\n                                                         width=self.width, height=self.height)\n\n    # Set bands to read\n    rst_reader.set_indexes(indexes=indexes, relative=False)\n\n    # set window_current relative to self.window_focus\n    rst_reader.set_window(window_current, relative=True)\n\n    return rst_reader\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.load","title":"<code>load(boundless=True)</code>","text":"<p>Load all raster in memory in an GeoTensor object</p> <p>Returns:</p> Type Description <code>GeoTensor</code> <p>GeoTensor (wrapper of numpy array with spatial information)</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def load(self, boundless:bool=True) -&gt; geotensor.GeoTensor:\n    \"\"\"\n    Load all raster in memory in an GeoTensor object\n\n    Returns:\n        GeoTensor (wrapper of numpy array with spatial information)\n\n    \"\"\"\n    np_data = self.read(boundless=boundless)\n    if boundless:\n        transform = self.transform\n    else:\n        # update transform, shape and coords\n        window = self.window_focus\n        start_col = max(window.col_off, 0)\n        end_col = min(window.col_off + window.width, self.real_width)\n        start_row = max(window.row_off, 0)\n        end_row = min(window.row_off + window.height, self.real_height)\n        spatial_shape = (end_row - start_row, end_col - start_col)\n        assert np_data.shape[-2:] == spatial_shape, f\"Different shapes {np_data.shape[-2:]} {spatial_shape}\"\n\n        window_real = rasterio.windows.Window(row_off=start_row, col_off=start_col,\n                                              width=spatial_shape[1], height=spatial_shape[0])\n        transform = rasterio.windows.transform(window_real, self.real_transform)\n\n    return geotensor.GeoTensor(np_data, transform=transform, crs=self.crs, fill_value_default=self.fill_value_default)\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.overviews","title":"<code>overviews(index=1, time_index=0)</code>","text":"<p>Returns a list of the available overview levels for the current raster.</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def overviews(self, index:int=1, time_index:int=0) -&gt; List[int]:\n    \"\"\"\n    Returns a list of the available overview levels for the current raster.\n    \"\"\"\n    with rasterio.Env(**self._get_rio_options_path(self.paths[time_index])):\n        with rasterio.open(self.paths[time_index]) as src:\n            return src.overviews(index)\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.read","title":"<code>read(**kwargs)</code>","text":"<p>Read data from the list of rasters. It reads with boundless=True by default and fill_value=self.fill_value_default by default.</p> <p>This function is process safe (opens and closes the rasterio object every time is called).</p> <p>For arguments see: https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.read</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>if self.stack: 4D np.ndarray with shape (len(paths), C, H, W)</p> <code>ndarray</code> <p>if self.stack is False: 3D np.ndarray with shape (len(paths)*C, H, W)</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def read(self, **kwargs) -&gt; np.ndarray:\n    \"\"\"\n    Read data from the list of rasters. It reads with boundless=True by default and\n    fill_value=self.fill_value_default by default.\n\n    This function is process safe (opens and closes the rasterio object every time is called).\n\n    For arguments see: https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.read\n\n    Returns:\n        if self.stack:\n            4D np.ndarray with shape (len(paths), C, H, W)\n        if self.stack is False:\n            3D np.ndarray with shape (len(paths)*C, H, W)\n    \"\"\"\n\n    if (\"window\" in kwargs) and kwargs[\"window\"] is not None:\n        window_read = kwargs[\"window\"]\n        if isinstance(window_read, tuple):\n            window_read = rasterio.windows.Window.from_slices(*window_read,\n                                                              boundless=kwargs.get(\"boundless\", True))\n\n        # Windows are relative to the windows_focus window.\n        window = rasterio.windows.Window(col_off=window_read.col_off + self.window_focus.col_off,\n                                         row_off=window_read.row_off + self.window_focus.row_off,\n                                         height=window_read.height, width=window_read.width)\n    else:\n        window = self.window_focus\n\n    kwargs[\"window\"] = window\n\n    if \"boundless\" not in kwargs:\n        kwargs[\"boundless\"] = True\n\n    if not rasterio.windows.intersect([self.real_window, window]) and not kwargs[\"boundless\"]:\n        return None\n\n    if not kwargs[\"boundless\"]:\n        window = window.intersection(self.real_window)\n\n    if \"fill_value\" not in kwargs:\n        kwargs[\"fill_value\"] = self.fill_value_default\n\n    if  kwargs.get(\"indexes\", None) is not None:\n        # Indexes are relative to the self.indexes window.\n        indexes = kwargs[\"indexes\"]\n        if isinstance(indexes, numbers.Number):\n            n_bands_read = 1\n            kwargs[\"indexes\"] = [self.indexes[kwargs[\"indexes\"] - 1]]\n            flat_channels = True\n        else:\n            n_bands_read = len(indexes)\n            kwargs[\"indexes\"] = [self.indexes[i - 1] for i in kwargs[\"indexes\"]]\n            flat_channels = False\n    else:\n        kwargs[\"indexes\"] = self.indexes\n        n_bands_read = self.count\n        flat_channels = False\n\n    if kwargs.get(\"out_shape\", None) is not None:\n        if len(kwargs[\"out_shape\"]) == 2:\n            kwargs[\"out_shape\"] = (n_bands_read, ) + kwargs[\"out_shape\"]\n        elif len(kwargs[\"out_shape\"]) == 3:\n            assert kwargs[\"out_shape\"][0] == n_bands_read, f\"Expected to read {n_bands_read} but found out_shape: {kwargs['out_shape']}\"\n        else:\n            raise NotImplementedError(f\"Expected out_shape of len 2 or 3 found out_shape: {kwargs['out_shape']}\")\n        spatial_shape = kwargs[\"out_shape\"][1:]\n    else:\n        spatial_shape = (window.height, window.width)\n\n    shape = (len(self.paths), n_bands_read) + spatial_shape\n\n    obj_out = np.full(shape, kwargs[\"fill_value\"], dtype=self.dtype)\n    if rasterio.windows.intersect([self.real_window, window]):\n        pad = None\n        if kwargs[\"boundless\"]:\n            slice_, pad = get_slice_pad(self.real_window, window)\n            need_pad = any(x != 0 for x in pad[\"x\"] + pad[\"y\"])\n\n            #  read and pad instead of using boundless attribute when transform is not rectilinear (otherwise rasterio fails!)\n            if (abs(self.real_transform.b) &gt; 1e-6) or (abs(self.real_transform.d) &gt; 1e-6):\n                if need_pad:\n                    assert kwargs.get(\"out_shape\", None) is None, \"out_shape not compatible with boundless and non rectilinear transform!\"\n                    kwargs[\"window\"] = rasterio.windows.Window.from_slices(slice_[\"y\"], slice_[\"x\"])\n                    kwargs[\"boundless\"] = False\n                else:\n                    kwargs[\"boundless\"] = False\n            else:\n                #  if transform is rectilinear read boundless if needed\n                kwargs[\"boundless\"] = need_pad\n                pad = None\n\n        for i, p in enumerate(self.paths):\n            with rasterio.Env(**self._get_rio_options_path(p)):\n                with rasterio.open(p, \"r\", overview_level=self.overview_level) as src:\n                # rasterio.read API: https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.read\n                    read_data = src.read(**kwargs)\n\n                    # Add pad when reading\n                    if pad is not None and need_pad:\n                        slice_y = slice(pad[\"y\"][0], -pad[\"y\"][1] if pad[\"y\"][1] !=0 else None)\n                        slice_x = slice(pad[\"x\"][0], -pad[\"x\"][1] if pad[\"x\"][1] !=0 else None)\n                        obj_out[i, :, slice_y, slice_x] = read_data\n                    else:\n                        obj_out[i] = read_data\n                    # pad_list_np = _get_pad_list(pad)\n                #\n                # read_data = np.pad(read_data, tuple(pad_list_np), mode=\"constant\",\n                #                    constant_values=self.fill_value_default)\n\n\n\n    if flat_channels:\n        obj_out = obj_out[:, 0]\n\n    if not self.stack:\n        if obj_out.shape[0] == 1:\n            obj_out = obj_out[0]\n        else:\n            obj_out = np.concatenate([obj_out[i] for i in range(obj_out.shape[0])],\n                                     axis=0)\n\n    return obj_out\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.read_from_tile","title":"<code>read_from_tile(x, y, z, out_shape=(SIZE_DEFAULT, SIZE_DEFAULT), dst_crs=WEB_MERCATOR_CRS)</code>","text":"<p>Read a web mercator tile from a raster.</p> <p>Tiles are TMS tiles defined as: (https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames)</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>x coordinate of the tile in the TMS system.</p> required <code>y</code> <code>int</code> <p>y coordinate of the tile in the TMS system.</p> required <code>z</code> <code>int</code> <p>z coordinate of the tile in the TMS system.</p> required <code>out_shape</code> <code>Tuple[int, int]</code> <p>size of the tile to read. Defaults to (read.SIZE_DEFAULT, read.SIZE_DEFAULT).</p> <code>(SIZE_DEFAULT, SIZE_DEFAULT)</code> <code>dst_crs</code> <code>Optional[Any]</code> <p>CRS of the output tile. Defaults to read.WEB_MERCATOR_CRS.</p> <code>WEB_MERCATOR_CRS</code> <p>Returns:</p> Type Description <code>GeoTensor</code> <p>geotensor.GeoTensor: geotensor with the tile data.</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def read_from_tile(self, x:int, y:int, z:int, \n                   out_shape:Tuple[int,int]=(SIZE_DEFAULT, SIZE_DEFAULT),\n                   dst_crs:Optional[Any]=WEB_MERCATOR_CRS) -&gt; geotensor.GeoTensor:\n    \"\"\"\n    Read a web mercator tile from a raster.\n\n    Tiles are TMS tiles defined as: (https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames)\n\n    Args:\n        x (int): x coordinate of the tile in the TMS system.\n        y (int): y coordinate of the tile in the TMS system.\n        z (int): z coordinate of the tile in the TMS system.\n        out_shape (Tuple[int,int]: size of the tile to read. Defaults to (read.SIZE_DEFAULT, read.SIZE_DEFAULT).\n        dst_crs (Optional[Any], optional): CRS of the output tile. Defaults to read.WEB_MERCATOR_CRS.\n\n    Returns:\n        geotensor.GeoTensor: geotensor with the tile data.\n    \"\"\"\n    window = window_from_tile(self, x, y, z)\n    window = window_utils.round_outer_window(window)\n    data = read_out_shape(self, out_shape=out_shape, window=window)\n\n    if window_utils.compare_crs(self.crs, dst_crs):\n        return data\n\n    # window = window_utils.pad_window(window, (1, 1))\n    # data = read_out_shape(self, out_shape=size_out, window=window)\n\n    return read_from_tile(data, x, y, z, dst_crs=dst_crs, out_shape=out_shape)\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.read_from_window","title":"<code>read_from_window(window, boundless=True)</code>","text":"<p>Returns a new reader with window focus the window <code>window</code> relative to <code>self.window_focus</code></p> <p>Parameters:</p> Name Type Description Default <code>window</code> <code>Window</code> <p>rasterio.window.Window to read</p> required <code>boundless</code> <code>bool</code> <p>if boundless is False if the window do not overlap the total raster  it will be intersected.</p> <code>True</code> <p>Raises:</p> Type Description <code>WindowError</code> <p>if bounless is False and window does not intersects self.window_focus</p> <p>Returns:</p> Type Description <code>__class__</code> <p>New reader object</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def read_from_window(self, window:rasterio.windows.Window, boundless:bool=True) -&gt; '__class__':\n    \"\"\"\n    Returns a new reader with window focus the window `window` relative to `self.window_focus`\n\n    Args:\n        window: rasterio.window.Window to read\n        boundless: if boundless is False if the window do not overlap the total raster  it will be\n            intersected.\n\n    Raises:\n        rasterio.windows.WindowError: if bounless is False and window does not intersects self.window_focus\n\n    Returns:\n        New reader object\n    \"\"\"\n    rst_reader = RasterioReader(list(self.paths),\n                                allow_different_shape=self.allow_different_shape,\n                                window_focus=self.window_focus, fill_value_default=self.fill_value_default,\n                                stack=self.stack, overview_level=self.overview_level,\n                                check=False)\n\n    rst_reader.set_window(window, relative=True, boundless=boundless)\n    rst_reader.set_indexes(self.indexes, relative=False)\n    return rst_reader\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.same_extent","title":"<code>same_extent(other, precision=0.001)</code>","text":"<p>Check if two GeoData objects have the same extent</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Union[GeoData, RasterioReader]</code> <p>GeoData object to compare</p> required <code>precision</code> <code>float</code> <p>precision to compare the bounds</p> <code>0.001</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if both objects have the same extent</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def same_extent(self, other:Union[GeoData,'RasterioReader'], precision:float=1e-3) -&gt; bool:\n    \"\"\"\n    Check if two GeoData objects have the same extent\n\n    Args:\n        other: GeoData object to compare\n        precision: precision to compare the bounds\n\n    Returns:\n        True if both objects have the same extent\n\n    \"\"\"\n    return same_extent(self, other, precision=precision)\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.set_indexes","title":"<code>set_indexes(indexes, relative=True)</code>","text":"<p>Set the channels to read. This is useful for processing only some channels of the raster. The indexes passed will be relative to self.indexes Args:     indexes: 1-based array to mantain rasterio convention     relative: True means the indexes arg will be treated ad relative to the current self.indexes. If false              it sets self.indexes = indexes (and update the count attribute) Examples:     &gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\", indexes=[2,3,4]) # Read all bands except the first one.     &gt;&gt;&gt; r.set_indexes([2,3], relative=True) # will read bands 2 and 3 of the original raster</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def set_indexes(self, indexes:List[int], relative:bool=True)-&gt; None:\n    \"\"\"\n    Set the channels to read. This is useful for processing only some channels of the raster. The indexes\n    passed will be relative to self.indexes\n    Args:\n        indexes: 1-based array to mantain rasterio convention\n        relative: True means the indexes arg will be treated ad relative to the current self.indexes. If false\n                 it sets self.indexes = indexes (and update the count attribute)\n    Examples:\n        &gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\", indexes=[2,3,4]) # Read all bands except the first one.\n        &gt;&gt;&gt; r.set_indexes([2,3], relative=True) # will read bands 2 and 3 of the original raster\n    \"\"\"\n    if relative:\n        new_indexes = [self.indexes[idx - 1] for idx in indexes]\n    else:\n        new_indexes = indexes\n\n    # Check if indexes are valid\n    assert all((s &gt;= 1) and (s &lt;= self.real_count) for s in new_indexes), \\\n           f\"Indexes (1-based) out of real bounds current: {self.indexes} asked: {new_indexes} number of bands:{self.real_count}\"\n\n    self.indexes = new_indexes\n\n    assert all((s &gt;= 1) and (s &lt;= self.real_count) for s in\n               self.indexes), f\"Indexes out of real bounds current: {self.indexes} asked: {indexes} number of bands:{self.real_count}\"\n\n    self.count = len(self.indexes)\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.set_indexes_by_name","title":"<code>set_indexes_by_name(names)</code>","text":"<p>Function to set the indexes by the name of the band which is stored in the descriptions attribute</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>List[str]</code> <p>List of band names to read</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\") # Read all bands except the first one.\n&gt;&gt;&gt; # Assume r.descriptions = [\"B1\", \"B2\", \"B3\"]\n&gt;&gt;&gt; r.set_indexes_by_name([\"B2\", \"B3\"])\n</code></pre> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def set_indexes_by_name(self, names:List[str]) -&gt; None:\n    \"\"\"\n    Function to set the indexes by the name of the band which is stored in the descriptions attribute\n\n    Args:\n        names: List of band names to read\n\n    Examples:\n        &gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\") # Read all bands except the first one.\n        &gt;&gt;&gt; # Assume r.descriptions = [\"B1\", \"B2\", \"B3\"]\n        &gt;&gt;&gt; r.set_indexes_by_name([\"B2\", \"B3\"])\n\n    \"\"\"\n    descriptions = self.descriptions\n    if len(self.paths) == 1:\n        if self.stack:\n            descriptions = descriptions[0]\n    else:\n        assert all(d == descriptions[0] for d in descriptions), \"There are tiffs with different names\"\n        descriptions = descriptions[0]\n\n    bands = [descriptions.index(b) + 1 for b in names]\n    self.set_indexes(bands, relative=False)\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.set_window","title":"<code>set_window(window_focus=None, relative=True, boundless=True)</code>","text":"<p>Set window to read. This is useful for processing only some part of the raster. The windows passed as  arguments in the read calls will be relative to this window.</p> <p>Parameters:</p> Name Type Description Default <code>window_focus</code> <code>Optional[Window]</code> <p>rasterio window. If None will be set to the full raster tile</p> <code>None</code> <code>relative</code> <code>bool</code> <p>provided window is relative to current self.window_focus</p> <code>True</code> <code>boundless</code> <code>bool</code> <p>if boundless is false the windows that do not overlap the total raster will be intersected.</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Read the first 1000x1000 pixels of the raster\n&gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\")\n&gt;&gt;&gt; r.set_window(rasterio.windows.Window(col_off=0, row_off=0, width=1000, height=1000))\n&gt;&gt;&gt; r.load() #  returns GeoTensor with shape (1, 1, 1000, 1000)\n</code></pre> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def set_window(self, window_focus:Optional[rasterio.windows.Window] = None,\n               relative:bool = True, boundless:bool=True)-&gt;None:\n    \"\"\"\n    Set window to read. This is useful for processing only some part of the raster. The windows passed as\n     arguments in the read calls will be relative to this window.\n\n    Args:\n        window_focus: rasterio window. If None will be set to the full raster tile\n        relative: provided window is relative to current self.window_focus\n        boundless: if boundless is false the windows that do not overlap the total raster will be\n            intersected.\n\n    Examples:\n        &gt;&gt;&gt; # Read the first 1000x1000 pixels of the raster\n        &gt;&gt;&gt; r = RasterioReader(\"path/to/raster.tif\")\n        &gt;&gt;&gt; r.set_window(rasterio.windows.Window(col_off=0, row_off=0, width=1000, height=1000))\n        &gt;&gt;&gt; r.load() #  returns GeoTensor with shape (1, 1, 1000, 1000)\n\n    \"\"\"\n    if window_focus is None:\n        self.window_focus = rasterio.windows.Window(row_off=0, col_off=0,\n                                                    width=self.real_width, height=self.real_height)\n    elif relative:\n        self.window_focus = rasterio.windows.Window(col_off=window_focus.col_off + self.window_focus.col_off,\n                                                    row_off=window_focus.row_off + self.window_focus.row_off,\n                                                    height=window_focus.height, width=window_focus.width)\n    else:\n        self.window_focus = window_focus\n\n    if not boundless:\n        self.window_focus = rasterio.windows.intersection(self.real_window, self.window_focus)\n\n    self.height = self.window_focus.height\n    self.width = self.window_focus.width\n\n    self.bounds = window_bounds(self.window_focus, self.real_transform)\n    self.transform = rasterio.windows.transform(self.window_focus, self.real_transform)\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.RasterioReader.tags","title":"<code>tags()</code>","text":"<p>Returns a list with the tags for each tiff file. If stack and len(self.paths) == 1 it returns just the dictionary of the tags</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def tags(self) -&gt; Union[List[Dict[str, str]], Dict[str, str]]:\n    \"\"\"\n    Returns a list with the tags for each tiff file.\n    If stack and len(self.paths) == 1 it returns just the dictionary of the tags\n\n    \"\"\"\n    tags = []\n    for i, p in enumerate(self.paths):\n        with rasterio.Env(**self._get_rio_options_path(p)):\n            with rasterio.open(p, mode=\"r\") as src:\n                tags.append(src.tags())\n\n    if (not self.stack) and (len(tags) == 1):\n        return tags[0]\n\n    return tags\n</code></pre>"},{"location":"modules/rasterio_reader/#georeader.rasterio_reader.read_out_shape","title":"<code>read_out_shape(reader, size_read=None, indexes=None, window=None, out_shape=None, fill_value_default=0)</code>","text":"<p>Reads data using the <code>out_shape</code> param of rasterio. This allows to read from the pyramids if the file is a COG. This function returns an xarray with the data with its geographic metadata.</p> <p>Parameters:</p> Name Type Description Default <code>reader</code> <code>Union[RasterioReader, DatasetReader]</code> <p>RasterioReader, rasterio.DatasetReader</p> required <code>size_read</code> <code>Optional[int]</code> <p>if out_shape is None it uses this to compute the size to read that maintains the aspect ratio</p> <code>None</code> <code>indexes</code> <code>Optional[Union[List[int], int]]</code> <p>1-based channels to read</p> <code>None</code> <code>window</code> <code>Optional[Window]</code> <p>window to read</p> <code>None</code> <code>out_shape</code> <code>Optional[Tuple[int, int]]</code> <p>shape of the output to be readed. Conceptually, the function resizes the output to this shape</p> <code>None</code> <code>fill_value_default</code> <code>int</code> <p>if the object is rasterio.DatasetReader and nodata is None it will use this value for the corresponding GeoTensor</p> <code>0</code> <p>Returns:</p> Type Description <code>GeoTensor</code> <p>GeoTensor with geo metadata</p> Source code in <code>georeader/rasterio_reader.py</code> <pre><code>def read_out_shape(reader:Union[RasterioReader, rasterio.DatasetReader],\n                   size_read:Optional[int]=None,\n                   indexes:Optional[Union[List[int], int]]=None,\n                   window:Optional[rasterio.windows.Window]=None,\n                   out_shape:Optional[Tuple[int, int]]=None,\n                   fill_value_default:int=0) -&gt; geotensor.GeoTensor:\n    \"\"\"\n    Reads data using the `out_shape` param of rasterio. This allows to read from the pyramids if the file is a COG.\n    This function returns an xarray with the data with its geographic metadata.\n\n    Args:\n        reader: RasterioReader, rasterio.DatasetReader\n        size_read: if out_shape is None it uses this to compute the size to read that maintains the aspect ratio\n        indexes: 1-based channels to read\n        window: window to read\n        out_shape: shape of the output to be readed. Conceptually, the function resizes the output to this shape\n        fill_value_default: if the object is rasterio.DatasetReader and nodata is None it will use this value for the\n            corresponding GeoTensor\n\n    Returns:\n        GeoTensor with geo metadata\n\n    \"\"\"\n\n    if window is None:\n        shape = reader.shape[-2:]\n    else:\n        shape = window.height, window.width\n\n    if out_shape is None:\n        assert size_read is not None, f\"Both out_shape and size_read are None\"\n        out_shape = get_out_shape(shape, size_read)\n    else:\n        assert len(out_shape) == 2, f\"Expected 2 dimensions found {out_shape}\"\n\n    transform = reader.transform if window is None else rasterio.windows.transform(window, reader.transform)\n\n    if (indexes is not None) and isinstance(indexes, (list, tuple)):\n        if len(out_shape) == 2:\n            out_shape = (len(indexes),) + out_shape\n\n    input_output_factor = (shape[0] / out_shape[-2], shape[1] / out_shape[-1])    \n    transform = transform * rasterio.Affine.scale(input_output_factor[1], input_output_factor[0])\n\n    output = reader.read(indexes=indexes, out_shape=out_shape, window=window)\n\n    return geotensor.GeoTensor(output, transform=transform,\n                               crs=reader.crs, fill_value_default=getattr(reader, \"fill_value_default\",\n                                                                          reader.nodata if reader.nodata else fill_value_default))\n</code></pre>"},{"location":"modules/rasterize_module/","title":"rasterize","text":""},{"location":"modules/rasterize_module/#georeader.rasterize.rasterize_from_geometry","title":"<code>rasterize_from_geometry(geometry, bounds=None, transform=None, resolution=None, window_out=None, value=1, dtype=np.uint8, crs_geom_bounds=None, fill=0, all_touched=False, return_only_data=False)</code>","text":"<p>Rasterise the provided geometry over the bounds with the specified resolution, transform, shape and crs.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>Union[Polygon, MultiPolygon, LineString]</code> <p>geometry to rasterise (with crs <code>crs_geom_bounds</code>)</p> required <code>bounds</code> <code>Optional[Tuple[float, float, float, float]]</code> <p>bounds where the polygons will be rasterised. (with crs <code>crs_geom_bounds</code>)</p> <code>None</code> <code>transform</code> <code>Optional[Affine]</code> <p>if transform is provided it will use this instead of <code>resolution</code> (with crs <code>crs_geom_bounds</code>)</p> <code>None</code> <code>resolution</code> <code>Optional[Union[float, Tuple[float, float]]]</code> <p>spatial resolution of the rasterised array. It won't be used if transform is provided (with crs <code>crs_geom_bounds</code>)</p> <code>None</code> <code>window_out</code> <code>Optional[Window]</code> <p>Window out in <code>crs_geom_bounds</code>. If not provided it is computed from the bounds.</p> <code>None</code> <code>value</code> <code>Number</code> <p>column to take the values for rasterisation.</p> <code>1</code> <code>dtype</code> <code>Any</code> <p>dtype of the rasterise raster.</p> <code>uint8</code> <code>crs_geom_bounds</code> <code>Optional[Any]</code> <p>CRS of geometry and bounds</p> <code>None</code> <code>fill</code> <code>Union[int, float]</code> <p>fill option for <code>rasterio.features.rasterize</code>. Value for pixels not covered by the geometries.</p> <code>0</code> <code>all_touched</code> <code>bool</code> <p>all_touched option for <code>rasterio.features.rasterize</code>. If True, all pixels touched  by geometries will be burned in.  If false, only pixels whose center is within the polygon or that are selected by Bresenham's line algorithm will be burned in.</p> <code>False</code> <code>return_only_data</code> <code>bool</code> <p>if <code>True</code> returns only the np.ndarray without georref info.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[GeoTensor, ndarray]</code> <p><code>GeoTensor</code> or <code>np.ndarray</code> with shape <code>(H, W)</code> with the rasterised polygon</p> Source code in <code>georeader/rasterize.py</code> <pre><code>def rasterize_from_geometry(geometry:Union[Polygon, MultiPolygon, LineString],\n                            bounds:Optional[Tuple[float, float, float, float]]=None,\n                            transform:Optional[rasterio.Affine]=None,\n                            resolution:Optional[Union[float, Tuple[float, float]]]=None,\n                            window_out:Optional[rasterio.windows.Window]=None,\n                            value:Number=1,\n                            dtype:Any=np.uint8,\n                            crs_geom_bounds:Optional[Any]=None, fill:Union[int, float]=0, all_touched:bool=False,\n                            return_only_data:bool=False)-&gt; Union[GeoTensor, np.ndarray]:\n    \"\"\"\n    Rasterise the provided geometry over the bounds with the specified resolution, transform, shape and crs.\n\n    Args:\n        geometry: geometry to rasterise (with crs `crs_geom_bounds`)\n        bounds: bounds where the polygons will be rasterised. (with crs `crs_geom_bounds`)\n        transform: if transform is provided it will use this instead of `resolution` (with crs `crs_geom_bounds`)\n        resolution: spatial resolution of the rasterised array. It won't be used if transform is provided (with crs `crs_geom_bounds`)\n        window_out: Window out in `crs_geom_bounds`. If not provided it is computed from the bounds.\n        value: column to take the values for rasterisation.\n        dtype: dtype of the rasterise raster.\n        crs_geom_bounds: CRS of geometry and bounds\n        fill: fill option for `rasterio.features.rasterize`. Value for pixels not covered by the geometries.\n        all_touched: all_touched option for `rasterio.features.rasterize`. If True, all pixels touched \n            by geometries will be burned in.  If false, only pixels whose center is within the polygon or that\n            are selected by Bresenham's line algorithm will be burned in.\n        return_only_data: if `True` returns only the np.ndarray without georref info.\n\n    Returns:\n        `GeoTensor` or `np.ndarray` with shape `(H, W)` with the rasterised polygon\n    \"\"\"\n\n    transform = window_utils.figure_out_transform(transform=transform, bounds=bounds,\n                                                  resolution_dst=resolution)\n    if window_out is None:\n        window_out = rasterio.windows.from_bounds(*bounds,\n                                                  transform=transform).round_lengths(op=\"ceil\",\n                                                                                     pixel_precision=PIXEL_PRECISION)\n\n\n    chip_label = rasterio.features.rasterize(shapes=[(geometry, value)],\n                                             out_shape=(window_out.height, window_out.width),\n                                             transform=transform,\n                                             dtype=dtype,\n                                             fill=fill,\n                                             all_touched=all_touched)\n    if return_only_data:\n        return chip_label\n\n    return GeoTensor(chip_label, transform=transform, crs=crs_geom_bounds, fill_value_default=fill)\n</code></pre>"},{"location":"modules/rasterize_module/#georeader.rasterize.rasterize_from_geopandas","title":"<code>rasterize_from_geopandas(dataframe, column, bounds=None, transform=None, window_out=None, resolution=None, crs_out=None, fill=0, all_touched=False, return_only_data=False)</code>","text":"<p>Rasterise the provided geodataframe over the bounds with the specified resolution.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>GeoDataFrame</code> <p><code>GeoDataFrame</code> with columns <code>geometry</code> and <code>column</code>.  The 'geometry' column is expected to have shapely geometries.</p> required <code>bounds</code> <code>Optional[Tuple[float, float, float, float]]</code> <p>bounds where the polygons will be rasterised with CRS <code>crs_out</code>.</p> <code>None</code> <code>transform</code> <code>Optional[Affine]</code> <p>if transform is provided if will use this for the resolution.</p> <code>None</code> <code>resolution</code> <code>Optional[Union[float, Tuple[float, float]]]</code> <p>spatial resolution of the rasterised array</p> <code>None</code> <code>window_out</code> <code>Optional[Window]</code> <p>Window out in <code>crs_geom_bounds</code>. If not provided it is computed from the bounds.</p> <code>None</code> <code>column</code> <code>str</code> <p>column to take the values for rasterisation.</p> required <code>crs_out</code> <code>Optional[Any]</code> <p>defaults to dataframe.crs. This function will transform the geometries from dataframe.crs to this crs before rasterisation. <code>bounds</code> are in this crs.</p> <code>None</code> <code>fill</code> <code>Union[int, float]</code> <p>fill option for <code>rasterio.features.rasterize</code>. Value for pixels not covered by the geometries.</p> <code>0</code> <code>all_touched</code> <code>bool</code> <p>all_touched option for <code>rasterio.features.rasterize</code>. If True, all pixels touched  by geometries will be burned in.  If false, only pixels whose center is within the polygon or that are selected by Bresenham's line algorithm will be burned in.</p> <code>False</code> <code>return_only_data</code> <code>bool</code> <p>if <code>True</code> returns only the <code>np.ndarray</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[GeoTensor, ndarray]</code> <p><code>GeoTensor</code> or <code>np.ndarray</code> with shape <code>(H, W)</code> with the rasterised polygons of the dataframe</p> Source code in <code>georeader/rasterize.py</code> <pre><code>def rasterize_from_geopandas(dataframe:gpd.GeoDataFrame,\n                             column:str,\n                             bounds:Optional[Tuple[float, float, float, float]]=None,\n                             transform:Optional[rasterio.Affine]=None,\n                             window_out:Optional[rasterio.windows.Window]=None,\n                             resolution:Optional[Union[float, Tuple[float, float]]]=None,\n                             crs_out:Optional[Any]=None, fill:Union[int, float]=0, all_touched:bool=False,\n                             return_only_data:bool=False) -&gt; Union[GeoTensor, np.ndarray]:\n    \"\"\"\n    Rasterise the provided geodataframe over the bounds with the specified resolution.\n\n    Args:\n        dataframe: `GeoDataFrame` with columns `geometry` and `column`. \n            The 'geometry' column is expected to have shapely geometries.\n        bounds: bounds where the polygons will be rasterised with CRS `crs_out`.\n        transform: if transform is provided if will use this for the resolution.\n        resolution: spatial resolution of the rasterised array\n        window_out: Window out in `crs_geom_bounds`. If not provided it is computed from the bounds.\n        column: column to take the values for rasterisation.\n        crs_out: defaults to dataframe.crs. This function will transform the geometries from dataframe.crs to this crs\n            before rasterisation. `bounds` are in this crs.\n        fill: fill option for `rasterio.features.rasterize`. Value for pixels not covered by the geometries.\n        all_touched: all_touched option for `rasterio.features.rasterize`. If True, all pixels touched \n            by geometries will be burned in.  If false, only pixels whose center is within the polygon or that\n            are selected by Bresenham's line algorithm will be burned in.\n        return_only_data: if `True` returns only the `np.ndarray`.\n\n    Returns:\n        `GeoTensor` or `np.ndarray` with shape `(H, W)` with the rasterised polygons of the dataframe\n    \"\"\"\n\n    if crs_out is None:\n        crs_out = str(dataframe.crs).lower()\n    else:\n        data_crs = str(dataframe.crs).lower()\n        crs_out = str(crs_out).lower().replace(\"+init=\",\"\")\n        if data_crs != crs_out:\n            dataframe = dataframe.to_crs(crs=crs_out)\n\n    transform = window_utils.figure_out_transform(transform=transform, bounds=bounds,\n                                                  resolution_dst=resolution)\n    if window_out is None:\n        window_out = rasterio.windows.from_bounds(*bounds,\n                                                  transform=transform).round_lengths(op=\"ceil\",\n                                                                                     pixel_precision=PIXEL_PRECISION)\n\n    dtype = dataframe[column].dtype\n    chip_label = rasterio.features.rasterize(shapes=zip(dataframe.geometry, dataframe[column]),\n                                             out_shape=(window_out.height, window_out.width),\n                                             transform=transform,\n                                             dtype=dtype,\n                                             fill=fill,\n                                             all_touched=all_touched)\n    if return_only_data:\n        return chip_label\n\n    return GeoTensor(chip_label, transform=transform, crs=crs_out, fill_value_default=fill)\n</code></pre>"},{"location":"modules/rasterize_module/#georeader.rasterize.rasterize_geometry_like","title":"<code>rasterize_geometry_like(geometry, data_like, value=1, dtype=np.uint8, crs_geometry=None, fill=0, all_touched=False, return_only_data=False)</code>","text":"<p>Rasterise the <code>geometry</code> to the same extent and resolution as defined <code>data_like</code> GeoData object.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>Union[Polygon, MultiPolygon, LineString]</code> <p>geometry to rasterise</p> required <code>data_like</code> <code>GeoData</code> <p>geoData to use transform, bounds and crs for rasterisation. Output raster will have the same extent, resolution, crs and shape as this object.</p> required <code>value</code> <code>Number</code> <p>value to use in the points within the geometry</p> <code>1</code> <code>dtype</code> <code>Any</code> <p>dtype of the rasterised raster.</p> <code>uint8</code> <code>crs_geometry</code> <code>Optional[Any]</code> <p>CRS of geometry</p> <code>None</code> <code>fill</code> <code>Union[int, float]</code> <p>fill option for <code>rasterio.features.rasterize</code>. Value for pixels not covered by the geometries.</p> <code>0</code> <code>all_touched</code> <code>bool</code> <p>all_touched option for <code>rasterio.features.rasterize</code>. If True, all pixels touched  by geometries will be burned in.  If false, only pixels whose center is within the polygon or that are selected by Bresenham's line algorithm will be burned in.</p> <code>False</code> <code>return_only_data</code> <code>bool</code> <p>if <code>True</code> returns only the <code>np.ndarray</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[GeoTensor, ndarray]</code> <p><code>GeoTensor</code> or <code>np.ndarray</code> with shape <code>(H, W)</code> with the rasterised polygon</p> Source code in <code>georeader/rasterize.py</code> <pre><code>def rasterize_geometry_like(geometry:Union[Polygon, MultiPolygon, LineString], \n                            data_like: GeoData, value:Number=1,\n                            dtype:Any=np.uint8,\n                            crs_geometry:Optional[Any]=None, fill:Union[int, float]=0, all_touched:bool=False,\n                            return_only_data:bool=False)-&gt; Union[GeoTensor, np.ndarray]:\n    \"\"\"\n    Rasterise the `geometry` to the same extent and resolution as defined `data_like` GeoData object.\n\n    Args:\n        geometry: geometry to rasterise\n        data_like: geoData to use transform, bounds and crs for rasterisation. Output\n            raster will have the same extent, resolution, crs and shape as this object.\n        value: value to use in the points within the geometry\n        dtype: dtype of the rasterised raster.\n        crs_geometry: CRS of geometry\n        fill: fill option for `rasterio.features.rasterize`. Value for pixels not covered by the geometries.\n        all_touched: all_touched option for `rasterio.features.rasterize`. If True, all pixels touched \n            by geometries will be burned in.  If false, only pixels whose center is within the polygon or that\n            are selected by Bresenham's line algorithm will be burned in.\n        return_only_data: if `True` returns only the `np.ndarray`.\n\n    Returns:\n        `GeoTensor` or `np.ndarray` with shape `(H, W)` with the rasterised polygon\n    \"\"\"\n    shape_out = data_like.shape\n    if crs_geometry and not window_utils.compare_crs(data_like.crs, crs_geometry):\n        geometry = window_utils.polygon_to_crs(geometry, crs_geometry, data_like.crs)\n\n    return rasterize_from_geometry(geometry, crs_geom_bounds=data_like.crs,\n                                   transform=data_like.transform,\n                                   window_out=rasterio.windows.Window(0, 0, width=shape_out[-1], height=shape_out[-2]),\n                                   return_only_data=return_only_data,dtype=dtype, value=value,\n                                   fill=fill, all_touched=all_touched)\n</code></pre>"},{"location":"modules/rasterize_module/#georeader.rasterize.rasterize_geopandas_like","title":"<code>rasterize_geopandas_like(dataframe, data_like, column, fill=0, all_touched=False, return_only_data=False)</code>","text":"<p>Rasterise the geodataframe to the same extent and resolution as defined <code>data_like</code> GeoData object</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>GeoDataFrame</code> <p><code>GeoDataFrame</code> with columns <code>geometry</code> and <code>column</code>.  The 'geometry' column is expected to have shapely geometries.</p> required <code>data_like</code> <code>GeoData</code> <p>geoData to use transform, bounds and crs for rasterisation</p> required <code>column</code> <code>str</code> <p>column to take the values for rasterisation.</p> required <code>fill</code> <code>Union[int, float]</code> <p>fill option for <code>rasterio.features.rasterize</code>. Value for pixels not covered by the geometries.</p> <code>0</code> <code>all_touched</code> <code>bool</code> <p>all_touched option for <code>rasterio.features.rasterize</code>. If True, all pixels touched  by geometries will be burned in.  If false, only pixels whose center is within the polygon or that are selected by Bresenham's line algorithm will be burned in.</p> <code>False</code> <code>return_only_data</code> <code>bool</code> <p>if <code>True</code> returns only the <code>np.ndarray</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[GeoTensor, ndarray]</code> <p><code>GeoTensor</code> or <code>np.ndarray</code> with shape (H, W) with the rasterised polygons of the dataframe</p> Source code in <code>georeader/rasterize.py</code> <pre><code>def rasterize_geopandas_like(dataframe:gpd.GeoDataFrame,data_like: GeoData, column:str,\n                             fill:Union[int, float]=0, all_touched:bool=False,\n                             return_only_data:bool=False)-&gt; Union[GeoTensor, np.ndarray]:\n    \"\"\"\n    Rasterise the geodataframe to the same extent and resolution as defined `data_like` GeoData object\n\n    Args:\n        dataframe: `GeoDataFrame` with columns `geometry` and `column`. \n            The 'geometry' column is expected to have shapely geometries.\n        data_like: geoData to use transform, bounds and crs for rasterisation\n        column: column to take the values for rasterisation.\n        fill: fill option for `rasterio.features.rasterize`. Value for pixels not covered by the geometries.\n        all_touched: all_touched option for `rasterio.features.rasterize`. If True, all pixels touched \n            by geometries will be burned in.  If false, only pixels whose center is within the polygon or that\n            are selected by Bresenham's line algorithm will be burned in.\n        return_only_data: if `True` returns only the `np.ndarray`.\n\n    Returns:\n        `GeoTensor` or `np.ndarray` with shape (H, W) with the rasterised polygons of the dataframe\n\n    \"\"\"\n\n    shape_out = data_like.shape\n    return rasterize_from_geopandas(dataframe, column=column,\n                                    crs_out=data_like.crs,\n                                    transform=data_like.transform,\n                                    window_out=rasterio.windows.Window(0, 0, width=shape_out[-1], height=shape_out[-2]),\n                                    return_only_data=return_only_data,\n                                    fill=fill, all_touched=all_touched)\n</code></pre>"},{"location":"modules/read_module/","title":"read","text":""},{"location":"modules/read_module/#georeader.read.read_from_center_coords","title":"<code>read_from_center_coords(data_in, center_coords, shape, crs_center_coords=None, return_only_data=False, trigger_load=False, boundless=True)</code>","text":"<p>Returns a chip of <code>data_in</code> centered on <code>center_coords</code> of shape <code>shape</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>GeoData</code> <p>GeoData object</p> required <code>center_coords</code> <code>Tuple[float, float]</code> <p>x, y tuple of coords in <code>data_in</code> crs.</p> required <code>shape</code> <code>Tuple[int, int]</code> <p>shape of the window to read</p> required <code>crs_center_coords</code> <code>Optional[Any]</code> <p>CRS of center coords. If provided will check if it needs to reproject the coords before computing the reading window.</p> <code>None</code> <code>return_only_data</code> <code>bool</code> <p>defaults to <code>False</code>. If <code>True</code> it returns a np.ndarray otherwise returns an GeoData georreferenced object.</p> <code>False</code> <code>trigger_load</code> <code>bool</code> <p>defaults to <code>False</code>. Trigger loading the data to memory.</p> <code>False</code> <code>boundless</code> <code>bool</code> <p>if <code>True</code> data read will always have the shape of the provided window (padding with <code>fill_value_default</code>)</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[GeoData, ndarray]</code> <p>GeoData or np.array sliced from <code>data_in</code> of shape <code>shape</code>.</p> Source code in <code>georeader/read.py</code> <pre><code>def read_from_center_coords(data_in: GeoData, center_coords:Tuple[float, float], shape:Tuple[int,int],\n                            crs_center_coords:Optional[Any]=None,\n                            return_only_data:bool=False, trigger_load:bool=False,\n                            boundless:bool=True) -&gt; Union[GeoData, np.ndarray]:\n    \"\"\"\n    Returns a chip of `data_in` centered on `center_coords` of shape `shape`.\n\n    Args:\n        data_in: GeoData object\n        center_coords: x, y tuple of coords in `data_in` crs.\n        shape: shape of the window to read\n        crs_center_coords: CRS of center coords. If provided will check if it needs to reproject the coords before\n            computing the reading window.\n        return_only_data: defaults to `False`. If `True` it returns a np.ndarray otherwise\n            returns an GeoData georreferenced object.\n        trigger_load: defaults to `False`. Trigger loading the data to memory.\n        boundless: if `True` data read will always have the shape of the provided window\n            (padding with `fill_value_default`)\n\n    Returns:\n        GeoData or np.array sliced from `data_in` of shape `shape`.\n\n    \"\"\"\n\n    window = window_from_center_coords(data_in, center_coords, shape, crs_center_coords)\n\n    return read_from_window(data_in, window=window, return_only_data=return_only_data,\n                            trigger_load=trigger_load, boundless=boundless)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.read_from_bounds","title":"<code>read_from_bounds(data_in, bounds, crs_bounds=None, pad_add=(0, 0), return_only_data=False, trigger_load=False, boundless=True)</code>","text":"<p>Reads a slice of data_in covering the <code>bounds</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>GeoData</code> <p>GeoData with geographic info (crs and geotransform).</p> required <code>bounds</code> <code>Tuple[float, float, float, float]</code> <p>bounding box to read.</p> required <code>crs_bounds</code> <code>Optional[str]</code> <p>if not None will transform the bounds from that crs to the <code>data.crs</code> to read the chip.</p> <code>None</code> <code>pad_add</code> <code>Tuple[int, int]</code> <p>Tuple[int, int]. Pad in pixels to add to the <code>window</code> that is read.This is useful when this function is called for interpolation/CNN prediction.</p> <code>(0, 0)</code> <code>return_only_data</code> <code>bool</code> <p>defaults to <code>False</code>. If <code>True</code> it returns a np.ndarray otherwise returns an GeoData georreferenced object.</p> <code>False</code> <code>trigger_load</code> <code>bool</code> <p>defaults to <code>False</code>. Trigger loading the data to memory.</p> <code>False</code> <code>boundless</code> <code>bool</code> <p>if <code>True</code> data read will always have the shape of the provided window (padding with <code>fill_value_default</code>)</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[GeoData, ndarray]</code> <p>sliced GeoData</p> Source code in <code>georeader/read.py</code> <pre><code>def read_from_bounds(data_in: GeoData, bounds: Tuple[float, float, float, float],\n                     crs_bounds: Optional[str] = None, pad_add:Tuple[int, int]=(0, 0),\n                     return_only_data: bool = False, trigger_load: bool = False,\n                     boundless: bool = True) -&gt; Union[GeoData, np.ndarray]:\n    \"\"\"\n    Reads a slice of data_in covering the `bounds`.\n\n    Args:\n        data_in: GeoData with geographic info (crs and geotransform).\n        bounds:  bounding box to read.\n        crs_bounds: if not None will transform the bounds from that crs to the `data.crs` to read the chip.\n        pad_add: Tuple[int, int]. Pad in pixels to add to the `window` that is read.This is useful when this function is called for\n            interpolation/CNN prediction.\n        return_only_data: defaults to `False`. If `True` it returns a np.ndarray otherwise\n            returns an GeoData georreferenced object.\n        trigger_load: defaults to `False`. Trigger loading the data to memory.\n        boundless: if `True` data read will always have the shape of the provided window\n            (padding with `fill_value_default`)\n\n    Returns:\n        sliced GeoData\n    \"\"\"\n    window_in = window_from_bounds(data_in, bounds, crs_bounds)\n    if any(p &gt; 0 for p in pad_add):\n        window_in = pad_window(window_in, pad_add)  # Add padding for bicubic int or for co-registration\n    window_in = round_outer_window(window_in)\n\n    return read_from_window(data_in, window_in, return_only_data=return_only_data, trigger_load=trigger_load,\n                            boundless=boundless)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.read_from_polygon","title":"<code>read_from_polygon(data_in, polygon, crs_polygon=None, pad_add=(0, 0), return_only_data=False, trigger_load=False, boundless=True, window_surrounding=False)</code>","text":"<p>Reads a slice of data_in covering the <code>polygon</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>GeoData</code> <p>GeoData with geographic info (crs and geotransform).</p> required <code>polygon</code> <code>Union[Polygon, MultiPolygon]</code> <p>Polygon or MultiPolygon that specifies the region to read.</p> required <code>crs_polygon</code> <code>Optional[str]</code> <p>if not None will transform the polygon from that crs to the data.crs to read the chip.</p> <code>None</code> <code>pad_add</code> <code>Tuple[int, int]</code> <p>pad in pixels to add to the <code>window</code> that is read.This is useful when this function is called for interpolation/CNN prediction.</p> <code>(0, 0)</code> <code>return_only_data</code> <code>bool</code> <p>defaults to <code>False</code>. If <code>True</code> it returns a np.ndarray otherwise returns an GeoData georreferenced object.</p> <code>False</code> <code>trigger_load</code> <code>bool</code> <p>defaults to <code>False</code>. Trigger loading the data to memory.</p> <code>False</code> <code>boundless</code> <code>bool</code> <p>if <code>True</code> data read will always have the shape of the provided window (padding with <code>fill_value_default</code>)</p> <code>True</code> <code>window_surrounding</code> <code>bool</code> <p>The window surrounds the polygon. (i.e. <code>window.row_off</code> + <code>window.height</code> will not be a vertex)</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[GeoData, ndarray]</code> <p>sliced GeoData</p> Source code in <code>georeader/read.py</code> <pre><code>def read_from_polygon(data_in: GeoData, polygon: Union[Polygon, MultiPolygon],\n                      crs_polygon: Optional[str] = None, pad_add:Tuple[int, int]=(0, 0),\n                      return_only_data: bool = False, trigger_load: bool = False,\n                      boundless: bool = True, window_surrounding:bool=False) -&gt; Union[GeoData, np.ndarray]:\n    \"\"\"\n    Reads a slice of data_in covering the `polygon`.\n\n    Args:\n        data_in: GeoData with geographic info (crs and geotransform).\n        polygon: Polygon or MultiPolygon that specifies the region to read.\n        crs_polygon: if not None will transform the polygon from that crs to the data.crs to read the chip.\n        pad_add: pad in pixels to add to the `window` that is read.This is useful when this function is called for\n            interpolation/CNN prediction.\n        return_only_data: defaults to `False`. If `True` it returns a np.ndarray otherwise\n            returns an GeoData georreferenced object.\n        trigger_load: defaults to `False`. Trigger loading the data to memory.\n        boundless: if `True` data read will always have the shape of the provided window\n            (padding with `fill_value_default`)\n        window_surrounding: The window surrounds the polygon. (i.e. `window.row_off` + `window.height` will not be a vertex)\n\n    Returns:\n        sliced GeoData\n    \"\"\"\n    window_in = window_from_polygon(data_in, polygon, crs_polygon, \n                                    window_surrounding=window_surrounding)\n    if any(p &gt; 0 for p in pad_add):\n        window_in = pad_window(window_in, pad_add)  # Add padding for bicubic int or for co-registration\n    window_in = round_outer_window(window_in)\n\n    return read_from_window(data_in, window_in, return_only_data=return_only_data, \n                            trigger_load=trigger_load,\n                            boundless=boundless)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.read_from_window","title":"<code>read_from_window(data_in, window, return_only_data=False, trigger_load=False, boundless=True)</code>","text":"<p>Reads a window from data_in padding with <code>data_in.fill_value_default</code> if needed  (output GeoData will have <code>window.height</code>, <code>window.width</code> shape if boundless is <code>True</code>).</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>GeoData</code> <p>GeoData with \"x\" and \"y\" coordinates</p> required <code>window</code> <code>Window</code> <p>window to slice the GeoData with.</p> required <code>return_only_data</code> <code>bool</code> <p>defaults to <code>False</code>. If <code>True</code> it returns a np.ndarray otherwise returns an GeoData georreferenced object.</p> <code>False</code> <code>trigger_load</code> <code>bool</code> <p>defaults to <code>False</code>. Trigger loading the data to memory.</p> <code>False</code> <code>boundless</code> <code>bool</code> <p>if <code>True</code> data read will always have the shape of the provided window (padding with <code>fill_value_default</code>)</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[GeoData, ndarray, None]</code> <p>GeoData object</p> Source code in <code>georeader/read.py</code> <pre><code>def read_from_window(data_in: GeoData,\n                     window: rasterio.windows.Window, return_only_data: bool = False,\n                     trigger_load: bool = False,\n                     boundless: bool = True) -&gt; Union[GeoData, np.ndarray, None]:\n    \"\"\"\n    Reads a window from data_in padding with `data_in.fill_value_default` if needed \n    (output GeoData will have `window.height`, `window.width` shape if boundless is `True`).\n\n    Args:\n        data_in: GeoData with \"x\" and \"y\" coordinates\n        window: window to slice the GeoData with.\n        return_only_data: defaults to `False`. If `True` it returns a np.ndarray otherwise\n            returns an GeoData georreferenced object.\n        trigger_load: defaults to `False`. Trigger loading the data to memory.\n        boundless: if `True` data read will always have the shape of the provided window\n            (padding with `fill_value_default`)\n\n    Returns:\n        GeoData object\n    \"\"\"\n\n    named_shape = OrderedDict(zip(data_in.dims, data_in.shape))\n\n    window_data = rasterio.windows.Window(col_off=0, row_off=0,\n                                          width=named_shape[\"x\"], height=named_shape[\"y\"])\n\n    # get transform of current window\n    transform = data_in.transform\n\n    # Case the window does not intersect the data\n    if not rasterio.windows.intersect([window_data, window]):\n        if not boundless:\n            return None\n\n        expected_shapes = {\"x\": window.width, \"y\": window.height}\n        shape = tuple([named_shape[s] if s not in [\"x\", \"y\"] else expected_shapes[s] for s in data_in.dims])\n        data = np.zeros(shape, dtype=data_in.dtype)\n        fill_value_default = getattr(data_in, \"fill_value_default\", 0)\n        if fill_value_default != 0:\n            data += fill_value_default\n        if return_only_data:\n            return data\n\n        return GeoTensor(data, crs=data_in.crs,\n                         transform=rasterio.windows.transform(window, transform=transform),\n                         fill_value_default=fill_value_default)\n\n    # Read data directly with rasterio (handles automatically the padding)\n    data_sel = data_in.read_from_window(window=window, boundless=boundless)\n\n    if return_only_data:\n        return data_sel.values\n\n    if trigger_load:\n        data_sel = data_sel.load()\n\n    return data_sel\n</code></pre>"},{"location":"modules/read_module/#georeader.read.read_from_tile","title":"<code>read_from_tile(data, x, y, z, dst_crs=WEB_MERCATOR_CRS, out_shape=(SIZE_DEFAULT, SIZE_DEFAULT), resolution_dst_crs=None, assert_if_not_intersects=False)</code>","text":"<p>Read a web mercator tile from a GeoData object. Tiles are TMS tiles defined as: (https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>GeoData</code> <p>GeoData object</p> required <code>x</code> <code>int</code> <p>x. x coordinate of the tile in the TMS system.</p> required <code>y</code> <code>int</code> <p>y. y coordinate of the tile in the TMS system.</p> required <code>z</code> <code>int</code> <p>z. zoom level</p> required <code>dst_crs</code> <code>Optional[Any]</code> <p>output crs. Defaults to WEB_MERCATOR_CRS. If None uses the crs of data.</p> <code>WEB_MERCATOR_CRS</code> <code>out_shape</code> <code>Optional[Tuple[int, int]]</code> <p>output size. Defaults to (SIZE_DEFAULT, SIZE_DEFAULT). If None it will be the size of the tile in the input resolution.</p> <code>(SIZE_DEFAULT, SIZE_DEFAULT)</code> <code>resolution_dst_crs</code> <code>Optional[Union[float, Tuple[float, float]]]</code> <p>output resolution. Defaults to None.  If out_shape is not None it will be ignored. If None and out_shape is None the output will be at the resolution of the input data.</p> <code>None</code> <code>assert_if_not_intersects</code> <code>bool</code> <p>If True it will raise an error if the tile does not intersect the data. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>Optional[GeoTensor]</code> <p>GeoTensor covering the tile or None if the tile does not intersect the data.</p> Source code in <code>georeader/read.py</code> <pre><code>def read_from_tile(data:GeoData, x:int, y:int, z:int, dst_crs:Optional[Any]=WEB_MERCATOR_CRS, \n                   out_shape:Optional[Tuple[int,int]]=(SIZE_DEFAULT, SIZE_DEFAULT), \n                   resolution_dst_crs:Optional[Union[float, Tuple[float, float]]]=None,\n                   assert_if_not_intersects:bool=False) -&gt; Optional[GeoTensor]:\n    \"\"\"\n    Read a web mercator tile from a GeoData object. Tiles are TMS tiles defined as: (https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames)\n\n    Args:\n        data (GeoData): GeoData object\n        x (int): x. x coordinate of the tile in the TMS system.\n        y (int): y. y coordinate of the tile in the TMS system.\n        z (int): z. zoom level\n        dst_crs (Optional[Any], optional): output crs. Defaults to WEB_MERCATOR_CRS. If None uses the crs of data.\n        out_shape (Optional[Tuple[int,int]], optional): output size. Defaults to (SIZE_DEFAULT, SIZE_DEFAULT). If None it will be the size\n            of the tile in the input resolution.\n        resolution_dst_crs (Optional[Union[float, Tuple[float, float]]], optional): output resolution. Defaults to None. \n            If out_shape is not None it will be ignored. If None and out_shape is None the output will be at the resolution of the input data.\n        assert_if_not_intersects (bool, optional): If True it will raise an error if the tile does not intersect the data. Defaults to False.\n\n    Returns:\n        GeoTensor: GeoTensor covering the tile or None if the tile does not intersect the data.\n    \"\"\"\n    bounds_wgs = mercantile.xy_bounds(int(x), int(y), int(z))\n    polygon_crs_webmercator = box(bounds_wgs.left, bounds_wgs.bottom, bounds_wgs.right, bounds_wgs.top)\n\n    intersects = polygon_crs_webmercator.intersects(data.footprint(crs=WEB_MERCATOR_CRS))\n\n    if not intersects:\n        assert not assert_if_not_intersects, \"Tile does not intersect data\"\n    else:\n        return\n\n    if out_shape is not None and hasattr(data, \"read_from_tile\"):\n        return data.read_from_tile(x, y, z, dst_crs=dst_crs, out_shape=out_shape)\n\n    if dst_crs is None:\n        dst_crs = data.crs\n\n    if window_utils.compare_crs(data.crs, dst_crs) and (out_shape is None) and (resolution_dst_crs is None):\n        # read from polygon handles the case where the data does not intersect the polygon\n        return read_from_polygon(data, polygon_crs_webmercator, WEB_MERCATOR_CRS, window_surrounding=True).load()\n\n    if out_shape is not None:\n        polygon_crs_dst = window_utils.polygon_to_crs(polygon_crs_webmercator, WEB_MERCATOR_CRS, dst_crs)\n        bounds_dst = polygon_crs_dst.bounds\n        dst_transform = rasterio.transform.from_bounds(*bounds_dst, \n                                                       width=out_shape[1], height=out_shape[0])\n        window_data = rasterio.windows.Window(0, 0, width=out_shape[1], height=out_shape[0])\n    else:\n        if resolution_dst_crs is not None:\n            if isinstance(resolution_dst_crs, numbers.Number):\n                resolution_dst_crs = (abs(resolution_dst_crs), abs(resolution_dst_crs))\n\n        polygon_crs_data = window_utils.polygon_to_crs(polygon_crs_webmercator, WEB_MERCATOR_CRS, data.crs)\n        bounds_crs_data = polygon_crs_data.bounds\n\n        in_height, in_width = data.shape[-2:]\n        dst_transform, width, height = rasterio.warp.calculate_default_transform(data.crs, dst_crs, in_width, in_height, *bounds_crs_data,\n                                                                                resolution=resolution_dst_crs)\n        window_data = rasterio.windows.Window(0,0, width=width, height=height)\n        dst_transform, window_data = calculate_transform_window(data, dst_crs, resolution_dst_crs)\n\n    return read_reproject(data, dst_crs=dst_crs, dst_transform=dst_transform, \n                          window_out=window_data)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.read_to_crs","title":"<code>read_to_crs(data_in, dst_crs, resampling=rasterio.warp.Resampling.cubic_spline, resolution_dst_crs=None, return_only_data=False)</code>","text":"<p>Change the crs of data_in to dst_crs. This function is a wrapper of the <code>read_reproject</code> function</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>GeoData</code> <p>GeoData to reproyect</p> required <code>dst_crs</code> <code>Any</code> <p>dst crs</p> required <code>return_only_data</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[GeoTensor, ndarray]</code> <p>Union[GeoTensor, np.ndarray]: data in dst_crs</p> Source code in <code>georeader/read.py</code> <pre><code>def read_to_crs(data_in:GeoData, dst_crs:Any, \n                resampling:rasterio.warp.Resampling = rasterio.warp.Resampling.cubic_spline,\n                resolution_dst_crs:Optional[Union[float, Tuple[float, float]]]=None,\n                return_only_data: bool = False)-&gt; Union[GeoTensor, np.ndarray]:\n    \"\"\"\n    Change the crs of data_in to dst_crs. This function is a wrapper of the `read_reproject` function\n\n    Args:\n        data_in (GeoData): GeoData to reproyect\n        dst_crs (Any): dst crs\n        return_only_data (bool, optional): Defaults to False.\n\n    Returns:\n        Union[GeoTensor, np.ndarray]: data in dst_crs\n    \"\"\"\n    if window_utils.compare_crs(data_in.crs, dst_crs):\n        return data_in\n\n    window_data, dst_transform = calculate_transform_window(data_in, dst_crs, resolution_dst_crs)\n\n\n    return read_reproject(data_in, dst_crs=dst_crs,\n                          dst_transform=dst_transform,\n                          window_out=window_data,\n                          resampling=resampling, return_only_data=return_only_data)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.read_reproject_like","title":"<code>read_reproject_like(data_in, data_like, resolution_dst=None, resampling=rasterio.warp.Resampling.cubic_spline, dtype_dst=None, return_only_data=False, dst_nodata=None)</code>","text":"<p>Reads from <code>data_in</code> and reprojects to have the same extent and resolution than <code>data_like</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>GeoData</code> <p>GeoData to read and reproject. Expected coords \"x\" and \"y\".</p> required <code>data_like</code> <code>GeoData</code> <p>GeoData to get the bounds and resolution to reproject <code>data_in</code>.</p> required <code>resampling</code> <code>Resampling</code> <p>specifies how data is reprojected from <code>rasterio.warp.Resampling</code>.</p> <code>cubic_spline</code> <code>resolution_dst</code> <code>Optional[Union[float, Tuple[float, float]]]</code> <p>if not None it will overwrite the resolution of <code>data_like</code>.</p> <code>None</code> <code>dtype_dst</code> <code>Any</code> <p>if None it will be inferred</p> <code>None</code> <code>return_only_data</code> <code>bool</code> <p>defaults to <code>False</code>. If <code>True</code> it returns a np.ndarray otherwise returns an GeoTensor object (georreferenced array).</p> <code>False</code> <code>dst_nodata</code> <code>Optional[int]</code> <p>dst_nodata value</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[GeoTensor, ndarray]</code> <p>GeoTensor read from <code>data_in</code> with same transform, crs, shape and bounds than <code>data_like</code>.</p> Source code in <code>georeader/read.py</code> <pre><code>def read_reproject_like(data_in: GeoData, data_like: GeoData,\n                        resolution_dst:Optional[Union[float, Tuple[float, float]]]=None,\n                        resampling: rasterio.warp.Resampling = rasterio.warp.Resampling.cubic_spline,\n                        dtype_dst:Any=None, return_only_data: bool = False,\n                        dst_nodata: Optional[int] = None) -&gt; Union[GeoTensor, np.ndarray]:\n    \"\"\"\n    Reads from `data_in` and reprojects to have the same extent and resolution than `data_like`.\n\n    Args:\n        data_in: GeoData to read and reproject. Expected coords \"x\" and \"y\".\n        data_like: GeoData to get the bounds and resolution to reproject `data_in`.\n        resampling: specifies how data is reprojected from `rasterio.warp.Resampling`.\n        resolution_dst: if not None it will overwrite the resolution of `data_like`.\n        dtype_dst: if None it will be inferred\n        return_only_data: defaults to `False`. If `True` it returns a np.ndarray otherwise\n            returns an GeoTensor object (georreferenced array).\n        dst_nodata: dst_nodata value\n\n    Returns:\n        GeoTensor read from `data_in` with same transform, crs, shape and bounds than `data_like`.\n    \"\"\"\n\n    shape_out = data_like.shape[-2:]\n    if resolution_dst is not None:\n        if isinstance(resolution_dst, float):\n            resolution_dst = (resolution_dst, resolution_dst)\n\n        resolution_data_like = data_like.res\n\n        shape_out = int(round(shape_out[0] / resolution_dst[0] * resolution_data_like[0])), \\\n                    int(round(shape_out[1] / resolution_dst[1] * resolution_data_like[1]))\n\n    return read_reproject(data_in, dst_crs=data_like.crs, dst_transform=data_like.transform,\n                          resolution_dst_crs=resolution_dst,\n                          window_out=rasterio.windows.Window(0,0, width=shape_out[-1], height=shape_out[-2]),\n                          resampling=resampling,dtype_dst=dtype_dst, return_only_data=return_only_data,\n                          dst_nodata=dst_nodata)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.resize","title":"<code>resize(data_in, resolution_dst, window_out=None, anti_aliasing=True, anti_aliasing_sigma=None, resampling=rasterio.warp.Resampling.cubic_spline, return_only_data=False)</code>","text":"<p>Change the spatial resolution of data_in to <code>resolution_dst</code>. This function is a wrapper of the <code>read_reproject</code> function that adds anti_aliasing before reprojecting.</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>GeoData</code> <p>GeoData to change the resolution. Expected coords \"x\" and \"y\".</p> required <code>resolution_dst</code> <code>Union[float, Tuple[float, float]]</code> <p>spatial resolution in data_in crs</p> required <code>window_out</code> <code>Optional[Window]</code> <p>Optional. output size of the fragment to read and reproject. Defaults to the ceiling size</p> <code>None</code> <code>anti_aliasing</code> <code>bool</code> <p>Whether to apply a Gaussian filter to smooth the image prior to downsampling</p> <code>True</code> <code>anti_aliasing_sigma</code> <code>Optional[Union[float, ndarray]]</code> <p>anti_aliasing_sigma : {float}, optional     Standard deviation for Gaussian filtering used when anti-aliasing.     By default, this value is chosen as (s - 1) / 2 where s is the     downsampling factor, where s &gt; 1</p> <code>None</code> <code>resampling</code> <code>Resampling</code> <p>specifies how data is reprojected from <code>rasterio.warp.Resampling</code>.</p> <code>cubic_spline</code> <code>return_only_data</code> <code>bool</code> <p>defaults to <code>False</code>. If <code>True</code> it returns a np.ndarray otherwise returns an GeoTensor object (georreferenced array).</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[GeoTensor, ndarray]</code> <p>GeoTensor with spatial resolution <code>resolution_dst</code></p> Source code in <code>georeader/read.py</code> <pre><code>def resize(data_in:GeoData, resolution_dst:Union[float, Tuple[float, float]],\n           window_out:Optional[rasterio.windows.Window]=None,\n           anti_aliasing:bool=True, anti_aliasing_sigma:Optional[Union[float,np.ndarray]]=None,\n           resampling: rasterio.warp.Resampling = rasterio.warp.Resampling.cubic_spline,\n           return_only_data: bool = False)-&gt; Union[\n    GeoTensor, np.ndarray]:\n    \"\"\"\n    Change the spatial resolution of data_in to `resolution_dst`. This function is a wrapper of the `read_reproject` function\n    that adds anti_aliasing before reprojecting.\n\n    Args:\n        data_in: GeoData to change the resolution. Expected coords \"x\" and \"y\".\n        resolution_dst: spatial resolution in data_in crs\n        window_out: Optional. output size of the fragment to read and reproject. Defaults to the ceiling size\n        anti_aliasing: Whether to apply a Gaussian filter to smooth the image prior to downsampling\n        anti_aliasing_sigma:  anti_aliasing_sigma : {float}, optional\n                Standard deviation for Gaussian filtering used when anti-aliasing.\n                By default, this value is chosen as (s - 1) / 2 where s is the\n                downsampling factor, where s &gt; 1\n        resampling: specifies how data is reprojected from `rasterio.warp.Resampling`.\n        return_only_data: defaults to `False`. If `True` it returns a np.ndarray otherwise\n            returns an GeoTensor object (georreferenced array).\n\n    Returns:\n        GeoTensor with spatial resolution `resolution_dst`\n\n    \"\"\"\n    resolution_or = data_in.res\n    if isinstance(resolution_dst, numbers.Number):\n        resolution_dst = (abs(resolution_dst), abs(resolution_dst))\n    scale = np.array([resolution_dst[0] / resolution_or[0], resolution_dst[1] / resolution_or[1]])\n\n    if window_out is None:\n        spatial_shape = data_in.shape[-2:]\n\n        # scale &lt; 1 =&gt; make image smaller (resolution_or &lt; resolution_dst)\n        # scale &gt; 1 =&gt; make image larger (resolution_or &gt; resolution_dst)\n        output_shape_exact = spatial_shape[0] / scale[0], spatial_shape[1] / scale[1]\n        output_shape_rounded = round(output_shape_exact[0], ndigits=3), round(output_shape_exact[1], ndigits=3)\n        output_shape = ceil(output_shape_rounded[0]), ceil(output_shape_rounded[1])\n        window_out = rasterio.windows.Window(col_off=0, row_off=0, width=output_shape[1], height=output_shape[0])\n\n    if anti_aliasing:\n        data_in = apply_anti_aliasing(data_in, anti_aliasing_sigma=anti_aliasing_sigma, \n                                      resolution_dst=resolution_dst)\n\n    return read_reproject(data_in, dst_crs=data_in.crs, resolution_dst_crs=resolution_dst,\n                          dst_transform=data_in.transform, window_out=window_out,\n                          resampling=resampling, return_only_data=return_only_data)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.read_reproject","title":"<code>read_reproject(data_in, dst_crs=None, bounds=None, resolution_dst_crs=None, dst_transform=None, window_out=None, resampling=rasterio.warp.Resampling.cubic_spline, dtype_dst=None, return_only_data=False, dst_nodata=None)</code>","text":"<p>This function slices the data by the bounds and reprojects it to the dst_crs and resolution_dst_crs</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>GeoData</code> <p>GeoData to read and reproject. Expected coords \"x\" and \"y\".</p> required <code>bounds</code> <code>Optional[Tuple[float, float, float, float]]</code> <p>Optional. bounds in CRS specified by <code>dst_crs</code>. If not provided <code>window_out</code> must be given.</p> <code>None</code> <code>dst_crs</code> <code>Optional[str]</code> <p>CRS to reproject.</p> <code>None</code> <code>resolution_dst_crs</code> <code>Optional[Union[float, Tuple[float, float]]]</code> <p>resolution in the CRS specified by <code>dst_crs</code>. If not provided will use the the resolution intrinsic of dst_transform.</p> <code>None</code> <code>dst_transform</code> <code>Optional[Affine]</code> <p>Optional dest transform. If not provided the dst_transform is a rectilinear transform computed with the bounds and resolution_dst_crs.</p> <code>None</code> <code>window_out</code> <code>Optional[Window]</code> <p>Window out to read w.r.t <code>dst_transform</code>. If not provided it is computed from the bounds. Window out if provided has the output width and height of the reprojected data.</p> <code>None</code> <code>resampling</code> <code>Resampling</code> <p>specifies how data is reprojected from <code>rasterio.warp.Resampling</code>.</p> <code>cubic_spline</code> <code>dtype_dst</code> <code>Any</code> <p>if None it will be data_in.dtype</p> <code>None</code> <code>return_only_data</code> <code>bool</code> <p>defaults to <code>False</code>. If <code>True</code> it returns a np.ndarray otherwise returns an GeoTensor object (georreferenced array).</p> <code>False</code> <code>dst_nodata</code> <code>Optional[int]</code> <p>dst_nodata value</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[GeoTensor, ndarray]</code> <p>GeoTensor reprojected to dst_crs with resolution_dst_crs</p> Source code in <code>georeader/read.py</code> <pre><code>def read_reproject(data_in: GeoData, dst_crs: Optional[str]=None,\n                   bounds: Optional[Tuple[float, float, float, float]]=None,\n                   resolution_dst_crs: Optional[Union[float, Tuple[float, float]]]=None,\n                   dst_transform:Optional[rasterio.Affine]=None,\n                   window_out:Optional[rasterio.windows.Window]=None,\n                   resampling: rasterio.warp.Resampling = rasterio.warp.Resampling.cubic_spline,\n                   dtype_dst:Any=None, return_only_data: bool = False, dst_nodata: Optional[int] = None) -&gt; Union[\n    GeoTensor, np.ndarray]:\n    \"\"\"\n    This function slices the data by the bounds and reprojects it to the dst_crs and resolution_dst_crs\n\n    Args:\n        data_in: GeoData to read and reproject. Expected coords \"x\" and \"y\".\n        bounds: Optional. bounds in CRS specified by `dst_crs`. If not provided `window_out` must be given.\n        dst_crs: CRS to reproject.\n        resolution_dst_crs: resolution in the CRS specified by `dst_crs`. If not provided will use the the resolution\n            intrinsic of dst_transform.\n        dst_transform: Optional dest transform. If not provided the dst_transform is a rectilinear transform computed\n            with the bounds and resolution_dst_crs.\n        window_out: Window out to read w.r.t `dst_transform`. If not provided it is computed from the bounds.\n            Window out if provided has the output width and height of the reprojected data.\n        resampling: specifies how data is reprojected from `rasterio.warp.Resampling`.\n        dtype_dst: if None it will be data_in.dtype\n        return_only_data: defaults to `False`. If `True` it returns a np.ndarray otherwise\n            returns an GeoTensor object (georreferenced array).\n        dst_nodata: dst_nodata value\n\n    Returns:\n        GeoTensor reprojected to dst_crs with resolution_dst_crs\n\n    \"\"\"\n\n    named_shape = OrderedDict(zip(data_in.dims, data_in.shape))\n\n    # Compute output transform\n    dst_transform = window_utils.figure_out_transform(transform=dst_transform, bounds=bounds,\n                                                      resolution_dst=resolution_dst_crs)\n\n    # Compute size of window in out crs\n    if window_out is None:\n        assert bounds is not None, \"Both window_out and bounds are None. This is needed to figure out the size of the output array\"\n        window_out = rasterio.windows.from_bounds(*bounds,\n                                                  transform=dst_transform).round_lengths(op=\"ceil\",\n                                                                                         pixel_precision=PIXEL_PRECISION)\n\n    crs_data_in = data_in.crs\n    if dst_crs is None:\n        dst_crs = crs_data_in\n\n    #  if dst_crs == data_in.crs and the resolution is the same and window is exact return read_from_window\n    if window_utils.compare_crs(dst_crs, crs_data_in):\n        transform_data = data_in.transform\n        if (dst_transform.a == transform_data.a) and (dst_transform.b == transform_data.b) and (\n                dst_transform.d == transform_data.d) and (dst_transform.e == transform_data.e):\n            # find shift between the two transforms\n            x_dst, y_dst = dst_transform.c, dst_transform.f\n            col_off, row_off = ~transform_data * (x_dst, y_dst)\n            window_in_data = rasterio.windows.Window(col_off, row_off, \n                                                     window_out.width, window_out.height)\n\n            if _is_exact_round(window_in_data.row_off) and _is_exact_round(window_in_data.col_off):\n                window_in_data = window_in_data.round_offsets(op=\"floor\", pixel_precision=PIXEL_PRECISION)\n                return read_from_window(data_in, window_in_data, return_only_data=return_only_data, trigger_load=True)\n\n    isbool_dtypein = data_in.dtype == 'bool'\n    isbool_dtypedst = False\n\n    cast = True\n    if dtype_dst is None:\n        cast = False\n        dtype_dst = data_in.dtype\n        if isbool_dtypein:\n            isbool_dtypedst = True\n    elif np.dtype(dtype_dst) == 'bool':\n        isbool_dtypedst = True\n\n    # Create out array for reprojection\n    dict_shape_window_out = {\"x\": window_out.width, \"y\": window_out.height}\n    shape_out = tuple([named_shape[s] if s not in [\"x\", \"y\"] else dict_shape_window_out[s] for s in named_shape])\n    dst_nodata = dst_nodata or data_in.fill_value_default\n    if isbool_dtypedst:\n        dst_nodata = bool(dst_nodata)\n\n    destination = np.full(shape_out, fill_value=dst_nodata, dtype=dtype_dst)\n\n    polygon_dst_crs = window_utils.window_polygon(window_out, dst_transform)\n\n    # If the polygon does not intersect the data return a GeoTensor with nodata\n    if not data_in.footprint(crs=dst_crs).intersects(polygon_dst_crs):\n        return GeoTensor(destination, transform=dst_transform, crs=dst_crs,\n                         fill_value_default=dst_nodata)\n\n    if not isinstance(data_in, GeoTensor):\n        # Compute real polygon that is going to be read\n        # Read a padded window of the input data. This data will be then used for reprojection\n        geotensor_in = read_from_polygon(data_in, polygon_dst_crs, crs_polygon=dst_crs,\n                                         pad_add=(3, 3), return_only_data=False,\n                                         trigger_load=True)\n    else:\n        geotensor_in = data_in\n\n    # Triggering load makes that fill_value_default goes to nodata\n    np_array_in = np.asanyarray(geotensor_in.values)\n\n    if cast:\n        if isbool_dtypedst:\n            np_array_in = np_array_in.astype(np.float32)\n        else:\n            np_array_in = np_array_in.astype(dtype_dst)\n    elif isbool_dtypein:\n        np_array_in = np_array_in.astype(np.float32)\n\n\n    index_iter = [[(ns, i) for i in range(s)] for ns, s in named_shape.items() if ns not in [\"x\", \"y\"]]\n    # e.g. if named_shape = {'time': 4, 'band': 2, 'x':10, 'y': 10} index_iter -&gt;\n    # [[('time', 0), ('time', 1), ('time', 2), ('time', 3)],\n    #  [('band', 0), ('band', 1)]]\n\n    for current_select_tuple in itertools.product(*index_iter):\n        # current_select_tuple = (('time', 0), ('band', 0))\n        i_sel_tuple = tuple(t[1] for t in current_select_tuple)\n\n        np_array_iter = np_array_in[i_sel_tuple]\n        if isbool_dtypedst:\n            dst_iter_write = destination[i_sel_tuple].astype(np.float32)\n            dst_nodata_iter = float(dst_nodata)\n        else:\n            dst_iter_write = destination[i_sel_tuple]\n            dst_nodata_iter = dst_nodata\n\n        rasterio.warp.reproject(\n            np_array_iter,\n            dst_iter_write,\n            src_transform=geotensor_in.transform,\n            src_crs=crs_data_in,\n            dst_transform=dst_transform,\n            dst_crs=dst_crs,\n            src_nodata=geotensor_in.fill_value_default,\n            dst_nodata=dst_nodata_iter,\n            resampling=resampling)\n\n        if isbool_dtypedst:\n            destination[i_sel_tuple] = (dst_iter_write &gt; .5)\n\n    if return_only_data:\n        return destination\n\n    return GeoTensor(destination, transform=dst_transform, crs=dst_crs,\n                     fill_value_default=dst_nodata)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.read_rpcs","title":"<code>read_rpcs(input_npy, rpcs, fill_value_default=0, dst_crs=None, resolution_dst_crs=None, resampling=rasterio.warp.Resampling.cubic_spline, return_only_data=False)</code>","text":"<p>This function georreferences an array using the RPCs.      The RPCs are used to compute the transform from the input array to the destination crs.</p> <pre><code>This function assumes that the RPCs are in EPSG:4326.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>input_npy</code> <code>NDArray</code> <p>Array to georeference. It must have 2, 3 or 4 dimensions.</p> required <code>rpcs</code> <code>RPC</code> <p>RPCs to compute the transform.</p> required <code>fill_value_default</code> <code>int</code> <p>how to encode the nodata value. Defaults to 0.</p> <code>0</code> <code>dst_crs</code> <code>Optional[Any]</code> <p>Destination crs. Defaults to None. If None, the dst_crs is the same as in the RPC polynomial (EPSG:4326).</p> <code>None</code> <code>resampling</code> <code>Resampling</code> <p>Resampling method.  Defaults to rasterio.warp.Resampling.cubic_spline.</p> <code>cubic_spline</code> <code>return_only_data</code> <code>bool</code> <p>If True it returns only the data. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>GeoTensor</code> <code>GeoTensor</code> <p>GeoTensor with the georeferenced array based on the RPCs.</p> Source code in <code>georeader/read.py</code> <pre><code>def read_rpcs(input_npy:NDArray, rpcs:rasterio.rpc.RPC, \n              fill_value_default:int=0,\n              dst_crs:Optional[Any]=None,\n              resolution_dst_crs:Optional[Union[float, Tuple[float, float]]]=None,\n              resampling: rasterio.warp.Resampling = rasterio.warp.Resampling.cubic_spline,\n              return_only_data:bool=False) -&gt; GeoTensor:\n    \"\"\"\n    This function georreferences an array using the RPCs. \n        The RPCs are used to compute the transform from the input array to the destination crs.\n\n        This function assumes that the RPCs are in EPSG:4326.\n\n    Args:\n        input_npy (NDArray): Array to georeference. It must have 2, 3 or 4 dimensions.\n        rpcs (rasterio.rpc.RPC): RPCs to compute the transform.\n        fill_value_default (int, optional): how to encode the nodata value. Defaults to 0.\n        dst_crs (Optional[Any], optional): Destination crs. Defaults to None.\n            If None, the dst_crs is the same as in the RPC polynomial (EPSG:4326).\n        resampling (rasterio.warp.Resampling, optional): Resampling method. \n            Defaults to rasterio.warp.Resampling.cubic_spline.\n        return_only_data (bool, optional): If True it returns only the data. Defaults to False.\n\n    Returns:\n        GeoTensor: GeoTensor with the georeferenced array based on the RPCs.\n    \"\"\"\n\n    isbool_dtypedst = input_npy.dtype == 'bool'\n    if isbool_dtypedst:\n        fill_value_default = bool(fill_value_default)\n\n    assert input_npy.ndim &gt;= 2 and input_npy.ndim &lt;= 4, \"Input array must have 2, 3 or 4 dimensions\"\n\n    named_shape = OrderedDict(reversed(list(zip([\"y\", \"x\", \"band\", \"time\"], \n                                                reversed(input_npy.shape)))))\n\n    index_iter = [[(ns, i) for i in range(s)] for ns, s in named_shape.items() if ns not in [\"x\", \"y\"]]\n    # e.g. if named_shape = {'time': 4, 'band': 2, 'x':10, 'y': 10} index_iter -&gt;\n    # [[('time', 0), ('time', 1), ('time', 2), ('time', 3)],\n    #  [('band', 0), ('band', 1)]]\n\n    if dst_crs is None:\n        dst_crs = rasterio.crs.CRS.from_epsg(4326)\n\n    src_crs = rasterio.crs.CRS.from_epsg(4326)\n\n    if resolution_dst_crs is not None:\n        if isinstance(resolution_dst_crs, float):\n            resolution_dst_crs = (resolution_dst_crs, resolution_dst_crs)\n\n    dst_transform, dst_width, dst_height = rasterio.warp.calculate_default_transform(\n            src_crs=None, dst_crs=dst_crs, \n            width=input_npy.shape[-1], \n            height=input_npy.shape[-2], \n            resolution=resolution_dst_crs,\n            rpcs=rpcs, dst_width=None, dst_height=None)\n\n    destination = np.full(input_npy.shape[:-2] + (dst_height, dst_width),\n                          fill_value=fill_value_default,\n                          dtype=input_npy.dtype)\n\n    for current_select_tuple in itertools.product(*index_iter):\n        # current_select_tuple = (('time', 0), ('band', 0))\n        i_sel_tuple = tuple(t[1] for t in current_select_tuple)\n\n        np_array_iter = input_npy[i_sel_tuple]\n        if isbool_dtypedst:\n            dst_iter_write = destination[i_sel_tuple].astype(np.float32)\n            fill_value_default_iter = float(fill_value_default)\n        else:\n            dst_iter_write = destination[i_sel_tuple]\n            fill_value_default_iter = fill_value_default\n\n        rasterio.warp.reproject(\n            np_array_iter,\n            dst_iter_write,\n            src_transform=None,\n            rpcs=rpcs,\n            src_crs=src_crs,\n            dst_transform=dst_transform,\n            dst_crs=dst_crs,\n            src_nodata=fill_value_default_iter,\n            dst_nodata=fill_value_default_iter,\n            resampling=resampling)\n\n        if isbool_dtypedst:\n            destination[i_sel_tuple] = (dst_iter_write &gt; .5)\n\n    if return_only_data:\n        return destination\n\n    return GeoTensor(destination, transform=dst_transform, crs=dst_crs,\n                     fill_value_default=fill_value_default)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.window_from_bounds","title":"<code>window_from_bounds(data_in, bounds, crs_bounds=None)</code>","text":"<p>Compute window to read in data_in from bounds in crs_bounds. If crs_bounds is None it assumes bounds are in the crs of data_in</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>Union[GeoData, DatasetReader]</code> <p>Reader with crs and transform attributes</p> required <code>bounds</code> <code>Tuple[float, float, float, float]</code> <p>tuple with bounds to find the corresponding window</p> required <code>crs_bounds</code> <code>Optional[str]</code> <p>Optional coordinate reference system of the bounds. If not provided assumes same crs as <code>data_in</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Window</code> <p>Window object with location in pixel coordinates relative to <code>data_in</code> of the bounds</p> Source code in <code>georeader/read.py</code> <pre><code>def window_from_bounds(data_in: Union[GeoData, rasterio.DatasetReader], \n                       bounds:Tuple[float, float, float, float],\n                       crs_bounds:Optional[str]=None) -&gt; rasterio.windows.Window:\n    \"\"\"\n    Compute window to read in data_in from bounds in crs_bounds. If crs_bounds is None it assumes bounds are in the\n    crs of data_in\n\n    Args:\n        data_in: Reader with crs and transform attributes\n        bounds: tuple with bounds to find the corresponding window\n        crs_bounds: Optional coordinate reference system of the bounds. If not provided assumes same crs as `data_in`\n\n    Returns:\n        Window object with location in pixel coordinates relative to `data_in` of the bounds\n\n    \"\"\"\n    if (crs_bounds is not None) and not window_utils.compare_crs(crs_bounds, data_in.crs):\n\n        bounds_in = rasterio.warp.transform_bounds(crs_bounds,\n                                                   data_in.crs, *bounds)\n    else:\n        bounds_in = bounds\n\n    window_in = rasterio.windows.from_bounds(*bounds_in, transform=data_in.transform)\n\n    return window_in\n</code></pre>"},{"location":"modules/read_module/#georeader.read.window_from_center_coords","title":"<code>window_from_center_coords(data_in, center_coords, shape, crs_center_coords=None)</code>","text":"<p>Compute window to read in <code>data_in</code> from the coordinates of the center pixel. If <code>crs_center_coords</code> is None it assumes  <code>center_coords</code> are in the crs of <code>data_in</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>Union[GeoData, DatasetReader]</code> <p>Reader with crs and transform attributes</p> required <code>center_coords</code> <code>Tuple[float, float]</code> <p>Tuple with center coords (x, y) format</p> required <code>shape</code> <code>Tuple[int, int]</code> <p>Tuple with shape to read (H, W) format</p> required <code>crs_center_coords</code> <code>Optional[Any]</code> <p>Optional coordinate reference system of the bounds. If not provided assumes same crs as <code>data_in</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Window</code> <p>Window object with location in pixel coordinates relative to <code>data_in</code> of the window centered on <code>center_coords</code></p> Source code in <code>georeader/read.py</code> <pre><code>def window_from_center_coords(data_in: Union[GeoData, rasterio.DatasetReader], \n                              center_coords:Tuple[float, float],\n                              shape:Tuple[int,int], crs_center_coords:Optional[Any]=None) -&gt; rasterio.windows.Window:\n    \"\"\"\n     Compute window to read in `data_in` from the coordinates of the center pixel. If `crs_center_coords` is None it assumes\n     `center_coords` are in the crs of `data_in`.\n\n    Args:\n        data_in: Reader with crs and transform attributes\n        center_coords: Tuple with center coords (x, y) format\n        shape: Tuple with shape to read (H, W) format\n        crs_center_coords: Optional coordinate reference system of the bounds. If not provided assumes same crs as `data_in`\n\n    Returns:\n         Window object with location in pixel coordinates relative to `data_in` of the window centered on `center_coords`\n    \"\"\"\n\n    if (crs_center_coords is not None) and not window_utils.compare_crs(crs_center_coords, data_in.crs):\n        center_coords = _transform_from_crs(center_coords, crs_center_coords, data_in.crs)\n\n    # The computation of the corner coordinates from the center is the same as in utils.polygon_slices\n    transform = data_in.transform\n\n    pixel_center_coords = ~transform * tuple(center_coords)\n    pixel_upper_left =  _round_all((pixel_center_coords[0] - shape[1] / 2, pixel_center_coords[1] - shape[0] / 2))\n\n    # OLD CODE that didn't support non-rectilinear transforms\n    # assert transform.is_rectilinear(), \"Transform is not rectilear\"\n    #\n    # upper_left_coords = (center_coords[0] - (transform.a * shape[1] / 2),\n    #                      center_coords[1] - (transform.e * shape[0] / 2))\n    # pixel_upper_left = _round_all(~transform * upper_left_coords)\n\n    window = rasterio.windows.Window(row_off=pixel_upper_left[1], col_off=pixel_upper_left[0],\n                                     width=shape[1], height=shape[0])\n    return window\n</code></pre>"},{"location":"modules/read_module/#georeader.read.window_from_polygon","title":"<code>window_from_polygon(data_in, polygon, crs_polygon=None, window_surrounding=False)</code>","text":"<p>Obtains the data window that surrounds the polygon</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>Union[GeoData, DatasetReader]</code> <p>Reader with crs and transform attributes</p> required <code>polygon</code> <code>Union[Polygon, MultiPolygon]</code> <p>Polygon or MultiPolygon</p> required <code>crs_polygon</code> <code>Optional[str]</code> <p>Optional coordinate reference system of the bounds. If not provided assumes same crs as <code>data_in</code></p> <code>None</code> <code>window_surrounding</code> <code>bool</code> <p>The window surrounds the polygon. (i.e. window.row_off + window.height will not be a vertex)</p> <code>False</code> <p>Returns:</p> Type Description <code>Window</code> <p>Window object with location in pixel coordinates relative to <code>data_in</code> of the polygon</p> Source code in <code>georeader/read.py</code> <pre><code>def window_from_polygon(data_in: Union[GeoData, rasterio.DatasetReader],\n                        polygon:Union[Polygon, MultiPolygon], crs_polygon:Optional[str]=None,\n                        window_surrounding:bool=False) -&gt; rasterio.windows.Window:\n    \"\"\"\n    Obtains the data window that surrounds the polygon\n\n    Args:\n        data_in: Reader with crs and transform attributes\n        polygon: Polygon or MultiPolygon\n        crs_polygon: Optional coordinate reference system of the bounds. If not provided assumes same crs as `data_in`\n        window_surrounding: The window surrounds the polygon. (i.e. window.row_off + window.height will not be a vertex)\n\n    Returns:\n        Window object with location in pixel coordinates relative to `data_in` of the polygon\n\n    \"\"\"\n    data_in_crs = data_in.crs\n    data_in_transform = data_in.transform\n\n    # convert polygon to GeoData crs\n    coords_multipol = window_utils.exterior_pixel_coords(polygon=polygon, crs_polygon=crs_polygon, \n                                                         crs=data_in_crs, transform=data_in_transform)\n\n    # Figure out min max rows and cols to build the window\n    row_off = min(c[1] for coords in coords_multipol for c in coords)\n    col_off = min(c[0] for coords in coords_multipol for c in coords)\n\n    row_max = max(c[1] for coords in coords_multipol for c in coords)\n    col_max = max(c[0] for coords in coords_multipol for c in coords)\n    if window_surrounding:\n        row_max += 1\n        col_max += 1\n\n    return rasterio.windows.Window(row_off=row_off, col_off=col_off,\n                                   width=col_max-col_off,\n                                   height=row_max-row_off)\n</code></pre>"},{"location":"modules/read_module/#georeader.read.window_from_tile","title":"<code>window_from_tile(data_in, x, y, z)</code>","text":"<p>Returns the window corresponding to the x,y,z tile in the data_in.</p> <p>Tiles are TMS tiles defined as: (https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames)</p> <p>Parameters:</p> Name Type Description Default <code>data_in</code> <code>Union[GeoData, DatasetReader]</code> <p>GeoData object</p> required <code>x</code> <code>int</code> <p>x coordinate of the tile in the TMS system.</p> required <code>y</code> <code>int</code> <p>y coordinate of the tile in the TMS system.</p> required <code>z</code> <code>int</code> <p>z coordinate of the tile in the TMS system.</p> required <p>Returns:</p> Type Description <code>Window</code> <p>rasterio.windows.Window: window corresponding to the tile</p> Source code in <code>georeader/read.py</code> <pre><code>def window_from_tile(data_in: Union[GeoData, rasterio.DatasetReader],\n                     x:int, y:int, z:int) -&gt; rasterio.windows.Window:\n    \"\"\"\n    Returns the window corresponding to the x,y,z tile in the data_in.\n\n    Tiles are TMS tiles defined as: (https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames)\n\n    Args:\n        data_in (Union[GeoData, rasterio.DatasetReader]):  GeoData object\n        x (int): x coordinate of the tile in the TMS system.\n        y (int): y coordinate of the tile in the TMS system.\n        z (int): z coordinate of the tile in the TMS system.\n\n    Returns:\n        rasterio.windows.Window: window corresponding to the tile\n    \"\"\"\n    bounds_wgs = mercantile.xy_bounds(int(x), int(y), int(z))\n    polygon_crs_webmercator = box(bounds_wgs.left, bounds_wgs.bottom, bounds_wgs.right, bounds_wgs.top)\n    return window_from_polygon(data_in, polygon_crs_webmercator, WEB_MERCATOR_CRS,\n                               window_surrounding=True)\n</code></pre>"},{"location":"modules/reflectance_module/","title":"reflectance","text":""},{"location":"modules/reflectance_module/#georeader.reflectance.compute_sza","title":"<code>compute_sza(center_coords, date_of_acquisition, crs_coords=None)</code>","text":"<p>This function returns the solar zenith angle for a given location and date of acquisition.</p> <p>Parameters:</p> Name Type Description Default <code>center_coords</code> <code>Tuple[float, float]</code> <p>location being considered (x,y) (long, lat if EPSG:4326)</p> required <code>date_of_acquisition</code> <code>datetime</code> <p>date of acquisition to compute the solar zenith angles. It  is assumed to be UTC time.</p> required <code>crs_coords</code> <code>Optional[str]</code> <p>if None it will assume center_coords are in EPSG:4326. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>solar zenith angle in degrees</p> Source code in <code>georeader/reflectance.py</code> <pre><code>def compute_sza(center_coords:Tuple[float, float], date_of_acquisition:datetime, crs_coords:Optional[str]=None) -&gt; float:\n    \"\"\"\n    This function returns the solar zenith angle for a given location and date of acquisition.\n\n    Args:\n        center_coords (Tuple[float, float]): location being considered (x,y) (long, lat if EPSG:4326)\n        date_of_acquisition (datetime): date of acquisition to compute the solar zenith angles. It \n            is assumed to be UTC time.\n        crs_coords (Optional[str], optional): if None it will assume center_coords are in EPSG:4326. Defaults to None.\n\n    Returns:\n        float: solar zenith angle in degrees\n    \"\"\"\n    try:\n        from pysolar.solar import get_altitude\n    except ImportError:\n        raise ImportError(\"pysolar is required to compute the solar zenith angle. Install it with `pip install pysolar`\")\n\n    if crs_coords is not None and not window_utils.compare_crs(crs_coords, \"EPSG:4326\"):\n        from rasterio import warp\n        centers_long, centers_lat = warp.transform(crs_coords,\n                                                   {'init': 'epsg:4326'}, [center_coords[0]], [center_coords[1]])\n        centers_long = centers_long[0]\n        centers_lat = centers_lat[0]\n    else:\n        centers_long = center_coords[0]\n        centers_lat = center_coords[1]\n\n    # Get Solar Altitude (in degrees)\n    solar_altitude = get_altitude(latitude_deg=centers_lat, longitude_deg=centers_long,\n                                  when=date_of_acquisition)\n    return 90 - solar_altitude\n</code></pre>"},{"location":"modules/reflectance_module/#georeader.reflectance.earth_sun_distance_correction_factor","title":"<code>earth_sun_distance_correction_factor(date_of_acquisition)</code>","text":"<p>This function returns the Earth-sun distance correction factor given by the formula:</p> <pre><code>d = 1-0.01673*cos(0.0172*(t-4))\n\nWhere:\n0.0172 = 360/365.256363 * np.pi/180.  # (Earth orbit angular velocity)\n0.01673 is the Earth eccentricity\n\n# t is the day of the year starting in 1:\nt = datenum(Y,M,D) - datenum(Y,1,1) + 1;\n\n# tm_yday starts in 1\ndatetime.datetime.strptime(\"2022-01-01\", \"%Y-%m-%d\").timetuple().tm_yday -&gt; 1\n</code></pre> <p>In the Sentinel-2 metadata they provide <code>U</code> which is the square inverse of this factor: <code>U = 1 / d^2</code></p> <p>https://sentiwiki.copernicus.eu/web/s2-processing#S2Processing-TOAReflectanceComputation</p> <p>Parameters:</p> Name Type Description Default <code>date_of_acquisition</code> <code>datetime</code> <p>date of acquisition. The day of the year will be used  to compute the correction factor</p> required <p>Returns:</p> Type Description <code>float</code> <p>(1-0.01673cos(0.0172(t-4)))</p> Source code in <code>georeader/reflectance.py</code> <pre><code>def earth_sun_distance_correction_factor(date_of_acquisition:datetime) -&gt; float:\n    \"\"\"\n    This function returns the Earth-sun distance correction factor given by the formula:\n\n    ```\n    d = 1-0.01673*cos(0.0172*(t-4))\n\n    Where:\n    0.0172 = 360/365.256363 * np.pi/180.  # (Earth orbit angular velocity)\n    0.01673 is the Earth eccentricity\n\n    # t is the day of the year starting in 1:\n    t = datenum(Y,M,D) - datenum(Y,1,1) + 1;\n\n    # tm_yday starts in 1\n    datetime.datetime.strptime(\"2022-01-01\", \"%Y-%m-%d\").timetuple().tm_yday -&gt; 1\n\n    ```\n\n    In the Sentinel-2 metadata they provide `U` which is the square inverse of this factor: `U = 1 / d^2`\n\n    [https://sentiwiki.copernicus.eu/web/s2-processing#S2Processing-TOAReflectanceComputation](https://sentiwiki.copernicus.eu/web/s2-processing#S2Processing-TOAReflectanceComputation)\n\n    Args:\n        date_of_acquisition: date of acquisition. The day of the year will be used \n            to compute the correction factor\n\n    Returns:\n        (1-0.01673*cos(0.0172*(t-4)))\n    \"\"\"\n    tm_yday = date_of_acquisition.timetuple().tm_yday # from 1 to 365 (or 366!)\n    return 1 - 0.01673 * np.cos(0.0172 * (tm_yday - 4))\n</code></pre>"},{"location":"modules/reflectance_module/#georeader.reflectance.integrated_irradiance","title":"<code>integrated_irradiance(srf, solar_irradiance=None, epsilon_srf=0.0001)</code>","text":"<p>Returns the integrated irradiance for the given spectral response function (SRF) and solar irradiance.</p> <p>The output is the integrated irradiance for each band.</p> <p>Parameters:</p> Name Type Description Default <code>srf</code> <code>DataFrame</code> <p>dataframe with the spectral response function (SRF) (N, K) where N is the number of wavelengths and K the number of bands. The index is the wavelengths in nanometers and the columns are the bands.</p> required <code>solar_irradiance</code> <code>Optional[DataFrame]</code> <p>dataframe with the solar irradiance. It must contain the columns \"Nanometer\" and \"Radiance(mW/m2/nm)\". (D, 2)       Defaults to None. If None, it will load the Thuillier solar irradiance and the output will be in mW/m2/nm.</p> <code>None</code> <code>epsilon_srf</code> <code>float</code> <p>threshold to consider a band in the SRF. Defaults to 1e-4.</p> <code>0.0001</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>integrated irradiance (K,)</p> Source code in <code>georeader/reflectance.py</code> <pre><code>def integrated_irradiance(srf:pd.DataFrame, \n                          solar_irradiance:Optional[pd.DataFrame]=None,\n                          epsilon_srf:float=1e-4) -&gt; NDArray:\n    \"\"\"\n    Returns the integrated irradiance for the given spectral response function (SRF) and solar irradiance.\n\n    The output is the integrated irradiance for each band.\n\n    Args:\n        srf (pd.DataFrame): dataframe with the spectral response function (SRF) (N, K) where N is the number of wavelengths and K the number of bands.\n            The index is the wavelengths in nanometers and the columns are the bands.\n        solar_irradiance (Optional[pd.DataFrame], optional): dataframe with the solar irradiance. It must contain the columns \"Nanometer\" and \"Radiance(mW/m2/nm)\". (D, 2)\n                  Defaults to None. If None, it will load the Thuillier solar irradiance and the output will be in mW/m2/nm.\n        epsilon_srf (float, optional): threshold to consider a band in the SRF. Defaults to 1e-4.\n\n    Returns:\n        NDArray: integrated irradiance (K,)\n    \"\"\"\n    from scipy import interpolate\n\n    if solar_irradiance is None:\n        solar_irradiance = load_thuillier_irradiance()\n\n    anybigvalue = (srf&gt;epsilon_srf).any(axis=1)\n    srf = srf.loc[anybigvalue, :]\n\n    # Trim the solar irradiance to the min and max wavelengths\n    solar_irradiance = solar_irradiance[(solar_irradiance[\"Nanometer\"] &gt;= srf.index.min()) &amp;\\\n                                        (solar_irradiance[\"Nanometer\"] &lt;= srf.index.max())]\n\n    # interpolate srf to the solar irradiance\n    interp = interpolate.interp1d(srf.index, srf, kind=\"linear\", axis=0)\n    srf_interp = interp(solar_irradiance[\"Nanometer\"].values) # (D, K)\n\n    # integrate the product of the solar irradiance and the srf\n    return np.sum(solar_irradiance[\"Radiance(mW/m2/nm)\"].values[:, np.newaxis] * srf_interp, axis=0) / srf_interp.sum(axis=0)\n</code></pre>"},{"location":"modules/reflectance_module/#georeader.reflectance.load_thuillier_irradiance","title":"<code>load_thuillier_irradiance()</code>","text":"<p>https://oceancolor.gsfc.nasa.gov/docs/rsr/f0.txt</p> <p>G. Thuillier et al., \"The Solar Spectral Irradiance from 200 to 2400nm as      Measured by the SOLSPEC Spectrometer from the Atlas and Eureca Missions\", Solar Physics, vol. 214, no. 1, pp. 1-22, May 2003, doi: 10.1023/A:1024048429145.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pandas dataframe with columns: Nanometer, Radiance(mW/m2/nm)</p> Source code in <code>georeader/reflectance.py</code> <pre><code>def load_thuillier_irradiance() -&gt; pd.DataFrame:\n    \"\"\"\n    https://oceancolor.gsfc.nasa.gov/docs/rsr/f0.txt\n\n    G. Thuillier et al., \"The Solar Spectral Irradiance from 200 to 2400nm as \n        Measured by the SOLSPEC Spectrometer from the Atlas and Eureca Missions\",\n    Solar Physics, vol. 214, no. 1, pp. 1-22, May 2003, doi: 10.1023/A:1024048429145.\n\n\n    Returns:\n        pandas dataframe with columns: Nanometer, Radiance(mW/m2/nm)\n    \"\"\"\n    global THUILLIER_RADIANCE\n\n    if THUILLIER_RADIANCE is None:\n        THUILLIER_RADIANCE = pd.read_csv(pkg_resources.resource_filename(\"georeader\",\"SolarIrradiance_Thuillier.csv\"))\n\n    return THUILLIER_RADIANCE\n</code></pre>"},{"location":"modules/reflectance_module/#georeader.reflectance.observation_date_correction_factor","title":"<code>observation_date_correction_factor(center_coords, date_of_acquisition, crs_coords=None)</code>","text":"<p>This function returns the observation date correction factor given by the formula:</p> <p>obfactor = (pi * d^2) / cos(solarzenithangle/180*pi)</p> <p>Parameters:</p> Name Type Description Default <code>center_coords</code> <code>Tuple[float, float]</code> <p>location being considered (x,y) (long, lat if EPSG:4326) </p> required <code>date_of_acquisition</code> <code>datetime</code> <p>date of acquisition to compute the solar zenith angles.</p> required <code>crs_coords</code> <code>Optional[str]</code> <p>if None it will assume center_coords are in EPSG:4326</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>correction factor</p> Source code in <code>georeader/reflectance.py</code> <pre><code>def observation_date_correction_factor(center_coords:Tuple[float, float], \n                                       date_of_acquisition:datetime,\n                                       crs_coords:Optional[str]=None) -&gt; float:\n    \"\"\"\n    This function returns the observation date correction factor given by the formula:\n\n      obfactor = (pi * d^2) / cos(solarzenithangle/180*pi)\n\n    Args:\n        center_coords: location being considered (x,y) (long, lat if EPSG:4326) \n        date_of_acquisition: date of acquisition to compute the solar zenith angles.\n        crs_coords: if None it will assume center_coords are in EPSG:4326\n\n    Returns:\n        correction factor\n\n    \"\"\"\n    sza = compute_sza(center_coords, date_of_acquisition, crs_coords=crs_coords)\n    d = earth_sun_distance_correction_factor(date_of_acquisition)\n\n    return np.pi*(d**2) / np.cos(sza/180.*np.pi)\n</code></pre>"},{"location":"modules/reflectance_module/#georeader.reflectance.radiance_to_reflectance","title":"<code>radiance_to_reflectance(data, solar_irradiance, date_of_acquisition=None, center_coords=None, crs_coords=None, observation_date_corr_factor=None, units='uW/cm^2/SR/nm')</code>","text":"<p>Convert the radiance to ToA reflectance using the solar irradiance and the date of acquisition.</p> <pre><code>toaBandX = (radianceBandX / 100 * pi * d^2) / (cos(solarzenithangle/180*pi) * solarIrradianceBandX)\ntoaBandX = (radianceBandX / 100 / solarIrradianceBandX) * observation_date_correction_factor(center_coords, date_of_acquisition)\n</code></pre> <p>ESA reference of ToA calculation</p> where <p>d = earth_sun_distance_correction_factor(date_of_acquisition) solarzenithangle = is obtained from the date of aquisition and location</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[GeoTensor, ArrayLike]</code> <p>(C, H, W) tensor with units: \u00b5W /(nm cm\u00b2 sr)     microwatts per centimeter_squared per nanometer per steradian</p> required <code>solar_irradiance</code> <code>ArrayLike</code> <p>(C,) vector units: W/m\u00b2/nm</p> required <code>date_of_acquisition</code> <code>Optional[datetime]</code> <p>date of acquisition to compute the solar zenith angles and the Earth-Sun distance correction factor.</p> <code>None</code> <code>center_coords</code> <code>Optional[Tuple[float, float]]</code> <p>location being considered to compute the solar zenith angles and the Earth-Sun distance correction factor. (x,y) (long, lat if EPSG:4326). If None, it will use the center of the image.</p> <code>None</code> <code>observation_date_corr_factor</code> <code>Optional[float]</code> <p>if None, it will be computed using the center_coords and date_of_acquisition.        </p> <code>None</code> <code>crs_coords</code> <code>Optional[str]</code> <p>if None it will assume center_coords are in <code>EPSG:4326</code>.</p> <code>None</code> <code>units</code> <code>str</code> <p>if as_reflectance is True, the units of the hyperspectral data must be provided. Defaults to None. accepted values: \"mW/m2/sr/nm\", \"W/m2/sr/nm\", \"uW/cm^2/SR/nm\"</p> <code>'uW/cm^2/SR/nm'</code> <p>Returns:</p> Type Description <code>Union[GeoTensor, NDArray]</code> <p>GeoTensor with ToA reflectance values (C, H, W)</p> Source code in <code>georeader/reflectance.py</code> <pre><code>def radiance_to_reflectance(data:Union[GeoTensor, ArrayLike], \n                            solar_irradiance:ArrayLike,\n                            date_of_acquisition:Optional[datetime]=None,\n                            center_coords:Optional[Tuple[float, float]]=None,\n                            crs_coords:Optional[str]=None,\n                            observation_date_corr_factor:Optional[float]=None,\n                            units:str=\"uW/cm^2/SR/nm\") -&gt; Union[GeoTensor, NDArray]:\n    \"\"\"\n    Convert the radiance to ToA reflectance using the solar irradiance and the date of acquisition.\n\n    ```\n    toaBandX = (radianceBandX / 100 * pi * d^2) / (cos(solarzenithangle/180*pi) * solarIrradianceBandX)\n    toaBandX = (radianceBandX / 100 / solarIrradianceBandX) * observation_date_correction_factor(center_coords, date_of_acquisition)\n    ```\n\n    [ESA reference of ToA calculation](https://sentiwiki.copernicus.eu/web/s2-processing#S2Processing-TOAReflectanceComputation)\n\n    where:\n        d = earth_sun_distance_correction_factor(date_of_acquisition)\n        solarzenithangle = is obtained from the date of aquisition and location\n\n    Args:\n        data:  (C, H, W) tensor with units: \u00b5W /(nm cm\u00b2 sr)\n                microwatts per centimeter_squared per nanometer per steradian\n        solar_irradiance: (C,) vector units: W/m\u00b2/nm\n        date_of_acquisition: date of acquisition to compute the solar zenith angles and the Earth-Sun distance correction factor.\n        center_coords: location being considered to compute the solar zenith angles and the Earth-Sun distance correction factor.\n            (x,y) (long, lat if EPSG:4326). If None, it will use the center of the image.\n        observation_date_corr_factor: if None, it will be computed using the center_coords and date_of_acquisition.        \n        crs_coords: if None it will assume center_coords are in `EPSG:4326`.\n        units: if as_reflectance is True, the units of the hyperspectral data must be provided. Defaults to None.\n            accepted values: \"mW/m2/sr/nm\", \"W/m2/sr/nm\", \"uW/cm^2/SR/nm\"\n\n    Returns:\n        GeoTensor with ToA reflectance values (C, H, W)\n    \"\"\"\n\n    solar_irradiance = np.array(solar_irradiance)[:, np.newaxis, np.newaxis] # (C, 1, 1)\n    assert len(data.shape) == 3, f\"Expected 3 channels found {len(data.shape)}\"\n    assert data.shape[0] == len(solar_irradiance), \\\n        f\"Different number of channels {data.shape[0]} than number of radiances {len(solar_irradiance)}\"\n\n    if units == \"mW/m2/sr/nm\":\n        factor_div = 1000\n    elif units == \"W/m2/sr/nm\":\n        factor_div = 1\n    elif units == \"uW/cm^2/SR/nm\":\n        factor_div = 100 # (10**(-6) / 1) * (1 /10**(-4))\n    else:\n        raise ValueError(f\"Units {units} not recognized must be 'mW/m2/sr/nm', 'W/m2/sr/nm', 'uW/cm^2/SR/nm'\")\n\n\n    if observation_date_corr_factor is None:\n        assert date_of_acquisition is not None, \"If observation_date_corr_factor is None, date_of_acquisition must be provided\"\n        # Get latitude and longitude of the center of image to compute the solar angle\n        if center_coords is None:\n            assert isinstance(data, GeoTensor), \"If center_coords is None, data must be a GeoTensor\"\n            center_coords = data.transform * (data.shape[-1] // 2, data.shape[-2] // 2)\n            crs_coords = data.crs\n\n        observation_date_corr_factor = observation_date_correction_factor(center_coords, date_of_acquisition, crs_coords=crs_coords)\n\n    if isinstance(data, GeoTensor):\n        data_values = data.values\n    else:\n        data_values = data\n\n    # radiances = data_values * (10**(-6) / 1) * (1 /10**(-4))\n\n    # Convert units to W/m\u00b2/sr/nm\n    radiances = data_values / factor_div\n\n    # data_toa = data.values / 100 * constant_factor / solar_irradiance\n    data_toa_reflectance = radiances * observation_date_corr_factor / solar_irradiance\n    if not  isinstance(data, GeoTensor):\n        return data_toa_reflectance\n\n    mask = data.values == data.fill_value_default\n    data_toa_reflectance[mask] = data.fill_value_default\n\n    return GeoTensor(values=data_toa_reflectance, crs=data.crs, transform=data.transform,\n                     fill_value_default=data.fill_value_default)\n</code></pre>"},{"location":"modules/reflectance_module/#georeader.reflectance.srf","title":"<code>srf(center_wavelengths, fwhm, wavelengths)</code>","text":"<p>Returns the spectral response function (SRF) for the given center wavelengths and full width half maximum (FWHM).</p> <p>Parameters:</p> Name Type Description Default <code>center_wavelengths</code> <code>array</code> <p>array with center wavelengths. (K, )</p> required <code>fwhm</code> <code>array</code> <p>array with full width half maximum (FWHM) values (K,)</p> required <code>wavelengths</code> <code>array</code> <p>array with wavelengths where the SRF is evaluated (N,)</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>np.array: normalized SRF (N, K)</p> Source code in <code>georeader/reflectance.py</code> <pre><code>def srf(center_wavelengths:ArrayLike, fwhm:ArrayLike, wavelengths:ArrayLike) -&gt; NDArray:\n    \"\"\"\n    Returns the spectral response function (SRF) for the given center wavelengths and full width half maximum (FWHM).\n\n    Args:\n        center_wavelengths (np.array): array with center wavelengths. (K, )\n        fwhm (np.array): array with full width half maximum (FWHM) values (K,)\n        wavelengths (np.array): array with wavelengths where the SRF is evaluated (N,)\n\n    Returns:\n        np.array: normalized SRF (N, K)\n    \"\"\"\n    center_wavelengths = np.array(center_wavelengths) # (K, )\n    fwhm = np.array(fwhm) # (K, )\n    assert center_wavelengths.shape == fwhm.shape, f\"Center wavelengths and FWHM must have the same shape {center_wavelengths.shape} != {fwhm.shape}\"\n\n    sigma = fwhm / (2.0 * np.sqrt(2.0 * np.log(2.0))) # (K, )\n    var = sigma ** 2 # (K, )\n    denom = (2 * np.pi * var) ** 0.5 # (K, )\n    numer = np.exp(-(wavelengths[:, None] - center_wavelengths[None, :])**2 / (2*var)) # (N, K)\n    response = numer / denom # (N, K)\n\n    # Normalize each gaussian response to sum to 1.\n    response = np.divide(response, response.sum(axis=0), where=response.sum(axis=0) &gt; 0)# (N, K)\n    return response\n</code></pre>"},{"location":"modules/reflectance_module/#georeader.reflectance.transform_to_srf","title":"<code>transform_to_srf(hyperspectral_data, srf, wavelengths_hyperspectral, as_reflectance=False, solar_irradiance_bands=None, observation_date_corr_factor=None, center_coords=None, date_of_acquisition=None, resolution_dst=None, fill_value_default=0.0, sigma_bands=None, verbose=False, epsilon_srf=0.0001, extrapolate=False, units=None)</code>","text":"<p>Integrates the hyperspectral bands to the multispectral bands using the spectral response function (SRF).</p> <p>Parameters:</p> Name Type Description Default <code>hyperspectral_data</code> <code>Union[GeoData, NDArray]</code> <p>hyperspectral data (B, H, W) or GeoData. If as_reflectance is True, the data must be radiance and units must be filled in.</p> required <code>srf</code> <code>DataFrame</code> <p>spectral response function (SRF) (N, K). The index is the wavelengths and the columns are the bands.</p> required <code>wavelengths_hyperspectral</code> <code>List[float]</code> <p>wavelengths of the hyperspectral data (B,)</p> required <code>as_reflectance</code> <code>bool</code> <p>if True, the hyperspectral data will be converted to reflectance after integrating. Defaults to False.</p> <code>False</code> <code>solar_irradiance_bands</code> <code>Optional[NDArray]</code> <p>solar irradiance for each band to be used for the conversion to reflectance (K,).  Defaults to None. Must be provided in W/m\u00b2/nm.</p> <code>None</code> <code>observation_date_corr_factor</code> <code>Optional[float]</code> <p>observation date correction factor. Defaults to None.  Only used if as_reflectance is True.</p> <code>None</code> <code>center_coords</code> <code>Optional[Tuple[float, float]]</code> <p>center coordinates of the image. Defaults to None.  Only used if as_reflectance is True and observation_date_corr_factor is None.</p> <code>None</code> <code>date_of_acquisition</code> <code>Optional[datetime]</code> <p>date of acquisition. Defaults to None. Only used if as_reflectance is True and observation_date_corr_factor is None.</p> <code>None</code> <code>resolution_dst</code> <code>Optional[Union[float, Tuple[float, float]]]</code> <p>output resolution of the multispectral data. Defaults to None.  If None, the output will have the same resolution as the input hyperspectral data.</p> <code>None</code> <code>fill_value_default</code> <code>float</code> <p>fill value for missing data. Defaults to 0.</p> <code>0.0</code> <code>sigma_bands</code> <code>Optional[array]</code> <p>sigma for the anti-aliasing filter. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>print progress. Defaults to False.</p> <code>False</code> <code>epsilon_srf</code> <code>float</code> <p>threshold to consider a band in the SRF. Defaults to 1e-4.</p> <code>0.0001</code> <code>extrapolate</code> <code>bool</code> <p>if True, it will extrapolate the SRF to the hyperspectral wavelengths. Defaults to False.</p> <code>False</code> <code>units</code> <code>Optional[str]</code> <p>if as_reflectance is True, the units of the hyperspectral data must be provided. Defaults to None. accepted values: \"mW/m2/sr/nm\", \"W/m2/sr/nm\", \"uW/cm^2/SR/nm\"</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[GeoData, NDArray]</code> <p>Union[GeoData, NDArray]: multispectral data (C, H, W) or GeoData</p> Source code in <code>georeader/reflectance.py</code> <pre><code>def transform_to_srf(hyperspectral_data:Union[GeoData, NDArray], \n                     srf:pd.DataFrame,\n                     wavelengths_hyperspectral:List[float],\n                     as_reflectance:bool=False,\n                     solar_irradiance_bands:Optional[NDArray]=None,\n                     observation_date_corr_factor:Optional[float]=None,\n                     center_coords:Optional[Tuple[float, float]]=None,\n                     date_of_acquisition:Optional[datetime]=None,\n                     resolution_dst:Optional[Union[float,Tuple[float,float]]]=None,\n                     fill_value_default:float=0.,\n                     sigma_bands:Optional[np.array]=None,\n                     verbose:bool=False,\n                     epsilon_srf:float=1e-4,\n                     extrapolate:bool=False,\n                     units:Optional[str]=None) -&gt; Union[GeoData, NDArray]:\n    \"\"\"\n    Integrates the hyperspectral bands to the multispectral bands using the spectral response function (SRF).\n\n    Args:\n        hyperspectral_data (Union[GeoData, NDArray]): hyperspectral data (B, H, W) or GeoData. If as_reflectance is True, the data must be radiance\n            and units must be filled in.\n        srf (pd.DataFrame): spectral response function (SRF) (N, K). The index is the wavelengths and the columns are the bands.\n        wavelengths_hyperspectral (List[float]): wavelengths of the hyperspectral data (B,)\n        as_reflectance (bool, optional): if True, the hyperspectral data will be converted to reflectance after integrating. Defaults to False.\n        solar_irradiance_bands (Optional[NDArray], optional): solar irradiance for each band to be used for the conversion to reflectance (K,). \n            Defaults to None. Must be provided in W/m\u00b2/nm.\n        observation_date_corr_factor (Optional[float], optional): observation date correction factor. Defaults to None. \n            Only used if as_reflectance is True.\n        center_coords (Optional[Tuple[float, float]], optional): center coordinates of the image. Defaults to None. \n            Only used if as_reflectance is True and observation_date_corr_factor is None.\n        date_of_acquisition (Optional[datetime], optional): date of acquisition. Defaults to None.\n            Only used if as_reflectance is True and observation_date_corr_factor is None.\n        resolution_dst (Optional[Union[float,Tuple[float,float]]], optional): output resolution of the multispectral data. Defaults to None. \n            If None, the output will have the same resolution as the input hyperspectral data.\n        fill_value_default (float, optional): fill value for missing data. Defaults to 0.\n        sigma_bands (Optional[np.array], optional): sigma for the anti-aliasing filter. Defaults to None.\n        verbose (bool, optional): print progress. Defaults to False.\n        epsilon_srf (float, optional): threshold to consider a band in the SRF. Defaults to 1e-4.\n        extrapolate (bool, optional): if True, it will extrapolate the SRF to the hyperspectral wavelengths. Defaults to False.\n        units: if as_reflectance is True, the units of the hyperspectral data must be provided. Defaults to None.\n            accepted values: \"mW/m2/sr/nm\", \"W/m2/sr/nm\", \"uW/cm^2/SR/nm\"\n\n    Returns:\n        Union[GeoData, NDArray]: multispectral data (C, H, W) or GeoData\n    \"\"\"\n    from scipy import interpolate\n\n    assert hyperspectral_data.shape[0] == len(wavelengths_hyperspectral), f\"Different number of bands {hyperspectral_data.shape[0]} and band frequency centers {len(wavelengths_hyperspectral)}\"\n\n    anybigvalue = (srf&gt;epsilon_srf).any(axis=1)\n    srf = srf.loc[anybigvalue, :]    \n    bands = srf.columns\n\n    if as_reflectance:\n        assert units is not None, \"If as_reflectance is True, the units of the hyperspectral data must be specified\"\n        # check observation_date_corr_factor\n        if observation_date_corr_factor is None:\n            assert date_of_acquisition is not None, \"If observation_date_corr_factor is None, date_of_acquisition must be provided\"\n            if center_coords is None:\n                assert isinstance(hyperspectral_data, GeoTensor), \"If center_coords is None, data must be a GeoTensor\"\n                center_coords = hyperspectral_data.transform * (hyperspectral_data.shape[-1] // 2, hyperspectral_data.shape[-2] // 2)\n                crs_coords = hyperspectral_data.crs\n            else:\n                crs_coords = None\n\n            observation_date_corr_factor = observation_date_correction_factor(center_coords, date_of_acquisition,crs_coords=crs_coords)\n\n        if solar_irradiance_bands is None:\n            solar_irradiance_bands = integrated_irradiance(srf, epsilon_srf=epsilon_srf)\n            solar_irradiance_bands/=1_000\n\n    # Construct hyperspectral frequencies in the same resolution as srf\n    bands_index_hyperspectral = np.arange(0, len(wavelengths_hyperspectral))\n    interp = interpolate.interp1d(wavelengths_hyperspectral, bands_index_hyperspectral, kind=\"nearest\",\n                                  fill_value=\"extrapolate\" if extrapolate else np.nan)\n    y_nearest = interp(srf.index).astype(int)\n    table_hyperspectral_as_srf_multispectral = pd.DataFrame({\"SR_WL\": srf.index, \"band\": y_nearest})\n    table_hyperspectral_as_srf_multispectral = table_hyperspectral_as_srf_multispectral.set_index(\"SR_WL\")\n\n    output_array_spectral = np.full((len(bands),) + hyperspectral_data.shape[-2:],\n                                    fill_value=fill_value_default, dtype=np.float32)\n\n    for i,column_name in enumerate(bands):\n        if verbose:\n            print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}({i}/{len(bands)}) Processing band {column_name}\")\n        mask_zero = srf[column_name] &lt;= epsilon_srf\n        weight_per_wavelength = srf.loc[~mask_zero, [column_name]].copy()\n\n        assert weight_per_wavelength.shape[0] &gt;= 0, f\"No weights found! {weight_per_wavelength}\"\n\n        # Join with table of previous chunk\n        weight_per_wavelength = weight_per_wavelength.join(table_hyperspectral_as_srf_multispectral)\n\n        assert weight_per_wavelength.shape[0] &gt;= 0, \"No weights found!\"\n\n        # Normalize the SRF to sum one\n        column_name_norm = f\"{column_name}_norm\"\n        weight_per_wavelength[column_name_norm] = weight_per_wavelength[column_name] / weight_per_wavelength[\n            column_name].sum()\n        weight_per_hyperspectral_band = weight_per_wavelength.groupby(\"band\")[[column_name_norm]].sum()\n\n        indexes_read = weight_per_hyperspectral_band.index.tolist()\n\n        # Load bands of hyperspectral image\n        if verbose:\n            print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\t Loading {len(weight_per_hyperspectral_band.index)} bands\")\n            # print(\"these ones:\", weight_per_aviris_band.index)\n\n        if hasattr(hyperspectral_data, \"isel\"):\n            hyperspectral_multispectral_band_i_values = hyperspectral_data.isel({\"band\":indexes_read}).load().values\n\n            missing_values = np.any(hyperspectral_multispectral_band_i_values == hyperspectral_data.fill_value_default, axis=0)\n            if not np.any(missing_values):\n                missing_values = None\n        else:\n            hyperspectral_multispectral_band_i_values = hyperspectral_data[indexes_read]\n            missing_values = None\n\n        # hyperspectral_multispectral_band_i = hyperspectral_data.isel({\"band\": weight_per_hyperspectral_band.index}).load()\n        if verbose:\n            print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\t bands loaded, computing tensor\")\n\n\n        output_array_spectral[i] = np.sum(weight_per_hyperspectral_band[column_name_norm].values[:, np.newaxis,\n                                          np.newaxis] * hyperspectral_multispectral_band_i_values,\n                                          axis=0)\n\n        if as_reflectance:\n            output_array_spectral[i:(i+1)] = radiance_to_reflectance(output_array_spectral[i:(i+1)],\n                                                                     solar_irradiance_bands[i:(i+1)],\n                                                                     observation_date_corr_factor=observation_date_corr_factor,\n                                                                     units=units)\n\n        if missing_values is not None:\n            output_array_spectral[i][missing_values] = fill_value_default\n\n    if hasattr(hyperspectral_data, \"load\"):\n        geotensor_spectral = GeoTensor(output_array_spectral, transform=hyperspectral_data.transform,\n                                       crs=hyperspectral_data.crs,\n                                       fill_value_default=fill_value_default)\n\n        if (resolution_dst is None) or (resolution_dst == geotensor_spectral.res):\n            return geotensor_spectral\n\n        if isinstance(resolution_dst, numbers.Number):\n            resolution_dst = (abs(resolution_dst), abs(resolution_dst))\n\n\n        return read.resize(geotensor_spectral, resolution_dst=resolution_dst,\n                           anti_aliasing=True, anti_aliasing_sigma=sigma_bands)\n    else:\n        return output_array_spectral\n</code></pre>"},{"location":"modules/save_module/","title":"save","text":""},{"location":"modules/save_module/#georeader.save.save_cog","title":"<code>save_cog(data_save, path_tiff_save, profile=None, descriptions=None, tags=None, dir_tmpfiles='.', fs=None)</code>","text":"<p>Save data GeoData object as cloud optimized GeoTIFF</p> <p>Parameters:</p> Name Type Description Default <code>data_save</code> <code>GeoData</code> <p>GeoData (C, H, W) format with geoinformation (crs and transform).</p> required <code>descriptions</code> <code>Optional[List[str]]</code> <p>name of the bands</p> <code>None</code> <code>path_tiff_save</code> <code>str</code> <p>path to save the COG GeoTIFF</p> required <code>profile</code> <code>Optional[Dict[str, Any]]</code> <p>profile dict to save the data. crs and transform will be updated from data_save.</p> <code>None</code> <code>tags</code> <code>Optional[Dict[str, Any]]</code> <p>Dict to save as tags of the image</p> <code>None</code> <code>dir_tmpfiles</code> <code>str</code> <p>dir to create tempfiles if needed</p> <code>'.'</code> <code>fs</code> <code>Optional[Any]</code> <p>fsspec filesystem to save the file</p> <code>None</code> <p>Examples:</p> <p>img = np.random.randn(4,256,256) transform = rasterio.Affine(10, 0, 799980.0, 0, -10, 1900020.0) data = GeoTensor(img, crs=\"EPSG:32644\", transform=transform) save_cog(data, \"example.tif\", descriptions=[\"band1\", \"band2\", \"band3\", \"band4\"])</p> Source code in <code>georeader/save.py</code> <pre><code>def save_cog(data_save:GeoData, path_tiff_save:str,\n             profile:Optional[Dict[str, Any]]=None,\n             descriptions:Optional[List[str]] = None, \n             tags:Optional[Dict[str, Any]]=None,\n             dir_tmpfiles:str=\".\",\n             fs:Optional[Any]=None) -&gt; None:\n    \"\"\"\n    Save data GeoData object as cloud optimized GeoTIFF\n\n    Args:\n        data_save: GeoData (C, H, W) format with geoinformation (crs and transform).\n        descriptions: name of the bands\n        path_tiff_save: path to save the COG GeoTIFF\n        profile: profile dict to save the data. crs and transform will be updated from data_save.\n        tags: Dict to save as tags of the image\n        dir_tmpfiles: dir to create tempfiles if needed\n        fs: fsspec filesystem to save the file\n\n\n    Examples:\n        &gt;&gt; img = np.random.randn(4,256,256)\n        &gt;&gt; transform = rasterio.Affine(10, 0, 799980.0, 0, -10, 1900020.0)\n        &gt;&gt; data = GeoTensor(img, crs=\"EPSG:32644\", transform=transform)\n        &gt;&gt; save_cog(data, \"example.tif\", descriptions=[\"band1\", \"band2\", \"band3\", \"band4\"])\n\n    \"\"\"\n    if profile is None:\n        profile = {\n            \"compress\": \"lzw\",\n            \"RESAMPLING\": \"CUBICSPLINE\",  # for pyramids\n        }\n    if len(data_save.shape) == 3:\n        np_data = np.asanyarray(data_save.values)\n    elif len(data_save.shape) == 2:\n        np_data = np.asanyarray(data_save.values[np.newaxis])\n    else:\n        raise NotImplementedError(f\"Expected data with 2 or 3 dimensions found: {data_save.shape}\")\n\n    profile[\"crs\"] = data_save.crs\n    profile[\"transform\"] = data_save.transform\n\n    if \"nodata\" not in profile:\n        profile[\"nodata\"] = data_save.fill_value_default\n\n    _save_cog(np_data,\n              path_tiff_save, profile, descriptions=descriptions,\n              tags=tags, dir_tmpfiles=dir_tmpfiles, fs=fs)\n</code></pre>"},{"location":"modules/save_module/#georeader.save.save_tiled_geotiff","title":"<code>save_tiled_geotiff(data_save, path_tiff_save, profile_arg=None, descriptions=None, tags=None, dir_tmpfiles='.', blocksize=BLOCKSIZE_DEFAULT, fs=None)</code>","text":"<p>Save data GeoData object as tiled GeoTIFF (see <code>save_cog</code> to save as a Cloud Optimized GeoTIFF)</p> <p>Parameters:</p> Name Type Description Default <code>data_save</code> <code>GeoData</code> <p>GeoData (C, H, W) format with geoinformation (crs and transform).</p> required <code>path_tiff_save</code> <code>str</code> <p>path to save the GeoTIFF</p> required <code>profile_arg</code> <code>Optional[Dict[str, Any]]</code> <p>profile dict to save the data. crs and transform will be updated from data_save.</p> <code>None</code> <code>descriptions</code> <code>Optional[List[str]]</code> <p>name of the bands</p> <code>None</code> <code>profile</code> <p>profile dict to save the data. crs and transform will be updated from data_save.</p> required <code>tags</code> <code>Optional[Dict[str, Any]]</code> <p>Dict to save as tags of the image</p> <code>None</code> <code>dir_tmpfiles</code> <code>str</code> <p>dir to create tempfiles if needed</p> <code>'.'</code> <code>blocksize</code> <code>int</code> <p>blocksize of the GeoTIFF</p> <code>BLOCKSIZE_DEFAULT</code> <code>fs</code> <code>Optional[Any]</code> <p>fsspec filesystem to save the file</p> <code>None</code> Source code in <code>georeader/save.py</code> <pre><code>def save_tiled_geotiff(data_save:GeoData, path_tiff_save:str,\n                       profile_arg:Optional[Dict[str, Any]]=None,\n                       descriptions:Optional[List[str]] = None,\n                       tags:Optional[Dict[str, Any]]=None,\n                       dir_tmpfiles:str=\".\",\n                       blocksize:int=BLOCKSIZE_DEFAULT,\n                       fs:Optional[Any]=None) -&gt; None:\n    \"\"\"\n    Save data GeoData object as tiled GeoTIFF (see `save_cog` to save as a Cloud Optimized GeoTIFF)\n\n    Args:\n        data_save: GeoData (C, H, W) format with geoinformation (crs and transform).\n        path_tiff_save: path to save the GeoTIFF\n        profile_arg: profile dict to save the data. crs and transform will be updated from data_save.\n        descriptions: name of the bands\n        profile: profile dict to save the data. crs and transform will be updated from data_save.\n        tags: Dict to save as tags of the image\n        dir_tmpfiles: dir to create tempfiles if needed\n        blocksize: blocksize of the GeoTIFF\n        fs: fsspec filesystem to save the file\n\n    \"\"\"\n    profile = PROFILE_TILED_GEOTIFF_DEFAULT.copy()\n    profile.update({\"blockxsize\": blocksize, \"blockysize\": blocksize})\n    if profile_arg is not None:\n        profile.update(profile_arg)\n\n    if len(data_save.shape) == 3:\n        out_np = np.asanyarray(data_save.values)\n    elif len(data_save.shape) == 2:\n        out_np = np.asanyarray(data_save.values[np.newaxis])\n    else:\n        raise NotImplementedError(f\"Expected data with 2 or 3 dimensions found: {data_save.shape}\")\n\n    profile[\"crs\"] = data_save.crs\n    profile[\"transform\"] = data_save.transform\n\n    if \"nodata\" not in profile:\n        profile[\"nodata\"] = data_save.fill_value_default\n\n    if descriptions is not None:\n        assert len(descriptions) == out_np.shape[0], f\"Unexpected band descriptions {len(descriptions)} expected {out_np.shape[0]}\"\n\n    # Set count, height, width\n    for idx, c in enumerate([\"count\", \"height\", \"width\"]):\n        if c in profile:\n            assert profile[c] == out_np.shape[idx], f\"Unexpected shape: {profile[c]} {out_np.shape}\"\n        else:\n            profile[c] = out_np.shape[idx]\n\n    if \"dtype\" not in profile:\n        profile[\"dtype\"] = str(out_np.dtype)\n\n    # check blocksize\n    for idx, b in enumerate([\"blockysize\", \"blockxsize\"]):\n        if b in profile:\n            profile[b] = min(profile[b], out_np.shape[idx + 1])\n\n    if (out_np.shape[1] &gt; profile[\"blockysize\"]) or (out_np.shape[2] &gt; profile[\"blockxsize\"]):\n        profile[\"tiled\"] = True\n\n    profile[\"driver\"] = \"GTiff\"\n    is_remote_file = any((path_tiff_save.startswith(ext) for ext in REMOTE_FILE_EXTENSIONS))\n\n    # Create a tempfile if is a remote file\n    if is_remote_file:\n        with tempfile.NamedTemporaryFile(dir=dir_tmpfiles, suffix=\".tif\", delete=True) as fileobj:\n            name_save = fileobj.name\n    else:\n        name_save = path_tiff_save\n\n    with rasterio.open(name_save, \"w\", **profile) as rst_out:\n        if tags is not None:\n            rst_out.update_tags(**tags)\n        rst_out.write(out_np)\n        if descriptions is not None:\n            for i in range(1, out_np.shape[0] + 1):\n                rst_out.set_band_description(i, descriptions[i - 1])\n\n    if is_remote_file:\n        if fs is None:\n            import fsspec\n            fs = fsspec.filesystem(path_tiff_save.split(\":\")[0])\n\n        if not os.path.exists(name_save):\n            raise FileNotFoundError(f\"File {name_save} have not been created\")\n\n        fs.put_file(name_save, path_tiff_save, overwrite=True)\n        if os.path.exists(name_save):\n            os.remove(name_save)\n</code></pre>"},{"location":"modules/vectorize_module/","title":"vectorize","text":""},{"location":"modules/vectorize_module/#georeader.vectorize.get_polygons","title":"<code>get_polygons(binary_mask, min_area=25.5, polygon_buffer=0, tolerance=1.0, transform=None)</code>","text":"<p>Vectorize the polygons of the provided binary_mask.</p> <p>Parameters:</p> Name Type Description Default <code>binary_mask</code> <code>Union[ndarray, GeoData]</code> <p>(H, W) binary mask to rasterise</p> required <code>min_area</code> <code>float</code> <p>polygons with pixel area lower than this will be filtered</p> <code>25.5</code> <code>polygon_buffer</code> <code>int</code> <p>buffering of the polygons</p> <code>0</code> <code>tolerance</code> <code>float</code> <p>to simplify the polygons</p> <code>1.0</code> <code>transform</code> <code>Optional[Affine]</code> <p>affine transformation of the binary_water_mask raster. It will be used only if binary mask is        numpy array.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Polygon]</code> <p>list of vectorized polygons</p> Source code in <code>georeader/vectorize.py</code> <pre><code>def get_polygons(binary_mask: Union[np.ndarray, GeoData], min_area:float=25.5,\n                 polygon_buffer:int=0, tolerance:float=1., transform: Optional[rasterio.Affine]=None) -&gt; List[Polygon]:\n    \"\"\"\n    Vectorize the polygons of the provided binary_mask.\n\n    Args:\n        binary_mask: (H, W) binary mask to rasterise\n        min_area: polygons with pixel area lower than this will be filtered\n        polygon_buffer: buffering of the polygons\n        tolerance: to simplify the polygons\n        transform: affine transformation of the binary_water_mask raster. It will be used only if binary mask is \n                  numpy array.\n\n    Returns:\n        list of vectorized polygons\n\n    \"\"\"\n\n    if isinstance(binary_mask, np.ndarray):\n        binary_mask_np = binary_mask\n    else:\n        binary_mask_np = binary_mask.values\n\n        assert transform is None, \"transform only must be used if input is np.ndarray\"\n        transform = binary_mask.transform\n\n    shape_ = binary_mask_np.shape\n    if len(shape_) != 2:\n        binary_mask_np.squeeze()\n\n    assert len(binary_mask_np.shape) == 2, f\"Expected mask with 2 dim found {binary_mask_np.shape}\"\n\n    geoms_polygons = []\n    polygon_generator = features.shapes(binary_mask_np.astype(np.int16),\n                                        binary_mask_np)\n\n    for polygon, _ in polygon_generator:\n        p = shape(polygon)\n        if polygon_buffer &gt; 0:\n            p = p.buffer(polygon_buffer)\n        if p.area &gt;= min_area:\n            p = p.simplify(tolerance=tolerance)\n            if transform is not None:\n                p = transform_polygon(p, transform) # Convert polygon to raster coordinates\n            geoms_polygons.append(p)\n\n    return geoms_polygons\n</code></pre>"},{"location":"modules/vectorize_module/#georeader.vectorize.transform_polygon","title":"<code>transform_polygon(polygon, transform, relative=False, shape_raster=None)</code>","text":"<p>Transforms a polygon from pixel coordinates to the coordinates specified by the affine transform</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Union[Polygon, MultiPolygon]</code> <p>polygon to transform</p> required <code>transform</code> <code>Affine</code> <p>Affine transformation</p> required <code>relative</code> <code>bool</code> <p>if True, the polygon is transformed to relative coordinates (from 0 to 1)</p> <code>False</code> <code>shape_raster</code> <code>Optional[Tuple[int, int]]</code> <p>shape of the raster to which the polygon belongs. It is used only if relative is True</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Polygon, MultiPolygon]</code> <p>polygon with coordinates transformed by the affine transformation</p> Source code in <code>georeader/vectorize.py</code> <pre><code>def transform_polygon(polygon:Union[Polygon, MultiPolygon], \n                      transform: rasterio.Affine, relative:bool=False,\n                      shape_raster:Optional[Tuple[int,int]] = None) -&gt; Union[Polygon, MultiPolygon]:\n    \"\"\"\n    Transforms a polygon from pixel coordinates to the coordinates specified by the affine transform\n\n    Args:\n        polygon: polygon to transform\n        transform: Affine transformation\n        relative: if True, the polygon is transformed to relative coordinates (from 0 to 1)\n        shape_raster: shape of the raster to which the polygon belongs. It is used only if relative is True\n\n    Returns:\n        polygon with coordinates transformed by the affine transformation\n\n    \"\"\"\n    if relative:\n        assert shape_raster is not None, \"shape_raster must be provided if relative is True\"\n        transform = rasterio.Affine.scale(1/shape_raster[1], 1/shape_raster[0]) * transform\n\n    geojson_dict = mapping(polygon)\n    if geojson_dict[\"type\"] == \"Polygon\":\n        geojson_dict[\"coordinates\"] = [geojson_dict[\"coordinates\"]]\n\n    multipol_coords = []\n    for pol in geojson_dict[\"coordinates\"]:\n        pol_coords = []\n        for shell_or_holes in pol:\n            pol_out = []\n            for coords in shell_or_holes:\n                pol_out.append(transform * coords)\n\n            pol_coords.append(pol_out)\n\n        multipol_coords.append(pol_coords)\n\n    if geojson_dict[\"type\"] == \"Polygon\":\n        geojson_dict[\"coordinates\"] = multipol_coords[0]\n    else:\n        geojson_dict[\"coordinates\"] = multipol_coords\n\n    return shape(geojson_dict)\n</code></pre>"}]}